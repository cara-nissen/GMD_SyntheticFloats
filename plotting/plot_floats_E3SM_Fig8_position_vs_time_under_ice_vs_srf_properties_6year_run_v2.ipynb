{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "816a8784-8c24-4bb5-b790-052766d66fa8",
   "metadata": {},
   "source": [
    "\n",
    "# 6-year test run\n",
    "# Only look at floats under ice: How much does the trajectory deviate from straight line when float is under ice?\n",
    "# how much do surface properties vary along the path? \n",
    "# How many model grid cells does the trajectory cross under ice?\n",
    "\n",
    "# look at each year individually\n",
    "\n",
    "# Fig. 8 in GMD paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860ad28a-7d61-4bd1-ab78-71fc1ca51b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('/global/homes/c/cnissen/scripts/seawater-3.3.4/seawater/')\n",
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seawater\n",
    "#from seawater import dist\n",
    "#import seawater as sw\n",
    "import matplotlib.path as mpath\n",
    "from cartopy.util import add_cyclic_point\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.ticker as mticker\n",
    "from cartopy.mpl.ticker import (LongitudeFormatter, LatitudeFormatter,\n",
    "                                LatitudeLocator)\n",
    "import random\n",
    "from numba import njit\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "from tqdm import tqdm\n",
    "from mpasview import * # Qing's library, modified by Yohei Takano, Dec, 2022\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e35b95-dec1-45cf-a051-0032c8b2f2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----\n",
    "# saving plots\n",
    "#-----\n",
    "\n",
    "savepath     = '/global/cfs/cdirs/m4003/cnissen/Plots/E3SM_floats/trajectories_under_ice/6year_run/'\n",
    "# check existence of paths\n",
    "if not os.path.exists(savepath):\n",
    "    print ('Created '+savepath)\n",
    "    os.makedirs(savepath)\n",
    "    \n",
    "savepath2     = savepath+'example_trajectories/'\n",
    "# check existence of paths\n",
    "if not os.path.exists(savepath2):\n",
    "    print ('Created '+savepath2)\n",
    "    os.makedirs(savepath2)\n",
    "    \n",
    "savepath3     = savepath+'eps/'\n",
    "# check existence of paths\n",
    "if not os.path.exists(savepath3):\n",
    "    print ('Created '+savepath3)\n",
    "    os.makedirs(savepath3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7bab27-fab0-4496-b9df-e997f936bd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# specifics for trajectory output\n",
    "####\n",
    "\n",
    "rad_to_deg = 180.0/np.pi\n",
    "latlim = -45.0\n",
    "\n",
    "path_mesh = '/global/cfs/cdirs/m4003/maltrud/'\n",
    "meshID = 'EC30to60E2r2'\n",
    "meshfile = xr. open_dataset(path_mesh+'ocean.'+meshID+'.210210.nc')\n",
    "#print(meshfile)\n",
    "\n",
    "lon  = meshfile['lonCell'].values*rad_to_deg\n",
    "lat  = meshfile['latCell'].values*rad_to_deg\n",
    "topo = meshfile['bottomDepth'].values\n",
    "area = meshfile['areaCell'].values\n",
    "zlevs            = meshfile['refBottomDepth'].values\n",
    "layerThickness   = meshfile['layerThickness'].values\n",
    "restingThickness = meshfile['restingThickness'].values\n",
    "\n",
    "print(len(lon),'nodes in mesh')\n",
    "print(topo.shape)\n",
    "print(area.shape)\n",
    "print('Min/Max lon:',np.min(lon),np.max(lon))\n",
    "print('Min/Max lat:',np.min(lat),np.max(lat))\n",
    "print('layerThickness.shape:',layerThickness.shape)\n",
    "print('restingThickness.shape:',restingThickness.shape)\n",
    "\n",
    "meshfile.close()\n",
    "\n",
    "print(zlevs[38])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab0043d-92c4-4375-8e80-a2355c3e572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----\n",
    "# load daily float output from E3SM: oxygen, nitrate\n",
    "#----\n",
    "# NOTE: the reduction to \"deep\" floats is not 100% exact.\n",
    "#  -> when running this over different years, a different number of floats is identified as \"shallow\" floats\n",
    "#  -> for now, I kick out those that are \"shallow\" on day 1 of year 1\n",
    "# How to treat this later?\n",
    "\n",
    "path = '/global/cfs/cdirs/m4003/maltrud/6year/floats/'\n",
    "year_list = ['0055','0056','0057','0058','0059','0060']\n",
    "\n",
    "# kick out floats in shallow regions (these are not advected I think)\n",
    "ind = np.where(zlevs<=2200)[0]\n",
    "\n",
    "for yy in range(0,len(year_list)):\n",
    "    print('Load year '+year_list[yy])\n",
    "    file1 = 'floats.year'+year_list[yy]+'.nc'   \n",
    "    data = xr. open_dataset(path+file1)\n",
    "\n",
    "    lon_1   = data['particleColumnLon'].values*rad_to_deg \n",
    "    lat_1   = data['particleColumnLat'].values*rad_to_deg \n",
    "    ice_1   = data['particle_ifrac'].values \n",
    "    #oxy_1   = data['particleColumnO2'].values #[:,0,:]\n",
    "    no3_1   = data['particleColumnNO3'].values\n",
    "    u_1   = data['particleColumnVelZonal'].values\n",
    "    v_1   = data['particleColumnVelMerid'].values\n",
    "    #print('lat_all',lat_all.shape)\n",
    "\n",
    "    # set missing values to NaN (deep ocean layers) \n",
    "    #lat_1[no3_1==-1]=np.nan\n",
    "    #lon_1[no3_1==-1]=np.nan\n",
    "    lat_1[lat_1==0]=np.nan\n",
    "    lon_1[lon_1==0]=np.nan\n",
    "    no3_1[no3_1==-1]=np.nan \n",
    "    u_1[u_1==-1]=np.nan \n",
    "    v_1[v_1==-1]=np.nan \n",
    "    #oxy_1[oxy_1==-1]=np.nan \n",
    "    \n",
    "    print('Reduce to floats in the deep ocean')\n",
    "    if yy==0: # only load the first time, re-use ind_deep\n",
    "        aux = np.sum(np.isnan(no3_1[0,ind,:]),axis=0) # check if any of the depth levels shallower than 1100m is NaN\n",
    "        ind_deep = np.where(aux==0)[0] # if it is, aux is >0; only keep those that are 0\n",
    "  #  #print('Floats in the deep ocean:',ind_deep.shape)\n",
    "    lon_1   = lon_1[:,:,ind_deep]\n",
    "    lat_1   = lat_1[:,:,ind_deep]\n",
    "    no3_1   = no3_1[:,:,ind_deep]\n",
    "    u_1     = u_1[:,:,ind_deep]\n",
    "    v_1     = v_1[:,:,ind_deep]\n",
    "    ice_1   = ice_1[:,ind_deep]\n",
    "    #oxy_1   = oxy_1[:,:,ind_deep]\n",
    "    \n",
    "    #indSO = np.where(lat_all[0,:]<=-50)[0]\n",
    "    \n",
    "    if yy==0: # first time\n",
    "        lat_all = np.expand_dims(lat_1[:,0,:],axis=0)\n",
    "        lon_all = np.expand_dims(lon_1[:,0,:],axis=0)\n",
    "        no3_all = np.expand_dims(no3_1[:,0,:],axis=0)\n",
    "        u_all   = np.expand_dims(u_1[:,38,:],axis=0)\n",
    "        v_all   = np.expand_dims(v_1[:,38,:],axis=0)\n",
    "        ice_all = np.expand_dims(ice_1,axis=0)\n",
    "        #oxy_all_E3SM   = oxy_1\n",
    "    else:\n",
    "        if lat_1.shape[0]==363: # 2nd to last year\n",
    "            fill_array = np.nan*np.ones([1,lat_1.shape[2]])\n",
    "            fill_array = np.ma.masked_where(np.isnan(fill_array),fill_array)\n",
    "            lat_1 = np.concatenate((lat_1[:,0,:],fill_array))\n",
    "            lon_1 = np.concatenate((lon_1[:,0,:],fill_array))\n",
    "            no3_1 = np.concatenate((no3_1[:,0,:],fill_array))\n",
    "            u_1 = np.concatenate((u_1[:,38,:],fill_array))\n",
    "            v_1 = np.concatenate((v_1[:,38,:],fill_array))\n",
    "            ice_1 = np.concatenate((ice_1,fill_array))\n",
    "            lat_all = np.concatenate((lat_all,np.expand_dims(lat_1,axis=0)))\n",
    "            lon_all = np.concatenate((lon_all,np.expand_dims(lon_1,axis=0)))\n",
    "            no3_all = np.concatenate((no3_all,np.expand_dims(no3_1,axis=0)))\n",
    "            u_all = np.concatenate((u_all,np.expand_dims(u_1,axis=0)))\n",
    "            v_all = np.concatenate((v_all,np.expand_dims(v_1,axis=0)))\n",
    "            ice_all = np.concatenate((ice_all,np.expand_dims(ice_1,axis=0)))\n",
    "        else:\n",
    "            lat_all = np.concatenate((lat_all,np.expand_dims(lat_1[:,0,:],axis=0)))\n",
    "            lon_all = np.concatenate((lon_all,np.expand_dims(lon_1[:,0,:],axis=0)))\n",
    "            no3_all = np.concatenate((no3_all,np.expand_dims(no3_1[:,0,:],axis=0)))\n",
    "            ice_all = np.concatenate((ice_all,np.expand_dims(ice_1,axis=0)))\n",
    "            u_all = np.concatenate((u_all,np.expand_dims(u_1[:,38,:],axis=0)))\n",
    "            v_all = np.concatenate((v_all,np.expand_dims(v_1[:,38,:],axis=0)))\n",
    "            \n",
    "        #oxy_all_E3SM = np.concatenate((oxy_all_E3SM,oxy_1))\n",
    "        \n",
    "    #if yy==0: # first time\n",
    "    #    lat_all = lat_1[:,0,:]\n",
    "    #    lon_all = lon_1[:,0,:]\n",
    "    #    no3_all = no3_1[:,0,:]\n",
    "    #    ice_all = ice_1\n",
    "    #    #oxy_all_E3SM   = oxy_1\n",
    "    #else:\n",
    "    #    lat_all = np.concatenate((lat_all,lat_1[:,0,:]))\n",
    "    #    no3_all = np.concatenate((no3_all,no3_1[:,0,:]))\n",
    "    #    ice_all = np.concatenate((ice_all,ice_1))\n",
    "    #    #oxy_all_E3SM = np.concatenate((oxy_all_E3SM,oxy_1))\n",
    "        \n",
    "    del lon_1,lat_1,no3_1,ice_1,u_1,v_1\n",
    "    print(lon_all.shape)\n",
    "    \n",
    "print ('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f78d54-9624-4d19-b559-b29453006d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----\n",
    "# How far has each float travelled (horizontally) in those xx months?\n",
    "#-----\n",
    "\n",
    "#-------\n",
    "# functions\n",
    "#-------\n",
    "\n",
    "@njit\n",
    "def get_closest_grid_point(lon_point, lat_point, lon2, lat2):  \n",
    "    # in all nodes in mesh, return the index of the closest node to lon_point/lat_point\n",
    "    # lon2 & lat2 are the locations in the new mesh (to be redistributed to)\n",
    "    # lon2 & lat2 should be in radians\n",
    "    # numpy needs to be imported outside the function\n",
    "    \n",
    "    #from math import sin, cos, sqrt, atan2, radians\n",
    "    #import numpy as np\n",
    "    # approximate radius of earth in km\n",
    "    R = 6373.0\n",
    "    \n",
    "    #lat2 = radians(mesh.y2) # all positions in mesh\n",
    "    #lon2 = radians(mesh.x2)\n",
    "    #lat2 = [radians(x) for x in mesh.y2]\n",
    "    #lon2 = [radians(x) for x in mesh.x2]\n",
    "    lat1 = radians(lat_point)\n",
    "    lon1 = radians(lon_point)\n",
    "    bb1 = cos(lat1)\n",
    "    \n",
    "    all_distances = np.zeros(len(lon2))\n",
    "    for i in range(0,len(lon2)):\n",
    "        dlon = lon2[i] - lon1\n",
    "        dlat = lat2[i] - lat1\n",
    "        a = sin(dlat / 2)**2 + bb1 * cos(lat2[i]) * sin(dlon / 2)**2\n",
    "        all_distances[i] = 2*R*atan2(sqrt(a), sqrt(1 - a)) # to speed things up, omit constant factors here!\n",
    "        #all_distances[i] = 2*R*atan2(sqrt(a), sqrt(1 - a)) # correct distance\n",
    "        #del dlon, dlat, a\n",
    "    index_closest_node = np.argmin(all_distances)\n",
    "    distance_closest_node = np.min(all_distances)\n",
    "\n",
    "    return index_closest_node, distance_closest_node\n",
    "\n",
    "@njit\n",
    "def get_closest_grid_point_vector(lon_point, lat_point, lon2, lat2):  \n",
    "    # PROVIDE LIST OF LOCATIONS TO FUNCTION!\n",
    "    # in all nodes in mesh, return the index of the closest node to lon_point/lat_point\n",
    "    # lon2 & lat2 are the locations in the new mesh (to be redistributed to)\n",
    "    # lon2 & lat2 should be in radians\n",
    "    # numpy needs to be imported outside the function\n",
    "    \n",
    "    #from math import sin, cos, sqrt, atan2, radians\n",
    "    #import numpy as np\n",
    "    # approximate radius of earth in km\n",
    "    R = 6373.0\n",
    "    \n",
    "    #lat2 = radians(mesh.y2) # all positions in mesh\n",
    "    #lon2 = radians(mesh.x2)\n",
    "    #lat2 = [radians(x) for x in mesh.y2]\n",
    "    #lon2 = [radians(x) for x in mesh.x2]\n",
    "    \n",
    "    index_closest_node    = np.zeros(len(lon_point))\n",
    "    distance_closest_node = np.zeros(len(lon_point))\n",
    "    for jj in range(0,len(lon_point)):\n",
    "        lat1 = radians(lat_point[jj])\n",
    "        lon1 = radians(lon_point[jj])\n",
    "        bb1 = cos(lat1)\n",
    "        \n",
    "        all_distances = np.zeros(len(lon2))\n",
    "        for i in range(0,len(lon2)):\n",
    "            dlon = lon2[i] - lon1\n",
    "            dlat = lat2[i] - lat1\n",
    "            a = sin(dlat / 2)**2 + bb1 * cos(lat2[i]) * sin(dlon / 2)**2\n",
    "            all_distances[i] = 2*R*atan2(sqrt(a), sqrt(1 - a)) # to speed things up, omit constant factors here!\n",
    "            #all_distances[i] = 2*R*atan2(sqrt(a), sqrt(1 - a)) # correct distance\n",
    "            #del dlon, dlat, a\n",
    "        index_closest_node[jj] = np.argmin(all_distances)\n",
    "        distance_closest_node[jj] = np.min(all_distances)\n",
    "\n",
    "    return index_closest_node, distance_closest_node\n",
    "\n",
    "@njit\n",
    "def get_distance_between_two_points(lon_point, lat_point, lon_point2, lat_point2):\n",
    "        # all coordinates NOT in radians\n",
    "        #from math import sin, cos, sqrt, atan2, radians\n",
    "        #import numpy as np\n",
    "        # approximate radius of earth in km\n",
    "        R = 6373.0\n",
    "\n",
    "        #lat2 = radians(mesh.y2) # all positions in mesh\n",
    "        #lon2 = radians(mesh.x2)\n",
    "        #lat2 = [radians(x) for x in mesh.y2]\n",
    "        #lon2 = [radians(x) for x in mesh.x2]\n",
    "        lat1 = radians(lat_point)\n",
    "        lon1 = radians(lon_point)\n",
    "        bb1 = cos(lat1)\n",
    "        lat2 = radians(lat_point2)\n",
    "        lon2 = radians(lon_point2)\n",
    "\n",
    "        dlon = lon2 - lon1\n",
    "        dlat = lat2 - lat1\n",
    "        a = sin(dlat / 2)**2 + bb1 * cos(lat2) * sin(dlon / 2)**2\n",
    "        distance = 2*R*atan2(sqrt(a), sqrt(1 - a)) # to speed things up, omit constant factors here!\n",
    "\n",
    "        return distance\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48421ffa-69f4-428c-b500-2acd0e83d5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----\n",
    "# load full model output\n",
    "#-----\n",
    "\n",
    "path1 = '/global/cfs/cdirs/m4003/maltrud/6year/monthlyEulerianAverages/'\n",
    "# monthlyAverageIceFraction.year0055.nc\n",
    "\n",
    "year_list = ['55','56','57','58','59','60']\n",
    "\n",
    "for yy in tqdm(range(0,len(year_list))):\n",
    "    print('Load year',year_list[yy]) \n",
    "    \n",
    "    file1 = 'monthlyAverageIceFraction.year00'+year_list[yy]+'.nc'\n",
    "    ff = xr. open_dataset(path1+file1)\n",
    "    data=ff['timeMonthly_avg_iceAreaCell'].mean(axis=0)\n",
    "    data2=ff['timeMonthly_avg_iceAreaCell']#.mean(axis=0)\n",
    "    data2 = np.mean(data2[5:8+1,:],axis=0) # get JJA avg\n",
    "    if yy==0:\n",
    "        sea_ice_full     = data\n",
    "        sea_ice_full_jja = data2\n",
    "    else:\n",
    "        sea_ice_full     = sea_ice_full + data\n",
    "        sea_ice_full_jja = sea_ice_full_jja + data2\n",
    "    ff.close()\n",
    "    del data,data2\n",
    "    \n",
    "    file1 = 'monthlyAverageEulerianFields.year00'+year_list[yy]+'.nc'\n",
    "    ff = xr. open_dataset(path1+file1)\n",
    "    data1=np.squeeze(ff['timeMonthly_avg_velocityMeridional'].mean(axis=0))\n",
    "    data2=np.squeeze(ff['timeMonthly_avg_velocityZonal'].mean(axis=0)) \n",
    "    data1 = data1[:,38] # approximately 1000m\n",
    "    data2 = data2[:,38]\n",
    "    if yy==0:\n",
    "        vel_full = np.sqrt((data1*data1 + data2*data2))\n",
    "    else:\n",
    "        vel_full = vel_full + np.sqrt((data1*data1 + data2*data2))\n",
    "    ff.close()\n",
    "    del data1,data2\n",
    "    \n",
    "    #print(vel_full.shape)\n",
    "    \n",
    "sea_ice_full     = np.divide(sea_ice_full,len(year_list))\n",
    "sea_ice_full_jja = np.divide(sea_ice_full_jja,len(year_list))\n",
    "vel_full         = np.divide(vel_full,len(year_list))\n",
    "print('Annual mean sea ice:',np.min(np.array(sea_ice_full)),np.max(np.array(sea_ice_full)))\n",
    "print('JJA mean sea ice:',np.min(np.array(sea_ice_full_jja)),np.max(np.array(sea_ice_full_jja)))\n",
    "print(np.min(np.array(vel_full)),np.max(np.array(vel_full)))\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e9cc2f-1b53-4c37-87f8-9317b377ec80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-----\n",
    "# load full model output\n",
    "#-----\n",
    "\n",
    "path1 = '/global/cfs/cdirs/m4003/maltrud/6year/monthlyEulerianAverages/'\n",
    "# monthlyAverageIceFraction.year0055.nc\n",
    "\n",
    "year_list = ['55','56','57','58','59','60']\n",
    "\n",
    "for yy in tqdm(range(0,len(year_list))):\n",
    "    print('Load year',year_list[yy]) \n",
    "    \n",
    "    file1 = 'monthlyAverageEulerianFields.year00'+year_list[yy]+'.nc'\n",
    "    ff = xr. open_dataset(path1+file1)\n",
    "    data=np.squeeze(ff['timeMonthly_avg_ecosysTracers_NO3']) #.mean(axis=0)\n",
    "    data = np.mean(data[:,:,0],axis=0)\n",
    "    if yy==0:\n",
    "        no3_full     = data\n",
    "    else:\n",
    "        no3_full     = no3_full + data\n",
    "    ff.close()\n",
    "    del data\n",
    "    \n",
    "no3_full     = np.divide(no3_full,len(year_list))\n",
    "print('Annual mean NO3:',np.min(np.array(no3_full)),np.max(np.array(no3_full)))\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c74e89-8f02-4f2a-8da3-e6bc99b13423",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#----\n",
    "# plot Southern Ocean, ANNUAL MEAN\n",
    "#----\n",
    "res = 1\n",
    "levels = np.arange(15, 35+res, res)\n",
    "\n",
    "# MPAS-O mesh for EC30to60E2r2\n",
    "meshfile = path_mesh+'ocean.EC30to60E2r2.210210.nc'\n",
    "mpasmesh = MPASMesh(name = 'EC30to60E2r2', filepath = meshfile)\n",
    "print(mpasmesh)\n",
    "\n",
    "# Define MPASOMap for run1\n",
    "mpasomap_run1 = MPASOMap(data = no3_full, name = 'Sea ice concentration',\\\n",
    "                         units = '', mesh = mpasmesh)\n",
    "print(mpasomap_run1)\n",
    "\n",
    "save_plots = True\n",
    "dpicnt = 350\n",
    "\n",
    "plt.figure(figsize = [6, 5])\n",
    "m = mpasomap_run1.plot(region = 'SO_highLats', levels = levels,\\\n",
    "                       cmap = cm.Spectral_r, ptype = 'contourf',\\\n",
    "                       cticks=[0,0.2,0.4,0.6,0.8,1],colorbar=False) # pcolor, contourf\n",
    "\n",
    "#plt.title('Annual mean, 2012-2017')\n",
    "if save_plots:\n",
    "    filename = 'NO3_annual_mean_2012_2017_SO.png'\n",
    "    print(savepath+filename)\n",
    "    plt.savefig(savepath+filename,dpi = dpicnt, bbox_inches='tight')\n",
    "    del filename\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8461f4-ef1e-4a90-a665-6a4692534084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----\n",
    "# get average sea ice concentration for different regions\n",
    "#----\n",
    "\n",
    "latlim = -60\n",
    "\n",
    "ind_amundsen = np.where((lon>=210) & (lon<300) & (lat<=latlim))[0]\n",
    "ind_ross     = np.where((lon>=160) & (lon<210) & (lat<=latlim))[0]\n",
    "ind_eastAA   = np.where((lon>=0) & (lon<160) & (lat<=latlim))[0]\n",
    "ind_weddell  = np.where(((lon>=300) | (lon<0)) & (lat<=latlim))[0]\n",
    "a1 = np.array(np.sum(sea_ice_full[ind_amundsen]*area[ind_amundsen])/np.sum(area[ind_amundsen]))\n",
    "a2 = np.array(np.sum(sea_ice_full[ind_ross]*area[ind_ross])/np.sum(area[ind_ross]))\n",
    "a3 = np.array(np.sum(sea_ice_full[ind_eastAA]*area[ind_eastAA])/np.sum(area[ind_eastAA]))\n",
    "a4 = np.array(np.sum(sea_ice_full[ind_weddell]*area[ind_weddell])/np.sum(area[ind_weddell]))\n",
    "\n",
    "print('Sea ice concentration:')\n",
    "print('avg Amundsen/Bellingshausen: '+str(100*a1)+'%')\n",
    "print('avg Ross Sea: '+str(100*a2)+'%')\n",
    "print('avg east Antarctic: '+str(100*a3)+'%')\n",
    "print('avg Weddell Sea: '+str(100*a4)+'%')\n",
    "print('')\n",
    "\n",
    "b1 = np.array(np.sum(vel_full[ind_amundsen]*area[ind_amundsen])/np.sum(area[ind_amundsen]))\n",
    "b2 = np.array(np.sum(vel_full[ind_ross]*area[ind_ross])/np.sum(area[ind_ross]))\n",
    "b3 = np.array(np.sum(vel_full[ind_eastAA]*area[ind_eastAA])/np.sum(area[ind_eastAA]))\n",
    "b4 = np.array(np.sum(vel_full[ind_weddell]*area[ind_weddell])/np.sum(area[ind_weddell]))\n",
    "print('Velocity at 1000m:')\n",
    "print('avg Amundsen/Bellingshausen: '+str(b1)+' m s-1')\n",
    "print('avg Ross Sea: '+str(b2)+' m s-1')\n",
    "print('avg east Antarctic: '+str(b3)+' m s-1')\n",
    "print('avg Weddell Sea: '+str(b4)+' m s-1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daf8beb-beda-42e8-86e5-ee580aab814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----\n",
    "# plot Southern Ocean, ANNUAL MEAN\n",
    "#----\n",
    "res = 0.1\n",
    "levels = np.arange(0, 1+res, res) # velocity at 1000m\n",
    "\n",
    "# MPAS-O mesh for EC30to60E2r2\n",
    "meshfile = path_mesh+'ocean.EC30to60E2r2.210210.nc'\n",
    "mpasmesh = MPASMesh(name = 'EC30to60E2r2', filepath = meshfile)\n",
    "print(mpasmesh)\n",
    "\n",
    "# Define MPASOMap for run1\n",
    "mpasomap_run1 = MPASOMap(data = sea_ice_full, name = 'Sea ice concentration',\\\n",
    "                         units = '', mesh = mpasmesh)\n",
    "print(mpasomap_run1)\n",
    "\n",
    "save_plots = True\n",
    "dpicnt = 350\n",
    "\n",
    "plt.figure(figsize = [6, 5])\n",
    "m = mpasomap_run1.plot(region = 'SO_highLats', levels = levels,\\\n",
    "                       cmap = cm.Blues_r, ptype = 'contourf',\\\n",
    "                       cticks=[0,0.2,0.4,0.6,0.8,1],colorbar=False) # pcolor, contourf\n",
    "\n",
    "#plt.title('Annual mean, 2012-2017')\n",
    "if save_plots:\n",
    "    filename = 'Sea_ice_annual_mean_2012_2017_SO_blues.png'\n",
    "    print(savepath+filename)\n",
    "    plt.savefig(savepath+filename,dpi = dpicnt, bbox_inches='tight')\n",
    "    ##---\n",
    "    ## PDF\n",
    "    ##---\n",
    "    #filename = 'Velocity_annual_mean_1yr_test_SO_b.pdf'\n",
    "    #print(savepath+filename)\n",
    "    #plt.savefig(savepath+filename,dpi = dpicnt, bbox_inches='tight',format='pdf')\n",
    "    \n",
    "    del filename\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16066f6c-cb40-467f-a32b-49830a00e753",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#----\n",
    "# plot Southern Ocean, JJA MEAN\n",
    "#----\n",
    "res = 0.1\n",
    "levels = np.arange(0, 1+res, res) # velocity at 1000m\n",
    "\n",
    "# MPAS-O mesh for EC30to60E2r2\n",
    "meshfile = path_mesh+'ocean.EC30to60E2r2.210210.nc'\n",
    "mpasmesh = MPASMesh(name = 'EC30to60E2r2', filepath = meshfile)\n",
    "print(mpasmesh)\n",
    "\n",
    "# Define MPASOMap for run1\n",
    "mpasomap_run1 = MPASOMap(data = sea_ice_full_jja, name = 'Sea ice concentration',\\\n",
    "                         units = '', mesh = mpasmesh)\n",
    "print(mpasomap_run1)\n",
    "\n",
    "save_plots = True\n",
    "dpicnt = 350\n",
    "\n",
    "plt.figure(figsize = [6, 5])\n",
    "m = mpasomap_run1.plot(region = 'SO_highLats', levels = levels,\\\n",
    "                       cmap = cm.Blues_r, ptype = 'contourf',\\\n",
    "                       cticks=[0,0.2,0.4,0.6,0.8,1],colorbar=False) # pcolor, contourf\n",
    "\n",
    "#plt.title('Annual mean, 2012-2017')\n",
    "if save_plots:\n",
    "    filename = 'Sea_ice_JJA_mean_2012_2017_SO_blues.png'\n",
    "    print(savepath+filename)\n",
    "    plt.savefig(savepath+filename,dpi = dpicnt, bbox_inches='tight')\n",
    "    ##---\n",
    "    ## PDF\n",
    "    ##---\n",
    "    #filename = 'Velocity_annual_mean_1yr_test_SO_b.pdf'\n",
    "    #print(savepath+filename)\n",
    "    #plt.savefig(savepath+filename,dpi = dpicnt, bbox_inches='tight',format='pdf')\n",
    "    \n",
    "    del filename\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#---\n",
    "# colorbar separately\n",
    "#---\n",
    "\n",
    "lon_reg2 = np.arange(-180,180,1)\n",
    "lat_reg2 = np.arange(-90,90,1)\n",
    "lon_reg, lat_reg = np.meshgrid(lon_reg2, lat_reg2)\n",
    "data_plot = np.zeros_like(lon_reg)\n",
    "height,width = 18,7\n",
    "fs = 12\n",
    "\n",
    "fig = plt.figure(figsize=(height,width))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree(central_longitude=-150))\n",
    "ax.set_extent([-180, 180, -90, 90])\n",
    "mm1=ax.contourf(lon_reg, lat_reg, data_plot,\\\n",
    "                   levels=levels,extend='both',cmap=cm.Blues_r,transform=ccrs.PlateCarree())\n",
    "cbar = plt.colorbar(mm1,ax=ax,orientation='vertical',fraction=0.075, pad=0.02,shrink=0.9,ticks=[0,0.2,0.4,0.6,0.8,1])\n",
    "cbar.set_label('Sea ice concentration',fontsize=fs-2)\n",
    "cbar.ax.tick_params(labelsize=fs-3)\n",
    "fig.gca().set_visible(False)\n",
    "if save_plots:\n",
    "    filename = 'COLORBAR_Sea_ice_JJA_mean_2012_2017_SO_blues.png'\n",
    "    print(savepath+filename)\n",
    "    plt.savefig(savepath+filename,dpi = dpicnt, bbox_inches='tight')\n",
    "    del filename\n",
    "plt.show()\n",
    "\n",
    "#---\n",
    "# eps\n",
    "#---\n",
    "fig = plt.figure(figsize=(height,width))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree(central_longitude=-150))\n",
    "ax.set_extent([-180, 180, -90, 90])\n",
    "mm1=ax.contourf(lon_reg, lat_reg, data_plot,\\\n",
    "                   levels=levels,extend='both',cmap=cm.Blues_r,transform=ccrs.PlateCarree())\n",
    "cbar = plt.colorbar(mm1,ax=ax,orientation='vertical',fraction=0.075, pad=0.02,shrink=0.9,ticks=[0,0.2,0.4,0.6,0.8,1])\n",
    "cbar.ax.tick_params(labelsize=fs-3)\n",
    "cbar.ax.set_yticklabels(['', '', '','','',''])\n",
    "fig.gca().set_visible(False)\n",
    "if save_plots:\n",
    "    filename = 'COLORBAR_Sea_ice_JJA_mean_2012_2017_SO_blues.eps'\n",
    "    print(savepath+filename)\n",
    "    plt.savefig(savepath+filename,dpi = dpicnt, bbox_inches='tight',format='eps')\n",
    "    del filename\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e98c68-af8b-470d-a4ec-d442249feb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---\n",
    "# what do I want to do?\n",
    "#\n",
    "# How much does a trajectory differ in length when we don't know its position under ice? \n",
    "# 2 steps: \n",
    "#    daily data, impact of ice\n",
    "#    10-daily data, impact of ice\n",
    "#\n",
    "# quantify the difference in length based on sectors?\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8f918c-7566-47a7-a2b4-9fc85a4cfb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----\n",
    "# assess the impact of sea-ice cover\n",
    "#----\n",
    "\n",
    "# loop over particles: \n",
    "# if surface ice cover exceeds ice_threshold, assume that we're losing its exact position\n",
    "# set these instances to NaN\n",
    "# then, compute the length of the total trajectory along the original and the modified trajectory\n",
    "\n",
    "#---\n",
    "# reduce to the Southern Ocean\n",
    "#---\n",
    "indSO = np.where(lat_all[0,0,:]<=-50)[0]\n",
    "lat_all_SO = lat_all[:,:,indSO]\n",
    "lon_all_SO = lon_all[:,:,indSO]\n",
    "ice_all_SO = ice_all[:,:,indSO]\n",
    "no3_all_SO = no3_all[:,:,indSO]\n",
    "u_all_SO = u_all[:,:,indSO]\n",
    "v_all_SO = v_all[:,:,indSO]\n",
    "\n",
    "# 2nd to last year has a day of NaNs\n",
    "lat_all_SO[4,-1,:] = -999\n",
    "lon_all_SO[4,-1,:] = -999\n",
    "ice_all_SO[4,-1,:] = -999\n",
    "no3_all_SO[4,-1,:] = -999\n",
    "u_all_SO[4,-1,:] = -999\n",
    "v_all_SO[4,-1,:] = -999\n",
    "\n",
    "#print(lat_all_ice_corr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f8afdb-7868-4fcb-ac3a-d21b1eca5c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---\n",
    "# plot INITIAL POSITIONS on a map\n",
    "#---\n",
    "# to get an idea whether the floats are evenly spread\n",
    "from tqdm import tqdm\n",
    "\n",
    "list_lat = lat_all_SO[:,0,:].ravel()\n",
    "list_lon = lon_all_SO[:,0,:].ravel()\n",
    "\n",
    "fs = 10\n",
    "projection=ccrs.SouthPolarStereo()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 9))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=projection)\n",
    "ax.set_extent([-280, 80, -80, -50], crs=ccrs.PlateCarree())\n",
    "ax.add_feature(cartopy.feature.LAND,facecolor=(\"grey\"))\n",
    "ax.coastlines(resolution='50m')\n",
    "# Compute a circle in axes coordinates, which we can use as a boundary\n",
    "# for the map. We can pan/zoom as much as we like - the boundary will be\n",
    "# permanently circular.\n",
    "make_round_SO_map = True\n",
    "if make_round_SO_map:\n",
    "    theta = np.linspace(0, 2*np.pi, 100)\n",
    "    center, radius = [0.5, 0.5], 0.5\n",
    "    verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n",
    "    circle = mpath.Path(verts * radius + center)\n",
    "    ax.set_boundary(circle, transform=ax.transAxes)\n",
    "\n",
    "#ind_amundsen = np.where((lon_start>=210) & (lon_start<300))[0]\n",
    "#ind_ross     = np.where((lon_start>=160) & (lon_start<210))[0]\n",
    "#ind_eastAA   = np.where((lon_start>=0) & (lon_start<160))[0]\n",
    "#ind_weddell  = np.where((lon_start>=300) | (lon_start<0))[0]\n",
    "\n",
    "color1 = 'firebrick' # Amundsen \n",
    "color2 = 'mediumpurple' # Ross\n",
    "color3 = 'cornflowerblue' # eastAA\n",
    "color4 = 'black' # Weddell\n",
    "\n",
    "for ff in tqdm(range(0,list_lat.shape[0])):  \n",
    "    if (list_lon[ff]>=210) & (list_lon[ff]<300):\n",
    "        color_plot=color1 # Amundsen\n",
    "    elif (list_lon[ff]>=160) & (list_lon[ff]<210):\n",
    "        color_plot=color2 # Ross\n",
    "    elif (list_lon[ff]>=0) & (list_lon[ff]<160):\n",
    "        color_plot=color3 # eastAA\n",
    "    elif (list_lon[ff]>=300) | (list_lon[ff]<0):\n",
    "        color_plot=color4 # Weddell\n",
    "    mm=ax.plot(list_lon[ff],list_lat[ff],color=color_plot,\\\n",
    "               marker='o',markersize=3,linestyle=None,transform=ccrs.PlateCarree()) \n",
    "    \n",
    "if make_round_SO_map:\n",
    "    gl=ax.gridlines(crs=ccrs.PlateCarree(),draw_labels=True,linewidth=.5,\\\n",
    "                    color='grey', alpha=0.8,linestyle='--')#,xlabels_bottom=True)\n",
    "    gl.top_labels = True\n",
    "    gl.bottom_labels = True\n",
    "    gl.left_labels = True\n",
    "    gl.right_labels=True\n",
    "    #gl.xlines = True\n",
    "    gl.xlocator = mticker.FixedLocator([-180,-120,-60,0,60,120]) \n",
    "    gl.ylocator = mticker.FixedLocator([-65,-45])\n",
    "    #gl.ylocator = LatitudeLocator()\n",
    "    gl.xformatter = LongitudeFormatter()\n",
    "    gl.yformatter = LatitudeFormatter()\n",
    "    gl.rotate_labels = False\n",
    "\n",
    "save_plots = True\n",
    "if save_plots:\n",
    "    dpicnt = 200\n",
    "    filename = 'Map_initial_position_yearly_floats_wColors.png'\n",
    "    plt.savefig(savepath+filename,dpi = dpicnt, bbox_inches='tight',format='png')#,transparent=True)\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c4b81b-9ef9-4953-a302-ad534e7c2740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3fb4e2-fe53-4da8-9e06-c0d7407b2a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----\n",
    "# assess the impact of sea-ice cover\n",
    "#----\n",
    "\n",
    "# loop over particles: \n",
    "# if surface ice cover exceeds ice_threshold, assume that we're losing its exact position\n",
    "# set these instances to NaN\n",
    "# then, compute the length of the total trajectory along the original and the modified trajectory\n",
    "\n",
    "ice_threshold = 0.5\n",
    "print('ice threshold: '+str(100*ice_threshold)+'%')\n",
    "\n",
    "lat_all_ice_corr = np.copy(lat_all_SO)\n",
    "lon_all_ice_corr = np.copy(lon_all_SO)\n",
    "no3_all_ice_corr = np.copy(no3_all_SO)\n",
    "u_all_ice_corr = np.copy(u_all_SO)\n",
    "v_all_ice_corr = np.copy(v_all_SO)\n",
    "\n",
    "for yy in range(0,lat_all_ice_corr.shape[0]): # all years\n",
    "    for dd in range(0,lat_all_ice_corr.shape[1]): # all days\n",
    "        aux = ice_all_SO[yy,dd,:]\n",
    "        ind = np.where(aux>=ice_threshold)[0]\n",
    "        lat_all_ice_corr[yy,dd,ind] = np.nan\n",
    "        lon_all_ice_corr[yy,dd,ind] = np.nan\n",
    "        no3_all_ice_corr[yy,dd,ind] = np.nan\n",
    "        u_all_ice_corr[yy,dd,ind] = np.nan\n",
    "        v_all_ice_corr[yy,dd,ind] = np.nan\n",
    "        del aux,ind\n",
    "\n",
    "#print(np.min(ice_all),np.max(ice_all))\n",
    "\n",
    "# How many float encounter the \"high ice\" conditions?\n",
    "ind = np.sum(np.isnan(lat_all_ice_corr),axis=1)\n",
    "print('ind.shape',ind.shape)\n",
    "#ind = np.isnan(lat_all_ice_corr)\n",
    "print('ind min/max:',np.min(ind),np.max(ind))\n",
    "days_under_high_ice = np.copy(ind)\n",
    "num_in_ice = np.where(ind>0)[0]\n",
    "for yy in range(0,lat_all_ice_corr.shape[0]): # all years\n",
    "    #if yy==4:\n",
    "    #    print(np.where(ind[yy,:]>0)[0])\n",
    "    print(100*np.where(ind[yy,:]>0)[0].shape[0]/lat_all_ice_corr.shape[2],'% of all floats in sea-ice area at some point')\n",
    "#print(num_in_ice.shape[0])\n",
    "#print(np.sum(np.isnan(lat_all_ice_corr)))\n",
    "\n",
    "# What impact do interpolated under-ice trajectories have on mapped fields?\n",
    "# How exactly is the interpolation dealt with in real life? Are the data there and we just don't know the position, thus is the interpolated \n",
    "# line divided into XX positions to which the data are attributed?\n",
    "\n",
    "#----\n",
    "# How many days do floats spent in \"high-ice\" conditions\n",
    "#----\n",
    "bins = np.arange(0,365+5,5)\n",
    "\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "#plt.hist(x, density=True, bins=30)\n",
    "plt.hist(ind[ind>0],density=False, bins=60)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d95a38-5a00-492a-9698-84144a9f3573",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----\n",
    "# avg deviation (shading as std) vs. time spent under sea-ice cover\n",
    "#-----\n",
    "# step 1: get distance travelled along a) original and b) modified list of positions\n",
    "# original: lat_all_SO,lon_all_SO\n",
    "# modified: lat_all_ice_corr,lon_all_ice_corr\n",
    "\n",
    "## kick out NaNs\n",
    "#ind = np.where(~np.isnan(lat_all_ice_corr))\n",
    "#lat_all_ice_corr_no_NaN = lat_all_ice_corr[ind]\n",
    "#lon_all_ice_corr_no_NaN = lon_all_ice_corr[ind]\n",
    "#print(lon_all_ice_corr_no_NaN.shape)\n",
    "\n",
    "\n",
    "# WHY is there so many NaNs???\n",
    "\n",
    "#----\n",
    "# get distance trvelled along each trajectory, ignore \"zeros\" in output\n",
    "#----\n",
    "\n",
    "dist_all = np.nan*np.ones([lat_all_SO.shape[0],lat_all_SO.shape[2]]) \n",
    "dist_all_ice = np.nan*np.ones([lat_all_ice_corr.shape[0],lat_all_ice_corr.shape[2]])\n",
    "print(dist_all.shape,dist_all_ice.shape)\n",
    "for yy in tqdm(range(0,lat_all_SO.shape[0])): # years\n",
    "    for nn in range(0,lat_all_SO.shape[2]): # floats\n",
    "\n",
    "        process_ice = True\n",
    "        if process_ice:\n",
    "            #-----\n",
    "            # modified position data (\"high ice\" regions set to NaN)\n",
    "            #-----\n",
    "            aux1 = lat_all_ice_corr[yy,:,nn]\n",
    "            aux2 = lon_all_ice_corr[yy,:,nn]\n",
    "            ind = np.where(~np.isnan(aux1))[0]\n",
    "            aux1 = aux1[ind]\n",
    "            aux2 = aux2[ind]\n",
    "            #print(aux1.shape,aux2.shape)\n",
    "            # loop over all days and get total length of trajectory\n",
    "            aux3 = 0\n",
    "            for tt in range(0,aux1.shape[0]-1):\n",
    "                lon_point1,lat_point1 = aux2[tt],aux1[tt] \n",
    "                lon_point2,lat_point2 = aux2[tt+1],aux1[tt+1]           \n",
    "                aux5 = [lon_point1,lat_point1,lon_point2,lat_point2]\n",
    "                # only continue if no NaNs involved:\n",
    "                if len(np.where(np.isnan(aux5))[0])==0:\n",
    "                    aux3 = aux3 + get_distance_between_two_points(lon_point1,lat_point1,\\\n",
    "                                                                  lon_point2,lat_point2)\n",
    "                del lon_point1,lat_point1,lon_point2,lat_point2,aux5\n",
    "\n",
    "            dist_all_ice[yy,nn] = aux3\n",
    "            del aux3\n",
    "\n",
    "        #-----\n",
    "        # original position data\n",
    "        #-----\n",
    "        aux1 = lat_all_SO[yy,:,nn]\n",
    "        aux2 = lon_all_SO[yy,:,nn]\n",
    "        # NOT SURE IF THE BELOW IS NEEDED (but lat/lon have some NaNs...)\n",
    "        ind = np.where(~np.isnan(aux1))[0]\n",
    "        aux1 = aux1[ind]\n",
    "        aux2 = aux2[ind]\n",
    "        # loop over all days and get total length of trajectory\n",
    "        aux3 = 0\n",
    "        for tt in range(0,aux1.shape[0]-1):\n",
    "            lon_point1,lat_point1 = aux2[tt],aux1[tt] \n",
    "            lon_point2,lat_point2 = aux2[tt+1],aux1[tt+1] \n",
    "            aux5 = [lon_point1,lat_point1,lon_point2,lat_point2]\n",
    "            # only continue if no NaNs involved:\n",
    "            if len(np.where(np.isnan(aux5))[0])==0:\n",
    "                aux3 = aux3 + get_distance_between_two_points(lon_point1,lat_point1,\\\n",
    "                                                              lon_point2,lat_point2)\n",
    "            del lon_point1,lat_point1,lon_point2,lat_point2,aux5\n",
    "        dist_all[yy,nn] = aux3\n",
    "        del aux3\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41cfb87-698e-4319-a9ed-a81e0637d054",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print (days_under_high_ice)\n",
    "\n",
    "# \n",
    "diff_ratio = (dist_all-dist_all_ice)/dist_all\n",
    "print(diff_ratio.shape)\n",
    "\n",
    "ind = np.sum(np.isnan(lat_all_ice_corr),axis=1)\n",
    "days_under_high_ice = np.copy(ind)\n",
    "print(days_under_high_ice.shape)\n",
    "\n",
    "#days_under_high_ice = np.delete(days_under_high_ice,ratio>1000000000)\n",
    "#ratio = np.delete(ratio,ratio>1000000000)\n",
    "\n",
    "print('Min/Max ratio:',np.nanmin(diff_ratio),np.nanmax(diff_ratio))\n",
    "print('Min/Max days_under_high_ice:',np.min(days_under_high_ice),np.max(days_under_high_ice))\n",
    "\n",
    "ind_ice = np.where(days_under_high_ice>0)[0]\n",
    "\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "plt.plot(days_under_high_ice[ind_ice],diff_ratio[ind_ice],'ko')\n",
    "plt.show()\n",
    "\n",
    "#print(ratio[~np.isnan(ratio)].shape)\n",
    "#bins = np.arange(1,2.2+0.02,0.02)\n",
    "#fig = plt.figure(figsize=(6,5))\n",
    "#plt.hist(ratio,bins,density=True)\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f501f4-9314-4d4d-910a-6c7f2aae25cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.nanmax(diff_ratio[:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab9197f-5691-42a0-ba04-efd48f09fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---\n",
    "# plot trajectories of particles with large deviation between original and modified \n",
    "#---\n",
    "\n",
    "color_list = ['yellow','mediumpurple','lightgreen','orangered','mediumturquoise','cornflowerblue',\\\n",
    "             'slateblue','lightsteelblue','red','pink','lightgrey','forestgreen','brown','orange',\\\n",
    "             'darkviolet','lightcoral','firebrick','palegreen','palevioletred','navy',\\\n",
    "             'papayawhip','indigo','cyan','bisque','tan','khaki','maroon','darksalmon','olive']\n",
    "color_list = 30*color_list\n",
    "print ('Available colors:',len(color_list))\n",
    "\n",
    "#ind_high_devition2 = np.where(ratio>1.1)[0] # ratio only contains SO parameters\n",
    "#ind_sort = np.argsort(-1*ratio[ind_high_devition2]) # multiply by -1 to change the order of the sorting (high lats should be plotted last)\n",
    "#ind_high_devition = ind_high_devition2[ind_sort]\n",
    "#del ind_sort\n",
    "\n",
    "cs = 10\n",
    "fs_text = 9\n",
    "\n",
    "ratio_threshold = 0.5\n",
    "\n",
    "ind_high_devition = np.where(diff_ratio>0.1)[0]\n",
    "print(ind_high_devition.shape)\n",
    "\n",
    "# for co-location with model grid cells\n",
    "ind_lat = np.where(lat<=-48)[0]\n",
    "lat_rad = [radians(x) for x in lat[ind_lat]]\n",
    "lon_rad = [radians(x) for x in lon[ind_lat]]\n",
    "\n",
    "#----\n",
    "plot_example =False\n",
    "save_plots = False\n",
    "display_plots = True\n",
    "\n",
    "counter = 0\n",
    "for yy in range(0,diff_ratio.shape[0]):\n",
    "    #ind_high_devition = np.where((diff_ratio[yy,:]>ratio_threshold) & (diff_ratio[yy,:]<1))[0] # not interested in the floats that are 100% under ice\n",
    "    ind_high_devition = np.where((days_under_high_ice[yy,:]>230) & (days_under_high_ice[yy,:]<232))[0] \n",
    "    print(ind_high_devition.shape[0])\n",
    "    ind_sort = np.argsort(-1*diff_ratio[yy,:][ind_high_devition]) # multiply by -1 to change the order of the sorting (high lats should be plotted last)\n",
    "    ind_high_devition = ind_high_devition[ind_sort]\n",
    "    \n",
    "    for ff in tqdm(range(0,ind_high_devition.shape[0])):\n",
    "        #print(ff,diff_ratio[yy,ind_high_devition[ff]])\n",
    "        print('counter,yy,ff:',counter,yy,ff)\n",
    "        \n",
    "        aux1 = lat_all_SO[yy,:,ind_high_devition[ff]] #[:,ind_ice]\n",
    "        aux2 = lon_all_SO[yy,:,ind_high_devition[ff]]\n",
    "\n",
    "        aux3 = lat_all_ice_corr[yy,:,ind_high_devition[ff]]\n",
    "        aux4 = lon_all_ice_corr[yy,:,ind_high_devition[ff]]\n",
    "\n",
    "        aux5 = no3_all_ice_corr[yy,:,ind_high_devition[ff]]\n",
    "        aux6 = no3_all_SO[yy,:,ind_high_devition[ff]]\n",
    "\n",
    "        ind_NaN = np.where(np.isnan(aux3))[0]\n",
    "        ind_noNaN = np.where(~np.isnan(aux3))[0]\n",
    "\n",
    "        # check how many model grid cells the float passes under ice       \n",
    "        unique_cells = np.zeros([aux2[ind_NaN].shape[0]])\n",
    "        lat_under_ice = aux1[ind_NaN]\n",
    "        lon_under_ice = aux2[ind_NaN]\n",
    "        index_closest_node, distance_closest_node = get_closest_grid_point_vector(lon_under_ice, lat_under_ice,\\\n",
    "                                                                                          lon_rad, lat_rad)\n",
    "       \n",
    "        if plot_example:\n",
    "            fig = plt.figure(figsize=(10,5))\n",
    "            #plt.plot(aux2,aux1,'k',marker='o')\n",
    "            #plt.plot(aux4,aux3,'b',marker='x')\n",
    "\n",
    "            plt.plot(aux2[ind_noNaN],aux1[ind_noNaN],'k',marker='s',markersize=0.5,zorder=0) # in open water\n",
    "            #plt.plot(aux2[ind_NaN],aux1[ind_NaN],color_list[ff],marker='x',label='sea-ice conc. > '+str(ice_threshold)) # under ice\n",
    "\n",
    "            cs = 14\n",
    "            #edgecolor='orange',\n",
    "            plt.scatter(aux2[ind_noNaN],aux1[ind_noNaN],s=cs-5,c=aux6[ind_noNaN],marker='s',linestyle='-',label='open water')\n",
    "            plt.scatter(aux2[ind_NaN],aux1[ind_NaN],s=cs+5,c=aux6[ind_NaN],marker='x',label='sea-ice conc. > '+str(ice_threshold))\n",
    "\n",
    "            #plt.plot(aux2[ind_noNaN][0],aux1[ind_noNaN][0],'k',marker='o') # in open water\n",
    "\n",
    "            cbar=plt.colorbar()\n",
    "            cbar.set_label('Surface NO3 in mmol m$^{-3}$')\n",
    "\n",
    "            #plt.plot(aux1,aux2,'rx',markersize=cs)\n",
    "            #plt.plot([lon_all_SO[(ss*10),ff],lon_all_SO[(ss*10)+9,ff]],\\\n",
    "            #                     [lat_all_SO[ss*10,ff],lat_all_SO[(ss*10)+9,ff]],'darkgrey')\n",
    "            plt.annotate('full trajectory: '+str(np.round(100*dist_all[yy,ind_high_devition[ff]])/100)+' km',\\\n",
    "                            xy=(0.97,0.92),xycoords='axes fraction',fontsize=fs_text,ha='right',color='k')\n",
    "            plt.annotate('with gaps due to sea-ice presence: '+str(np.round(100*dist_all_ice[yy,ind_high_devition[ff]])/100)+' km',\\\n",
    "                            xy=(0.97,0.86),xycoords='axes fraction',fontsize=fs_text,ha='right',color='k')\n",
    "            plt.annotate('ratio: '+str(np.round(100*diff_ratio[yy,ind_high_devition[ff]])/100),\\\n",
    "                            xy=(0.97,0.8),xycoords='axes fraction',fontsize=fs_text,ha='right',color='k')\n",
    "            plt.annotate('total number of days under high ice cover: '+str(days_under_high_ice[yy,ind_high_devition[ff]]),\\\n",
    "                            xy=(0.97,0.74),xycoords='axes fraction',fontsize=fs_text,ha='right',color='k')\n",
    "            plt.annotate('number of unique model grid cells under high ice cover: '+str(int(np.unique(index_closest_node).shape[0])),\\\n",
    "                            xy=(0.97,0.68),xycoords='axes fraction',fontsize=fs_text,ha='right',color='k')\n",
    "            plt.ylabel('Latitude in $^{\\circ}$N')\n",
    "            plt.xlabel('Longitude in $^{\\circ}$E')\n",
    "\n",
    "            #handles, labels = ax.get_legend_handles_labels() \n",
    "            #order = [2,4,3,1,0] ##specify order of items in legend\n",
    "            plt.legend(loc='upper center', bbox_to_anchor=(0.65, 1.1),\\\n",
    "                        ncol=2,fancybox=True, frameon=False,shadow=False,prop={'size': 11})\n",
    "\n",
    "            if save_plots:\n",
    "                dpicnt = 200\n",
    "                if counter<10:\n",
    "                    filename = 'Trajectory_length_SO_only_ice_threshold_'+str(100*ice_threshold)+'_example_0'+str(counter)+'_with_NO3.png'\n",
    "                else:\n",
    "                    filename = 'Trajectory_length_SO_only_ice_threshold_'+str(100*ice_threshold)+'_example_'+str(counter)+'_with_NO3.png'\n",
    "                plt.savefig(savepath+'example_trajectories/'+filename,dpi = dpicnt, bbox_inches='tight',format='png')#,transparent=True)\n",
    "            counter = counter+1\n",
    "\n",
    "            if display_plots:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.close(fig)\n",
    "                \n",
    "        del index_closest_node, distance_closest_node,lat_under_ice,lon_under_ice\n",
    "\n",
    "\n",
    "#----\n",
    "# for each example, print the number of grid cells passed in time under ice\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01d0ed2-d8c2-4366-a6a4-75d91ab44171",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---\n",
    "# plot trajectories of particles with large deviation between original and modified \n",
    "#---\n",
    "\n",
    "color_list = ['yellow','mediumpurple','lightgreen','orangered','mediumturquoise','cornflowerblue',\\\n",
    "             'slateblue','lightsteelblue','red','pink','lightgrey','forestgreen','brown','orange',\\\n",
    "             'darkviolet','lightcoral','firebrick','palegreen','palevioletred','navy',\\\n",
    "             'papayawhip','indigo','cyan','bisque','tan','khaki','maroon','darksalmon','olive']\n",
    "color_list = 30*color_list\n",
    "print ('Available colors:',len(color_list))\n",
    "\n",
    "#ind_high_devition2 = np.where(ratio>1.1)[0] # ratio only contains SO parameters\n",
    "#ind_sort = np.argsort(-1*ratio[ind_high_devition2]) # multiply by -1 to change the order of the sorting (high lats should be plotted last)\n",
    "#ind_high_devition = ind_high_devition2[ind_sort]\n",
    "#del ind_sort\n",
    "\n",
    "cs = 10\n",
    "fs_text = 9\n",
    "\n",
    "ratio_threshold = 0.5\n",
    "\n",
    "ind_high_devition = np.where(diff_ratio>0.1)[0]\n",
    "print(ind_high_devition.shape)\n",
    "\n",
    "# for co-location with model grid cells\n",
    "ind_lat = np.where(lat<=-48)[0]\n",
    "lat_rad = [radians(x) for x in lat[ind_lat]]\n",
    "lon_rad = [radians(x) for x in lon[ind_lat]]\n",
    "\n",
    "#----\n",
    "plot_example =True\n",
    "save_plots = True\n",
    "display_plots = True\n",
    "\n",
    "counter = 0\n",
    "for yy in range(2,3):#,diff_ratio.shape[0]):\n",
    "    #ind_high_devition = np.where((diff_ratio[yy,:]>ratio_threshold) & (diff_ratio[yy,:]<1))[0] # not interested in the floats that are 100% under ice\n",
    "    ind_high_devition = np.where((days_under_high_ice[yy,:]>230) & (days_under_high_ice[yy,:]<232))[0] \n",
    "    print(ind_high_devition.shape[0])\n",
    "    ind_sort = np.argsort(-1*diff_ratio[yy,:][ind_high_devition]) # multiply by -1 to change the order of the sorting (high lats should be plotted last)\n",
    "    ind_high_devition = ind_high_devition[ind_sort]\n",
    "    \n",
    "    for ff in tqdm(range(0,1)): # ind_high_devition.shape[0]\n",
    "        #print(ff,diff_ratio[yy,ind_high_devition[ff]])\n",
    "        print('counter,yy,ff:',counter,yy,ff)\n",
    "        \n",
    "        aux1 = lat_all_SO[yy,:,ind_high_devition[ff]] #[:,ind_ice]\n",
    "        aux2 = lon_all_SO[yy,:,ind_high_devition[ff]]\n",
    "\n",
    "        aux3 = lat_all_ice_corr[yy,:,ind_high_devition[ff]]\n",
    "        aux4 = lon_all_ice_corr[yy,:,ind_high_devition[ff]]\n",
    "\n",
    "        aux5 = no3_all_ice_corr[yy,:,ind_high_devition[ff]]\n",
    "        aux6 = no3_all_SO[yy,:,ind_high_devition[ff]]\n",
    "\n",
    "        ind_NaN = np.where(np.isnan(aux3))[0]\n",
    "        ind_noNaN = np.where(~np.isnan(aux3))[0]\n",
    "\n",
    "        # check how many model grid cells the float passes under ice       \n",
    "        unique_cells = np.zeros([aux2[ind_NaN].shape[0]])\n",
    "        lat_under_ice = aux1[ind_NaN]\n",
    "        lon_under_ice = aux2[ind_NaN]\n",
    "        index_closest_node, distance_closest_node = get_closest_grid_point_vector(lon_under_ice, lat_under_ice,\\\n",
    "                                                                                          lon_rad, lat_rad)\n",
    "       \n",
    "        if plot_example:\n",
    "            fig = plt.figure(figsize=(11,4)) # 20,5\n",
    "            \n",
    "            plt.plot(aux2[ind_noNaN],aux1[ind_noNaN],'k',marker='s',markersize=0.5,zorder=0) # in open water\n",
    "            \n",
    "            cs = 50\n",
    "            plt.scatter(aux2[ind_noNaN],aux1[ind_noNaN],s=cs-5,c=aux6[ind_noNaN],marker='s',linestyle='-',label='open water')\n",
    "            plt.scatter(aux2[ind_NaN],aux1[ind_NaN],s=cs+5,c=aux6[ind_NaN],marker='x',label='sea-ice conc. > '+str(ice_threshold))\n",
    "\n",
    "            cbar=plt.colorbar()\n",
    "            cbar.set_label('Surface NO3 in mmol m$^{-3}$')\n",
    "\n",
    "            print_text = False\n",
    "            if print_text:\n",
    "                plt.annotate('full trajectory: '+str(np.round(100*dist_all[yy,ind_high_devition[ff]])/100)+' km',\\\n",
    "                                xy=(0.97,0.92),xycoords='axes fraction',fontsize=fs_text,ha='right',color='k')\n",
    "                plt.annotate('with gaps due to sea-ice presence: '+str(np.round(100*dist_all_ice[yy,ind_high_devition[ff]])/100)+' km',\\\n",
    "                                xy=(0.97,0.86),xycoords='axes fraction',fontsize=fs_text,ha='right',color='k')\n",
    "                plt.annotate('ratio: '+str(np.round(100*diff_ratio[yy,ind_high_devition[ff]])/100),\\\n",
    "                                xy=(0.97,0.8),xycoords='axes fraction',fontsize=fs_text,ha='right',color='k')\n",
    "                plt.annotate('total number of days under high ice cover: '+str(days_under_high_ice[yy,ind_high_devition[ff]]),\\\n",
    "                                xy=(0.97,0.74),xycoords='axes fraction',fontsize=fs_text,ha='right',color='k')\n",
    "                plt.annotate('number of unique model grid cells under high ice cover: '+str(int(np.unique(index_closest_node).shape[0])),\\\n",
    "                                xy=(0.97,0.68),xycoords='axes fraction',fontsize=fs_text,ha='right',color='k')\n",
    "           # plt.ylabel('Latitude in $^{\\circ}$N')\n",
    "           # plt.xlabel('Longitude in $^{\\circ}$E')\n",
    "\n",
    "            #handles, labels = ax.get_legend_handles_labels() \n",
    "            #order = [2,4,3,1,0] ##specify order of items in legend\n",
    "            plt.legend(loc='upper center', bbox_to_anchor=(0.65, 1.1),\\\n",
    "                        ncol=2,fancybox=True, frameon=False,shadow=False,prop={'size': 11})\n",
    "\n",
    "            if save_plots:\n",
    "                dpicnt = 200\n",
    "                #if counter<10:\n",
    "                #    filename = 'Trajectory_length_SO_only_ice_threshold_'+str(100*ice_threshold)+'_example_0'+str(counter)+'_with_NO3.png'\n",
    "                #else:\n",
    "                #    filename = 'Trajectory_length_SO_only_ice_threshold_'+str(100*ice_threshold)+'_example_'+str(counter)+'_with_NO3.png'\n",
    "                filename = 'FOR_PAPER_Trajectory_length_SO_only_ice_threshold_'+\\\n",
    "                str(100*ice_threshold)+'_example_with_NO3_2.eps'\n",
    "                plt.savefig(savepath+'example_trajectories/'+filename,dpi = dpicnt, bbox_inches='tight',format='eps')#,transparent=True)\n",
    "            counter = counter+1\n",
    "\n",
    "            if display_plots:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.close(fig)\n",
    "                \n",
    "        del index_closest_node, distance_closest_node,lat_under_ice,lon_under_ice\n",
    "\n",
    "\n",
    "#----\n",
    "# for each example, print the number of grid cells passed in time under ice\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cb956d-d1c1-4e4d-9473-d83b97ee1545",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a92f55-9500-4994-81f3-740fca17017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----\n",
    "# get the average difference within each sector\n",
    "#----\n",
    "\n",
    "#-----\n",
    "# for the locations under ice, how many model grid cells are passed?\n",
    "#  colocate each trajectory with closest model grid cell, count how many unique grid cells exist\n",
    "# \n",
    "# divide into sectors (based on lat/lon on day 1): \n",
    "#   1) Ross/Amundsen/Bellinghausen (western border: 160E, eastern border: 60W)\n",
    "#   2) Weddell Sea (western border: 60W, eastern border: 30E)\n",
    "#   3) east Antarctic (western border: 30E, eastern border: 160E)\n",
    "#\n",
    "\n",
    "# things one can look at (with a longer run at higher resolution):\n",
    "#    IAV\n",
    "#    impact of linear interpolation on tracer distributions\n",
    "\n",
    "\n",
    "#for yy in range(0,1):#diff_ratio.shape[0]):\n",
    "#    \n",
    "    ##ind_high_devition = np.where((diff_ratio[yy,:]>ratio_threshold) & (diff_ratio[yy,:]<1))[0] # not interested in the floats that are 100% under ice\n",
    "    #ind_high_devition = np.where((days_under_high_ice[yy,:]>180) & (days_under_high_ice[yy,:]<240))[0] \n",
    "    #print(ind_high_devition.shape[0])\n",
    "    #ind_sort = np.argsort(-1*diff_ratio[yy,:][ind_high_devition]) # multiply by -1 to change the order of the sorting (high lats should be plotted last)\n",
    "    #ind_high_devition = ind_high_devition[ind_sort]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5825c32-0165-48f8-8942-f0d4fff5b492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---\n",
    "# get average sea ice cover and velocity in each sector\n",
    "#---\n",
    "\n",
    "ice_threshold_list = [0.01]\n",
    "\n",
    "# avg velocity -> I am not sure this works this way (no area-weighting etc.)\n",
    "avg_vel_amundsen = np.zeros([len(ice_threshold_list)])\n",
    "avg_vel_ross     = np.zeros([len(ice_threshold_list)])\n",
    "avg_vel_weddell  = np.zeros([len(ice_threshold_list)])\n",
    "avg_vel_eastAA   = np.zeros([len(ice_threshold_list)])\n",
    "# avg sea ice cover -> I am not sure this works this way (no area-weighting etc.)\n",
    "avg_ice_amundsen = np.zeros([len(ice_threshold_list)])\n",
    "avg_ice_ross     = np.zeros([len(ice_threshold_list)])\n",
    "avg_ice_weddell  = np.zeros([len(ice_threshold_list)])\n",
    "avg_ice_eastAA   = np.zeros([len(ice_threshold_list)])\n",
    "for ii in range(0,1):#len(ice_threshold_list)):\n",
    "    ice_threshold = ice_threshold_list[ii]\n",
    "    print('')\n",
    "    print('ice threshold: '+str(100*ice_threshold)+'%')\n",
    "\n",
    "    lat_all_ice_corr = np.copy(lat_all_SO)\n",
    "    lon_all_ice_corr = np.copy(lon_all_SO)\n",
    "    no3_all_ice_corr = np.copy(no3_all_SO)\n",
    "    ice_all_ice_corr = np.copy(ice_all_SO)\n",
    "    u_all_ice_corr = np.copy(u_all_SO)\n",
    "    v_all_ice_corr = np.copy(v_all_SO)\n",
    "\n",
    "    lat_start = lat_all_SO[:,0,:]\n",
    "    lon_start = lon_all_SO[:,0,:]\n",
    "    \n",
    "    for yy in range(0,lat_all_ice_corr.shape[0]): # all years\n",
    "        for dd in range(0,lat_all_ice_corr.shape[1]): # all days\n",
    "            aux = ice_all_SO[yy,dd,:]\n",
    "            ind = np.where(aux>=ice_threshold)[0]\n",
    "            lat_all_ice_corr[yy,dd,ind] = np.nan\n",
    "            lon_all_ice_corr[yy,dd,ind] = np.nan\n",
    "            no3_all_ice_corr[yy,dd,ind] = np.nan\n",
    "            ice_all_ice_corr[yy,dd,ind] = np.nan\n",
    "            u_all_ice_corr[yy,dd,ind] = np.nan\n",
    "            v_all_ice_corr[yy,dd,ind] = np.nan\n",
    "            del aux,ind\n",
    "            \n",
    "    u_all_ice_corr[u_all_ice_corr<-99]=np.nan\n",
    "    v_all_ice_corr[v_all_ice_corr<-99]=np.nan\n",
    "    velocity = np.sqrt(np.multiply(u_all_ice_corr,u_all_ice_corr) + np.multiply(v_all_ice_corr,v_all_ice_corr))\n",
    "    velocity = np.nanmean(velocity,axis=1)\n",
    "    \n",
    "    ice = np.nanmean(ice_all_ice_corr,axis=1)\n",
    "\n",
    "    # impose lat criterion for veolicites (to avoid ACC)\n",
    "    ind_amundsen2 = np.where((lon_start>=210) & (lon_start<300) & (lat_start<-60))[0]\n",
    "    ind_ross2     = np.where((lon_start>=160) & (lon_start<210) & (lat_start<-60))[0]\n",
    "    ind_eastAA2   = np.where((lon_start>=0) & (lon_start<160) & (lat_start<-60))[0]\n",
    "    ind_weddell2  = np.where(((lon_start>=300) | (lon_start<0)) & (lat_start<-60))[0]\n",
    "    # get avg velocity at ~1000m for current \"high ice\" conditions\n",
    "    avg_vel_amundsen[ii] = np.nanmean(velocity.ravel()[ind_amundsen2])\n",
    "    avg_vel_ross[ii]     = np.nanmean(velocity.ravel()[ind_ross2])\n",
    "    avg_vel_weddell[ii]  = np.nanmean(velocity.ravel()[ind_weddell2])\n",
    "    avg_vel_eastAA[ii]   = np.nanmean(velocity.ravel()[ind_eastAA2])\n",
    "    # get avg sea ice cover for current \"high ice\" conditions\n",
    "    avg_ice_amundsen[ii] = np.nanmean(ice.ravel()[ind_amundsen2])\n",
    "    avg_ice_ross[ii]     = np.nanmean(ice.ravel()[ind_ross2])\n",
    "    avg_ice_weddell[ii]  = np.nanmean(ice.ravel()[ind_weddell2])\n",
    "    avg_ice_eastAA[ii]   = np.nanmean(ice.ravel()[ind_eastAA2])\n",
    "    \n",
    "print('done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37dadb4-8544-4974-bbe4-73da93b44593",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ice.shape)\n",
    "print(velocity.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfcee8c-e33e-4bf2-978d-373d0d3f9512",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('velocity:')\n",
    "print(avg_vel_ross) \n",
    "print(avg_vel_weddell)\n",
    "print(avg_vel_amundsen)\n",
    "print(avg_vel_eastAA)\n",
    "\n",
    "print('')\n",
    "print('sea ice cover:')\n",
    "print(avg_ice_ross) \n",
    "print(avg_ice_weddell)\n",
    "print(avg_ice_amundsen)\n",
    "print(avg_ice_eastAA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c24619e-1b71-4826-b5e6-80b5817e0200",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# divide into sectors (based on lat/lon on day 1): \n",
    "#   1) Ross/Amundsen/Bellinghausen (western border: 160E, eastern border: 60W)\n",
    "#   2) Weddell Sea (western border: 60W, eastern border: 30E)\n",
    "#   3) east Antarctic (western border: 30E, eastern border: 160E)\n",
    "\n",
    "#----\n",
    "# assess the impact of sea-ice cover\n",
    "#----\n",
    "\n",
    "# loop over particles: \n",
    "# if surface ice cover exceeds ice_threshold, assume that we're losing its exact position\n",
    "# set these instances to NaN\n",
    "# then, compute the length of the total trajectory along the original and the modified trajectory\n",
    "\n",
    "#ice_threshold_list = [0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.95]\n",
    "ice_threshold_list = [0.025,0.05,0.075,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.925,0.95,0.975]\n",
    "\n",
    "ice_threshold_list = [0.5]\n",
    "\n",
    "\n",
    "# trajectory difference\n",
    "avg_amundsen = np.zeros([len(ice_threshold_list)])\n",
    "avg_ross     = np.zeros([len(ice_threshold_list)])\n",
    "avg_weddell  = np.zeros([len(ice_threshold_list)])\n",
    "avg_eastAA   = np.zeros([len(ice_threshold_list)])\n",
    "std_amundsen = np.zeros([len(ice_threshold_list)])\n",
    "std_ross     = np.zeros([len(ice_threshold_list)])\n",
    "std_weddell  = np.zeros([len(ice_threshold_list)])\n",
    "std_eastAA   = np.zeros([len(ice_threshold_list)])\n",
    "for ii in range(0,1):#len(ice_threshold_list)):\n",
    "    ice_threshold = ice_threshold_list[ii]\n",
    "    print('')\n",
    "    print('ice threshold: '+str(100*ice_threshold)+'%')\n",
    "\n",
    "    lat_all_ice_corr = np.copy(lat_all_SO)\n",
    "    lon_all_ice_corr = np.copy(lon_all_SO)\n",
    "    no3_all_ice_corr = np.copy(no3_all_SO)\n",
    "    u_all_ice_corr = np.copy(u_all_SO)\n",
    "    v_all_ice_corr = np.copy(v_all_SO)\n",
    "\n",
    "    for yy in range(0,lat_all_ice_corr.shape[0]): # all years\n",
    "        for dd in range(0,lat_all_ice_corr.shape[1]): # all days\n",
    "            aux = ice_all_SO[yy,dd,:]\n",
    "            ind = np.where(aux>=ice_threshold)[0]\n",
    "            lat_all_ice_corr[yy,dd,ind] = np.nan\n",
    "            lon_all_ice_corr[yy,dd,ind] = np.nan\n",
    "            no3_all_ice_corr[yy,dd,ind] = np.nan\n",
    "            u_all_ice_corr[yy,dd,ind] = np.nan\n",
    "            v_all_ice_corr[yy,dd,ind] = np.nan\n",
    "            del aux,ind\n",
    "            \n",
    "    u_all_ice_corr[u_all_ice_corr<-99]=np.nan\n",
    "    v_all_ice_corr[v_all_ice_corr<-99]=np.nan\n",
    "    velocity = np.sqrt(np.multiply(u_all_ice_corr,u_all_ice_corr) + np.multiply(v_all_ice_corr,v_all_ice_corr))\n",
    "    velocity = np.nanmean(velocity,axis=1)\n",
    "    \n",
    "    # How many float encounter the \"high ice\" conditions?\n",
    "    ind = np.sum(np.isnan(lat_all_ice_corr),axis=1)\n",
    "    #print('ind.shape',ind.shape)\n",
    "    #ind = np.isnan(lat_all_ice_corr)\n",
    "    #print('ind min/max:',np.min(ind),np.max(ind))\n",
    "    days_under_high_ice = np.copy(ind)\n",
    "    num_in_ice = np.where(ind>0)[0]\n",
    "\n",
    "    #----\n",
    "    # get distance trvelled along each trajectory, ignore \"zeros\" in output\n",
    "    #----\n",
    "\n",
    "    dist_all = np.nan*np.ones([lat_all_SO.shape[0],lat_all_SO.shape[2]]) \n",
    "    dist_all_ice = np.nan*np.ones([lat_all_ice_corr.shape[0],lat_all_ice_corr.shape[2]])\n",
    "    #print(dist_all.shape,dist_all_ice.shape)\n",
    "    for yy in range(0,lat_all_SO.shape[0]): # years\n",
    "        for nn in range(0,lat_all_SO.shape[2]): # floats\n",
    "\n",
    "            process_ice = True\n",
    "            if process_ice:\n",
    "                #-----\n",
    "                # modified position data (\"high ice\" regions set to NaN)\n",
    "                #-----\n",
    "                aux1 = lat_all_ice_corr[yy,:,nn]\n",
    "                aux2 = lon_all_ice_corr[yy,:,nn]\n",
    "                ind = np.where(~np.isnan(aux1))[0]\n",
    "                aux1 = aux1[ind]\n",
    "                aux2 = aux2[ind]\n",
    "                #print(aux1.shape,aux2.shape)\n",
    "                # loop over all days and get total length of trajectory\n",
    "                aux3 = 0\n",
    "                for tt in range(0,aux1.shape[0]-1):\n",
    "                    lon_point1,lat_point1 = aux2[tt],aux1[tt] \n",
    "                    lon_point2,lat_point2 = aux2[tt+1],aux1[tt+1]           \n",
    "                    aux5 = [lon_point1,lat_point1,lon_point2,lat_point2]\n",
    "                    # only continue if no NaNs involved:\n",
    "                    if len(np.where(np.isnan(aux5))[0])==0:\n",
    "                        aux3 = aux3 + get_distance_between_two_points(lon_point1,lat_point1,\\\n",
    "                                                                      lon_point2,lat_point2)\n",
    "                    del lon_point1,lat_point1,lon_point2,lat_point2,aux5\n",
    "\n",
    "                dist_all_ice[yy,nn] = aux3\n",
    "                del aux3\n",
    "\n",
    "            #-----\n",
    "            # original position data\n",
    "            #-----\n",
    "            aux1 = lat_all_SO[yy,:,nn]\n",
    "            aux2 = lon_all_SO[yy,:,nn]\n",
    "            # NOT SURE IF THE BELOW IS NEEDED (but lat/lon have some NaNs...)\n",
    "            ind = np.where(~np.isnan(aux1))[0]\n",
    "            aux1 = aux1[ind]\n",
    "            aux2 = aux2[ind]\n",
    "            # loop over all days and get total length of trajectory\n",
    "            aux3 = 0\n",
    "            for tt in range(0,aux1.shape[0]-1):\n",
    "                lon_point1,lat_point1 = aux2[tt],aux1[tt] \n",
    "                lon_point2,lat_point2 = aux2[tt+1],aux1[tt+1] \n",
    "                aux5 = [lon_point1,lat_point1,lon_point2,lat_point2]\n",
    "                # only continue if no NaNs involved:\n",
    "                if len(np.where(np.isnan(aux5))[0])==0:\n",
    "                    aux3 = aux3 + get_distance_between_two_points(lon_point1,lat_point1,\\\n",
    "                                                                  lon_point2,lat_point2)\n",
    "                del lon_point1,lat_point1,lon_point2,lat_point2,aux5\n",
    "            dist_all[yy,nn] = aux3\n",
    "            del aux3\n",
    "\n",
    "    #print('done')\n",
    "\n",
    "    diff_ratio = (dist_all-dist_all_ice)/dist_all\n",
    "    #print(diff_ratio.shape)\n",
    "\n",
    "    ind = np.sum(np.isnan(lat_all_ice_corr),axis=1)\n",
    "    days_under_high_ice = np.copy(ind)\n",
    "    #print(days_under_high_ice.shape)\n",
    "    #print('Min/Max ratio:',np.nanmin(diff_ratio),np.nanmax(diff_ratio))\n",
    "    #print('Min/Max days_under_high_ice:',np.min(days_under_high_ice),np.max(days_under_high_ice))\n",
    "    ind_ice = np.where(days_under_high_ice>0)[0]\n",
    "\n",
    "\n",
    "    lat_start = lat_all_SO[:,0,:]\n",
    "    lon_start = lon_all_SO[:,0,:]\n",
    "    #print('lon_start',lon_start.shape,lon_start.ravel().shape)\n",
    "\n",
    "    diff_ratio2 = np.copy(diff_ratio)\n",
    "    ind_not_nan = np.where(~np.isnan(diff_ratio2.ravel()))[0]\n",
    "    diff_ratio2 = diff_ratio2.ravel()[ind_not_nan]\n",
    "    lat_start   = lat_start.ravel()[ind_not_nan]\n",
    "    lon_start   = lon_start.ravel()[ind_not_nan]\n",
    "    #print('min/max lon:',np.nanmin(lon_start),np.nanmax(lon_start))\n",
    "\n",
    "    ind_amundsen = np.where((lon_start>=210) & (lon_start<300))[0]\n",
    "    ind_ross     = np.where((lon_start>=160) & (lon_start<210))[0]\n",
    "    #ind_ross    = np.where((lon_start>=160) & (lon_start<300))[0]\n",
    "    #ind_weddell = np.where((lon_start>=300) | (lon_start<30))[0]\n",
    "    ind_eastAA   = np.where((lon_start>=0) & (lon_start<160))[0]\n",
    "    ind_weddell  = np.where((lon_start>=300) | (lon_start<0))[0]\n",
    "    total_num = ind_amundsen.shape[0]+ind_ross.shape[0]+ind_weddell.shape[0]+ind_eastAA.shape[0]\n",
    "    print('Sum of all:',total_num)\n",
    "    print('absolute (Amundsen/Ross/Weddell/eastAA):',ind_amundsen.shape[0],ind_ross.shape[0],\\\n",
    "          ind_weddell.shape[0],ind_eastAA.shape[0])\n",
    "    print('relative:',ind_amundsen.shape[0]/total_num,ind_ross.shape[0]/total_num,\\\n",
    "          ind_weddell.shape[0]/total_num,ind_eastAA.shape[0]/total_num)\n",
    "\n",
    "\n",
    "    #avg_ross    = np.mean(dist_all.ravel()[ind_ross])\n",
    "    #avg_weddell = np.mean(dist_all.ravel()[ind_weddell])\n",
    "    #avg_eastAA  = np.mean(dist_all.ravel()[ind_eastAA])\n",
    "\n",
    "    #---\n",
    "    # TO DO:\n",
    "    # same for sea ice!\n",
    "    # get average sea ice cover\n",
    "    # in the end, the sorting of the region will be a combination\n",
    "    # of where sea ice cover is high and where velocities are high\n",
    "    #\n",
    "    \n",
    "    avg_amundsen[ii] = np.nanmean(diff_ratio2[ind_amundsen])\n",
    "    avg_ross[ii]     = np.nanmean(diff_ratio2[ind_ross])\n",
    "    avg_weddell[ii]  = np.nanmean(diff_ratio2[ind_weddell])\n",
    "    avg_eastAA[ii]   = np.nanmean(diff_ratio2[ind_eastAA])\n",
    "\n",
    "    std_amundsen[ii] = np.nanstd(diff_ratio2[ind_amundsen])\n",
    "    std_ross[ii]     = np.nanstd(diff_ratio2[ind_ross])\n",
    "    std_weddell[ii]  = np.nanstd(diff_ratio2[ind_weddell])\n",
    "    std_eastAA[ii]   = np.nanstd(diff_ratio2[ind_eastAA])\n",
    "\n",
    "    print('')\n",
    "    print('Amundsen Sea avg: '+str(avg_amundsen[ii])+' +/- '+str(std_amundsen[ii]))\n",
    "    print('Ross Sea avg: '+str(avg_ross[ii])+' +/- '+str(std_ross[ii]))\n",
    "    print('east Antarctic avg: '+str(avg_eastAA[ii])+' +/- '+str(std_eastAA[ii]))\n",
    "    print('Weddell Sea avg: '+str(avg_weddell[ii])+' +/- '+str(std_weddell[ii]))\n",
    "\n",
    "    # ice threshold 50%\n",
    "    #Sum of all: 4146\n",
    "    #absolute (Amundsen/Ross/Weddell/eastAA): 1036 693 955 1462\n",
    "    #relative: 0.24987940183309212 0.1671490593342981 0.23034249879401833 0.3526290400385914\n",
    "    #\n",
    "    #Amundsen Sea avg: 0.13102508154296055 +/- 0.2575042553228124\n",
    "    #Ross Sea avg: 0.18081375483811757 +/- 0.31005018916652866\n",
    "    #east Antarctic avg: 0.08282937489108787 +/- 0.2001843133775308\n",
    "    #Weddell Sea avg: 0.22485873569905585 +/- 0.37251976073398535\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07a846f-399a-4023-b922-2b83310e6c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53ff675-60dc-4775-a48b-6e669581caa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#colovelocity 'mediumpurple'\n",
    "#color2 = 'darkorange'\n",
    "#color3 = 'cornflowerblue'\n",
    "#color4 = 'black'\n",
    "color1 = 'firebrick' # Amundsen \n",
    "color2 = 'mediumpurple' # Ross\n",
    "color3 = 'cornflowerblue' # eastAA\n",
    "color4 = 'black' # Weddell\n",
    "\n",
    "fs = 12\n",
    "ls = '-'\n",
    "\n",
    "ice_threshold_list2 = [100*x for x in ice_threshold_list]\n",
    "\n",
    "fig = plt.figure(figsize=(10,4))\n",
    "#plt.hlines(0,0,100,color='grey',linewidth=1.0)\n",
    "#plt.errorbar(ice_threshold_list,avg_amundsen,yerr=std_amundsen)\n",
    "plt.plot(ice_threshold_list2,100*avg_weddell,'o',color=color4,linestyle=ls,label='Weddell')\n",
    "plt.plot(ice_threshold_list2,100*avg_ross,'o',color=color2,linestyle=ls,label='Ross')\n",
    "plt.plot(ice_threshold_list2,100*avg_amundsen,'o',color=color1,linestyle=ls,label='Amundsen')\n",
    "plt.plot(ice_threshold_list2,100*avg_eastAA,'o',color=color3,linestyle=ls,label='east AA')\n",
    "plt.ylabel('difference in trajectory length in %\\n(known vs. unknown position under ice)',fontsize=fs)\n",
    "plt.xlabel('ice threshold in %\\n(position is unknown whenever ice cover exceeds threshold)',fontsize=fs)\n",
    "plt.xticks([0,20,40,60,80,100],[0,20,40,60,80,100],fontsize=fs)\n",
    "plt.yticks(fontsize=fs)\n",
    "plt.xlim((0,100))\n",
    "plt.ylim((0,45))\n",
    "plt.legend(frameon=True)\n",
    "plt.grid()\n",
    "save_plots = True\n",
    "if save_plots:\n",
    "    dpicnt = 200\n",
    "    filename = 'Difference_trajectory_length_6year_run_different_regions_v2.png'\n",
    "    plt.savefig(savepath+filename,dpi = dpicnt, bbox_inches='tight',format='png')#,transparent=True)\n",
    "plt.show()\n",
    "\n",
    "plot_eps = True\n",
    "if plot_eps:\n",
    "    fig = plt.figure(figsize=(10,4))\n",
    "    #plt.hlines(0,0,100,color='grey',linewidth=1.0)\n",
    "    #plt.errorbar(ice_threshold_list,avg_amundsen,yerr=std_amundsen)\n",
    "    plt.plot(ice_threshold_list2,100*avg_weddell,'o',color=color4,linestyle=ls,label='Weddell')\n",
    "    plt.plot(ice_threshold_list2,100*avg_ross,'o',color=color2,linestyle=ls,label='Ross')\n",
    "    plt.plot(ice_threshold_list2,100*avg_amundsen,'o',color=color1,linestyle=ls,label='Amundsen')\n",
    "    plt.plot(ice_threshold_list2,100*avg_eastAA,'o',color=color3,linestyle=ls,label='east AA')\n",
    "    #plt.ylabel('difference in trajectory length in %\\n(known vs. unknown position under ice)',fontsize=fs)\n",
    "    #plt.xlabel('ice threshold in %\\n(position is unknown whenever ice cover exceeds threshold)',fontsize=fs)\n",
    "    plt.xticks([0,20,40,60,80,100],[],fontsize=fs)\n",
    "    plt.yticks([0,5,10,15,20,25,30,35,40,45],[],fontsize=fs)\n",
    "    plt.yticks(fontsize=fs)\n",
    "    plt.xlim((0,100))\n",
    "    plt.ylim((0,45))\n",
    "    plt.legend(frameon=True)\n",
    "    plt.grid()\n",
    "    save_plots = True\n",
    "    if save_plots:\n",
    "        dpicnt = 200\n",
    "        filename = 'Difference_trajectory_length_6year_run_different_regions_v2.eps'\n",
    "        plt.savefig(savepath3+filename,dpi = dpicnt, bbox_inches='tight',format='eps')#,transparent=True)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed502bc9-ddf9-47c0-a180-5175274a4b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fa85d6-8536-48c2-8337-08c750c7f2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#-----\n",
    "# for the locations under ice, how many model grid cells are passed?\n",
    "#  colocate each trajectory with closest model grid cell, count how many unique grid cells exist\n",
    "# \n",
    "# divide into sectors (based on lat/lon on day 1): \n",
    "#   1) Ross/Amundsen/Bellinghausen (western border: 160E, eastern border: 60W)\n",
    "#   2) Weddell Sea (western border: 60W, eastern border: 30E)\n",
    "#   3) east Antarctic (western border: 30E, eastern border: 160E)\n",
    "#\n",
    "\n",
    "# things one can look at (with a longer run at higher resolution):\n",
    "#    IAV\n",
    "#    impact of linear interpolation on tracer distributions\n",
    "\n",
    "print(area.shape)\n",
    "print(lat.shape,lon.shape)\n",
    "\n",
    "print(lat_all_ice_corr.shape,lon_all_ice_corr.shape)\n",
    "\n",
    "# go through each year and float\n",
    "\n",
    "# reduce model grid to Southern Ocean (much fewer grid cells to check)\n",
    "ind_lat = np.where(lat<=-48)[0]\n",
    "\n",
    "lat_rad = [radians(x) for x in lat[ind_lat]]\n",
    "lon_rad = [radians(x) for x in lon[ind_lat]]\n",
    "        \n",
    "unique_cells = np.zeros([lon_all_ice_corr.shape[0],lon_all_ice_corr.shape[2]])\n",
    "for yy in range(0,lon_all_ice_corr.shape[0]):\n",
    "    for nn in tqdm(range(0,lon_all_ice_corr.shape[2])):\n",
    "        aux1 = lat_all_ice_corr[yy,:,nn]\n",
    "        aux2 = lon_all_ice_corr[yy,:,nn]\n",
    "        ind_NaN = np.where(np.isnan(aux1))[0]\n",
    "        #print(ind_NaN.shape)\n",
    "        \n",
    "        lat_under_ice = lat_all_SO[yy,ind_NaN,nn]\n",
    "        lon_under_ice = lon_all_SO[yy,ind_NaN,nn]\n",
    "        #print(lat_under_ice.shape)\n",
    "        \n",
    "        index_closest_node, distance_closest_node = get_closest_grid_point_vector(lon_under_ice, lat_under_ice,\\\n",
    "                                                                                  lon_rad, lat_rad)\n",
    "        \n",
    "        unique_cells[yy,nn] = int(np.unique(index_closest_node).shape[0])\n",
    "        #print(unique_cells[yy,nn])\n",
    "        \n",
    "        del index_closest_node, distance_closest_node,lat_under_ice,lon_under_ice,aux1,aux2,ind_NaN\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06a6ecd-97f4-41d1-ba0a-fe1c13f3964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(index_closest_node)\n",
    "print(unique_cells.shape,np.min(unique_cells),np.max(unique_cells))\n",
    "\n",
    "data_mean = np.mean(unique_cells,axis=0)\n",
    "data_max  = np.max(unique_cells,axis=0)\n",
    "print(data_max.shape)\n",
    "\n",
    "v1,v2=1,15\n",
    "\n",
    "fig = plt.figure(figsize=(18,3))\n",
    "plt.plot(np.arange(0,data_mean.shape[0]),data_mean,'b')\n",
    "plt.plot(np.arange(0,data_max.shape[0]),data_max,'ko')\n",
    "plt.show()\n",
    "\n",
    "#fig = plt.figure(figsize=(10,5))\n",
    "#plt.pcolor(unique_cells,vmin=v1,vmax=v2,cmap=plt.cm.RdYlBu_r)\n",
    "#plt.colorbar()\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12b794e-2923-4e78-99e5-9fefdd8888e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc34ad29-86e6-430a-ab4d-7d3a9d574852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---\n",
    "# plot on a map\n",
    "#---\n",
    "\n",
    "fs = 10\n",
    "projection=ccrs.SouthPolarStereo()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 9))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=projection)\n",
    "#ax.set_extent([-100, 30, -80, -60]) # Weddell Sea\n",
    "#ax.set_extent([-220, -120, -85, -60]) # Ross Sea\n",
    "#ax.set_extent([-170, -150, -76, -70])\n",
    "ax.set_extent([-280, 80, -80, -60], crs=ccrs.PlateCarree())\n",
    "ax.add_feature(cartopy.feature.LAND,facecolor=(\"grey\"))\n",
    "ax.coastlines(resolution='50m')\n",
    "# Compute a circle in axes coordinates, which we can use as a boundary\n",
    "# for the map. We can pan/zoom as much as we like - the boundary will be\n",
    "# permanently circular.\n",
    "make_round_SO_map = True\n",
    "if make_round_SO_map:\n",
    "    theta = np.linspace(0, 2*np.pi, 100)\n",
    "    center, radius = [0.5, 0.5], 0.5\n",
    "    verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n",
    "    circle = mpath.Path(verts * radius + center)\n",
    "    ax.set_boundary(circle, transform=ax.transAxes)\n",
    "\n",
    "for ff in range(0,ind_high_devition.shape[0]):\n",
    "    \n",
    "    aux1 = lat_all_SO[:,ind_high_devition[ff]]\n",
    "    aux2 = lon_all_SO[:,ind_high_devition[ff]]\n",
    "    \n",
    "    aux3 = lat_all_ice_corr[:,ind_high_devition[ff]]\n",
    "    aux4 = lon_all_ice_corr[:,ind_high_devition[ff]]\n",
    "    \n",
    "    ind_NaN = np.where(np.isnan(aux3))[0]\n",
    "    ind_noNaN = np.where(~np.isnan(aux3))[0]\n",
    "    \n",
    "    mm=ax.plot(aux2[ind_noNaN],aux1[ind_noNaN],'k',marker='o',linestyle=None,transform=ccrs.PlateCarree()) # in open water\n",
    "    mm=ax.plot(aux2[ind_NaN],aux1[ind_NaN],color_list[ff],marker='x',linestyle='none',transform=ccrs.PlateCarree()) # under ice\n",
    "\n",
    "if make_round_SO_map:\n",
    "    gl=ax.gridlines(crs=ccrs.PlateCarree(),draw_labels=True,linewidth=.5,\\\n",
    "                    color='grey', alpha=0.8,linestyle='--')#,xlabels_bottom=True)\n",
    "    gl.top_labels = True\n",
    "    gl.bottom_labels = True\n",
    "    gl.left_labels = True\n",
    "    gl.right_labels=True\n",
    "    #gl.xlines = True\n",
    "    gl.xlocator = mticker.FixedLocator([-180,-120,-60,0,60,120]) \n",
    "    gl.ylocator = mticker.FixedLocator([-65,-45])\n",
    "    #gl.ylocator = LatitudeLocator()\n",
    "    gl.xformatter = LongitudeFormatter()\n",
    "    gl.yformatter = LatitudeFormatter()\n",
    "    gl.rotate_labels = False\n",
    "\n",
    "save_plots = False\n",
    "\n",
    "if save_plots:\n",
    "    dpicnt = 200\n",
    "    filename = 'Map_trajectory_length_SO_only_ice_threshold_'+str(100*ice_threshold)+'_example_'+str(counter)+'.png'\n",
    "    plt.savefig(savepath+filename,dpi = dpicnt, bbox_inches='tight',format='png')#,transparent=True)\n",
    "    \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed2daa1-ade6-4a7d-8431-9ec3ce1197ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73360d9f-9d99-47c9-b161-a626e772bfe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv-jupyter",
   "language": "python",
   "name": "myenv-jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
