{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "816a8784-8c24-4bb5-b790-052766d66fa8",
   "metadata": {},
   "source": [
    "\n",
    "# work with example float output\n",
    "# deep-ocean water-mass properties\n",
    "\n",
    "# v2: sample every ten days with floats\n",
    "\n",
    "# Fig. 7 in GMD paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "860ad28a-7d61-4bd1-ab78-71fc1ca51b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('/global/homes/c/cnissen/scripts/seawater-3.3.4/seawater/')\n",
    "sys.path.append(\"/global/homes/c/cnissen/scripts/python_gsw_py3/\")\n",
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seawater\n",
    "#from seawater import dist\n",
    "import seawater as sw\n",
    "import matplotlib.path as mpath\n",
    "from cartopy.util import add_cyclic_point\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.ticker as mticker\n",
    "from cartopy.mpl.ticker import (LongitudeFormatter, LatitudeFormatter,\n",
    "                                LatitudeLocator)\n",
    "import random\n",
    "from numba import njit\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "from gsw import rho # rho from SA, CT, p\n",
    "from gsw import pt0_from_t # potTemp from SA, t, p (at reference pressure 0)\n",
    "from gsw import pt_from_t # potTemp from SA, t, p and reference pressure\n",
    "from gsw import pot_rho_t_exact # potRho from SA, t, p and reference pressure\n",
    "from gsw import p_from_z # get pressure from z and lat\n",
    "#from gsw import sigma0_pt0_exact\n",
    "from gsw import SA_from_SP\n",
    "from tqdm import tqdm\n",
    "from statsmodels.stats.weightstats import DescrStatsW\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbc915e7-ae0f-47f0-afc8-a8406aa85d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----\n",
    "# saving plots\n",
    "#-----\n",
    "\n",
    "savepath     = '/global/cfs/cdirs/m4003/cnissen/Plots/E3SM_floats/deep_ocean_properties_10_daily_sampling/'\n",
    "# check existence of paths\n",
    "if not os.path.exists(savepath):\n",
    "    print ('Created '+savepath)\n",
    "    os.makedirs(savepath)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c7bab27-fab0-4496-b9df-e997f936bd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236853 nodes in mesh\n",
      "(236853,)\n",
      "(236853,)\n",
      "Min/Max lon: 0.0007300572350528742 359.997672445938\n",
      "Min/Max lat: -78.53259417674468 89.94461290099375\n",
      "layerThickness.shape: (1, 236853, 60)\n",
      "restingThickness.shape: (236853, 60)\n",
      "Average below depth level 45 2074.8740234375005\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "# specifics for trajectory output\n",
    "####\n",
    "\n",
    "rad_to_deg = 180.0/np.pi\n",
    "latlim = -45.0\n",
    "\n",
    "path_mesh = '/global/cfs/cdirs/m4003/maltrud/'\n",
    "meshID = 'EC30to60E2r2'\n",
    "meshfile = xr. open_dataset(path_mesh+'ocean.'+meshID+'.210210.nc')\n",
    "#print(meshfile)\n",
    "\n",
    "lon  = meshfile['lonCell'].values*rad_to_deg\n",
    "lat  = meshfile['latCell'].values*rad_to_deg\n",
    "topo = meshfile['bottomDepth'].values\n",
    "area = meshfile['areaCell'].values\n",
    "zlevs            = meshfile['refBottomDepth'].values\n",
    "layerThickness   = meshfile['layerThickness'].values\n",
    "restingThickness = meshfile['restingThickness'].values\n",
    "\n",
    "print(len(lon),'nodes in mesh')\n",
    "print(topo.shape)\n",
    "print(area.shape)\n",
    "print('Min/Max lon:',np.min(lon),np.max(lon))\n",
    "print('Min/Max lat:',np.min(lat),np.max(lat))\n",
    "print('layerThickness.shape:',layerThickness.shape)\n",
    "print('restingThickness.shape:',restingThickness.shape)\n",
    "\n",
    "meshfile.close()\n",
    "\n",
    "dd1 = np.argmin(np.abs(zlevs-2000))\n",
    "print('Average below depth level',dd1,zlevs[dd1])\n",
    "dz = np.diff(np.hstack((0,zlevs)))[dd1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24f7a91f-2838-4bf5-8917-ce77760ecb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load year 0055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [01:10<05:52, 70.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load year 0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [02:24<04:50, 72.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load year 0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [03:45<03:48, 76.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load year 0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [05:02<02:33, 76.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load year 0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [06:18<01:16, 76.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load year 0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [07:35<00:00, 75.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#----\n",
    "# load daily float output\n",
    "#----\n",
    "\n",
    "# only store data below XXm\n",
    "\n",
    "path = '/global/cfs/cdirs/m4003/maltrud/6year/floats/'\n",
    "year_list = ['0055','0056','0057','0058','0059','0060']\n",
    "\n",
    "for yy in tqdm(range(0,len(year_list))):\n",
    "    print('Load year '+year_list[yy])\n",
    "    file1 = 'floats.year'+year_list[yy]+'.nc'   \n",
    "    data = xr. open_dataset(path+file1)\n",
    "\n",
    "    lon_1   = data['particleColumnLon'] #.values*rad_to_deg \n",
    "    lat_1   = data['particleColumnLat'] #.values*rad_to_deg \n",
    "    temp_1  = data['particleColumnTemperature'] #.values \n",
    "    salt_1  = data['particleColumnSalinity'] #.values\n",
    "    oxy_1   = data['particleColumnO2'] #.values\n",
    "    #print('lat_all',lat_all.shape)\n",
    "\n",
    "  #  # set missing values to NaN (deep ocean layers) \n",
    "  #  lat_1[temp_1==-1]=np.nan\n",
    "  #  lon_1[temp_1==-1]=np.nan\n",
    "  #  temp_1[temp_1==-1]=np.nan\n",
    "  #  salt_1[salt_1==-1]=np.nan\n",
    "    \n",
    "    if yy==0: # first time\n",
    "        lat_all = lat_1[:,0,:].values*rad_to_deg \n",
    "        lon_all = lon_1[:,0,:].values*rad_to_deg \n",
    "        temp_all = temp_1[:,dd1:,:].values\n",
    "        salt_all = salt_1[:,dd1:,:].values\n",
    "        oxy_all  = oxy_1[:,dd1:,:].values\n",
    "    else:\n",
    "        lat_all = np.concatenate((lat_all,lat_1[:,0,:].values*rad_to_deg))\n",
    "        lon_all = np.concatenate((lon_all,lon_1[:,0,:].values*rad_to_deg))\n",
    "        temp_all = np.concatenate((temp_all,temp_1[:,dd1:,:].values))\n",
    "        salt_all = np.concatenate((salt_all,salt_1[:,dd1:,:].values))\n",
    "        oxy_all  = np.concatenate((oxy_all,oxy_1[:,dd1:,:].values))\n",
    "        \n",
    "    del lon_1,lat_1,temp_1,salt_1,oxy_1\n",
    "    \n",
    "# set missing values to NaN (deep ocean layers) \n",
    "temp_all[salt_all==-1]=np.nan # use salt here just in case temp accidentally is exactly -1 somewhere\n",
    "salt_all[salt_all==-1]=np.nan\n",
    "oxy_all[oxy_all==-1]=np.nan\n",
    "\n",
    "# the part below is just to make sure there is no random zeros in the fields...\n",
    "temp_all[salt_all==0]=np.nan # use salt\n",
    "salt_all[salt_all==0]=np.nan\n",
    "oxy_all[oxy_all==0]=np.nan\n",
    "\n",
    "print ('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4317fcc9-0625-42dd-b9e0-5a580a4e64eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---\n",
    "# functions\n",
    "#---\n",
    "\n",
    "@njit\n",
    "def get_avg_biomess_per_day(phyC_int_mean,num_profiles,days,phyC_int):\n",
    "    # get average for each day over all floats\n",
    "    for dd in range(1,phyC_int_mean.shape[0]+1):\n",
    "        ind = np.where(days==dd)[0]\n",
    "        num_profiles[dd-1] = ind.shape[0]\n",
    "        phyC_int_mean[dd-1] = np.mean(phyC_int[ind])\n",
    "        #del ind\n",
    "    return phyC_int_mean,num_profiles\n",
    "\n",
    "@njit\n",
    "def get_vertical_avg(data,dz,data_avg):\n",
    "    # get vertical average of a property (e.g., average temperature below 2000m)\n",
    "    # assumed format: time x floats\n",
    "    # pass initialized resulting array to the function\n",
    "    for tt in range(0,data.shape[0]):\n",
    "        for nn in range(0,data.shape[2]):\n",
    "            aux = data[tt,:,nn]\n",
    "            #ind_not_nan = np.where(~np.isnan(aux))[0]  # njit does not like NaNs\n",
    "            ind_not_nan = np.where(aux>-990)[0]\n",
    "            if len(ind_not_nan)>0:\n",
    "                data_avg[tt,nn] = np.sum(aux[ind_not_nan]*dz[ind_not_nan])/np.sum(dz[ind_not_nan])\n",
    "    return data_avg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2b7b899-b5df-42a9-806f-99531d3915c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(219, 10560) (219, 15, 10560)\n",
      "shape, min, max (219, 10560) -0.8824534171210164 20.780603408813477\n",
      "shape, min, max (219, 10560) 34.0919189453125 40.02397537231445\n",
      "shape, min, max (219, 10560) 5.040485382080078 301.62677001953125\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#---\n",
    "# reduce to 10-daily data\n",
    "#---\n",
    "\n",
    "temp10  = temp_all[::10,:,:]\n",
    "salt10  = salt_all[::10,:,:]\n",
    "oxy10   = oxy_all[::10,:,:]\n",
    "lat10   = lat_all[::10,:]\n",
    "lon10   = lon_all[::10,:]\n",
    "print (lat10.shape,temp10.shape)\n",
    "#\n",
    "##----\n",
    "## get average temperature below e.g. 2000m\n",
    "##----\n",
    "dz = np.diff(np.hstack((0,zlevs)))[dd1:] # add a zero to vector; assume zlevs to give depth at the bottom\n",
    "temp10[np.isnan(temp10)] = -999 # njit does not like NaNs\n",
    "temp10[temp10==0] = -999\n",
    "temp10_avg = np.ones([temp10.shape[0],temp10.shape[2]]) # initialize array to pass to function\n",
    "temp10_avg = get_vertical_avg(temp10,dz,temp10_avg) # get avg temp\n",
    "temp10_avg[temp10_avg==1]=np.nan # NaN -> areas shallower than 2000m\n",
    "print('shape, min, max',temp10_avg.shape,np.nanmin(temp10_avg),np.nanmax(temp10_avg))\n",
    "\n",
    "salt10[np.isnan(salt10)] = -999 # njit does not like NaNs\n",
    "salt10[salt10==0] = -999\n",
    "salt10_avg = np.ones([salt10.shape[0],salt10.shape[2]]) # initialize array to pass to function\n",
    "salt10_avg = get_vertical_avg(salt10,dz,salt10_avg) # get avg temp\n",
    "salt10_avg[salt10_avg==1]=np.nan # NaN -> areas shallower than 2000m\n",
    "print('shape, min, max',salt10_avg.shape,np.nanmin(salt10_avg),np.nanmax(salt10_avg))\n",
    "\n",
    "oxy10[np.isnan(oxy10)] = -999 # njit does not like NaNs\n",
    "oxy10[oxy10==0] = -999\n",
    "oxy10_avg = np.ones([oxy10.shape[0],oxy10.shape[2]]) # initialize array to pass to function\n",
    "oxy10_avg = get_vertical_avg(oxy10,dz,oxy10_avg) # get avg temp\n",
    "oxy10_avg[oxy10_avg==1]=np.nan # NaN -> areas shallower than 2000m\n",
    "print('shape, min, max',oxy10_avg.shape,np.nanmin(oxy10_avg),np.nanmax(oxy10_avg))\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29dd9f50-2000-4604-b33c-99bbdbf035ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min/Max mask_e3sm_all_regions: 0.0 27.0\n",
      "(236853,) (236853,) (236853,)\n"
     ]
    }
   ],
   "source": [
    "#----\n",
    "# load mask of biomes\n",
    "#----\n",
    "\n",
    "path_mask = '/global/cfs/cdirs/m4003/cnissen/masks/'\n",
    "file_mask = 'reccap_mask_regions_e3sm_mesh_EC30to60E2r2_wSubregions.nc'\n",
    "\n",
    "ff = xr. open_dataset(path_mask+file_mask)\n",
    "mask_global=ff['mask_e3sm_all_regions'].values.squeeze()\n",
    "ff.close()\n",
    "\n",
    "#subareas = ['Atlantic','Pacific','Indian','Arctic','SouthernOcean']\n",
    "#subareas = ['Atlantic','Pacific','Indian','Arctic','STSS','SPSS','ICE']\n",
    "\n",
    "print('Min/Max mask_e3sm_all_regions:',np.min(mask_global),np.max(mask_global)) \n",
    "\n",
    "print(mask_global.shape,lat.shape,lon.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56fb9575-f350-4799-a824-772fcd0642b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load year 0055\n",
      "Load year 0056\n",
      "Load year 0057\n",
      "Load year 0058\n",
      "Load year 0059\n",
      "Load year 0060\n",
      "(2183, 10560)\n",
      "Min/Max index biomes: (2183, 10560) 0.0 27.0\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "#---\n",
    "# load file in which profiles are colocated with biomes\n",
    "#---\n",
    "\n",
    "path_biome = '/global/cfs/cdirs/m4003/cnissen/6year_run/'\n",
    "year_list = ['0055','0056','0057','0058','0059','0060']\n",
    "\n",
    "for yy in range(0,len(year_list)):\n",
    "    print('Load year '+year_list[yy])\n",
    "    \n",
    "    file_biome = 'Float_positions_colocated_with_biomes_year'+year_list[yy]+'_v2.nc' # v2 (July20023) has a bug fix for colocation\n",
    "    ff = xr.open_dataset(path_biome+file_biome)\n",
    "\n",
    "    mask1=ff['biome_index'].values.squeeze()\n",
    "    \n",
    "    if yy==0: # first time\n",
    "        mask_biomes_all = mask1\n",
    "    else:\n",
    "        mask_biomes_all = np.concatenate((mask_biomes_all,mask1))\n",
    "        \n",
    "print(mask_biomes_all.shape)\n",
    "\n",
    "print('Min/Max index biomes:',mask_biomes_all.shape,np.min(mask_biomes_all),np.max(mask_biomes_all))\n",
    "\n",
    "#\"1.NA SPSS, 2.NA STSS, 3.NA STPS, 4.AEQU, 5.SA STPS, 6.MED (not in FM14)\" ;\n",
    "#\"7.IND STPS, 8.(not in FM14)\" ;\n",
    "#\"9.NP SPSS, 10.NP STSS, 11.NP STPS, 12.PEQU-W, 13.PEQU-E, 14.SP STPS\" ;\n",
    "#\"15.ARCTIC ICE (not in FM14), 16.NP ICE, 17.NA ICE, 18.Barents (not in FM14)\" ;\n",
    "#\"19. STSS_Atl, 20. SPSS_Atl, 21. ICE_Atl, 22. STSS_Ind, 23. SPSS_Ind, \n",
    "# 24. ICE_Ind, 25. STSS_Pac, 26. SPSS_Pac, 27. ICE_Pac\"\n",
    "\n",
    "subareas = ['NA_SPSS','NA_STSS','NA_STPS','AEQU','SA_STPS','MED',\\\n",
    "           'IND_STPS','xx',\\\n",
    "           'NA_SPSS','NP_STSS','NP_STPS','PEQU-W','PEQU-E','SP_STPS',\\\n",
    "           'ARTIC_ICE','NP_ICE','NA_ICE','Barents',\\\n",
    "           'STSS_Atl','SPSS_ATL','ICE_ATL','STSS_IND','SPSS_IND',\\\n",
    "            'ICE_IND','STSS_PAC','SPSS_PAC','ICE_PAC']\n",
    "print(len(subareas))   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a59418bd-d5e3-4a09-8080-9d55019cad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---\n",
    "# get average within each subarea\n",
    "#---\n",
    "old_code = False\n",
    "if old_code:\n",
    "    #subregions = ['global','ICE_south','SPSS_south','STSS_south','STPS_south',\\\n",
    "    #              'Equator',\n",
    "    #              'STPS_north','STSS_north','SPSS_north','ICE_north']\n",
    "    subregions = ['global','ICE_south','SPSS_south','STSS_south','STPS_south',\\\n",
    "                  'Equator',\n",
    "                  'STPS_north','STSS_north','SPSS_north','NA_SPSS']\n",
    "\n",
    "    save_plots = False\n",
    "    display_plots = True\n",
    "\n",
    "    # DOUBLE-CHECK THE ORDER -> I had indices 4,12,14 for equator, but I think it should be 4,12,13\n",
    "\n",
    "    #\"1.NA SPSS, 2.NA STSS, 3.NA STPS, 4.AEQU, 5.SA STPS, 6.MED (not in FM14)\" ;\n",
    "    #\"7.IND STPS, 8.(not in FM14)\" ;\n",
    "    #\"9.NP SPSS, 10.NP STSS, 11.NP STPS, 12.PEQU-W, 13.PEQU-E, 14.SP STPS\" ;\n",
    "    #\"15.ARCTIC ICE (not in FM14), 16.NP ICE, 17.NA ICE, 18.Barents (not in FM14)\" ;\n",
    "    #\"19. STSS_Atl, 20. SPSS_Atl, 21. ICE_Atl, 22. STSS_Ind, 23. SPSS_Ind, \n",
    "    # 24. ICE_Ind, 25. STSS_Pac, 26. SPSS_Pac, 27. ICE_Pac\"\n",
    "\n",
    "    data_sub = np.zeros([temp10_avg.shape[0],len(subregions)])\n",
    "    for ss in range(0,len(subregions)):\n",
    "        which_region = subregions[ss]\n",
    "        print(which_region)\n",
    "\n",
    "        for tt in range(0,temp10_avg.shape[0]): # loop over time (10-daily)\n",
    "\n",
    "            mask_biomes = mask_biomes_all[::10,:][tt,:]\n",
    "            #----\n",
    "            # get all data in current biome\n",
    "            #----\n",
    "            if which_region in ['global']: \n",
    "                ind = np.where(mask_biomes.ravel()>0)[0]\n",
    "            elif which_region in ['NA_STPS']:\n",
    "                ind = np.where(mask_biomes.ravel()==3)[0]\n",
    "            elif which_region in ['NA_SPSS']:\n",
    "                ind = np.where(mask_biomes.ravel()==1)[0]\n",
    "            elif which_region in ['ICE_south']:\n",
    "                ind = np.where((mask_biomes.ravel()==21) | (mask_biomes.ravel()==24) | (mask_biomes.ravel()==27))[0]\n",
    "            elif which_region in ['SPSS_south']:\n",
    "                ind = np.where((mask_biomes.ravel()==20) | (mask_biomes.ravel()==23) | (mask_biomes.ravel()==26))[0]\n",
    "            elif which_region in ['STSS_south']:\n",
    "                ind = np.where((mask_biomes.ravel()==19) | (mask_biomes.ravel()==22) | (mask_biomes.ravel()==25))[0]\n",
    "            elif which_region in ['STPS_south']:\n",
    "                ind = np.where((mask_biomes.ravel()==5) | (mask_biomes.ravel()==7) | (mask_biomes.ravel()==14))[0]\n",
    "            elif which_region in ['Equator']:\n",
    "                ind = np.where((mask_biomes.ravel()==4) | (mask_biomes.ravel()==12) | (mask_biomes.ravel()==13))[0]\n",
    "            elif which_region in ['STPS_north']:\n",
    "                ind = np.where((mask_biomes.ravel()==3) | (mask_biomes.ravel()==11))[0]\n",
    "            elif which_region in ['ICE_north']: # without Arctic ice!!\n",
    "                ind = np.where((mask_biomes.ravel()==16) | (mask_biomes.ravel()==17))[0]\n",
    "            elif which_region in ['SPSS_north']:\n",
    "                ind = np.where((mask_biomes.ravel()==1) | (mask_biomes.ravel()==9))[0]\n",
    "            elif which_region in ['STSS_north']:\n",
    "                ind = np.where((mask_biomes.ravel()==2) | (mask_biomes.ravel()==10))[0]\n",
    "\n",
    "            # get average below2000m-temperature for all profiles in current biome\n",
    "            temp_aux = temp10_avg[tt,:].ravel() \n",
    "            data_sub[tt,ss] = np.nanmean(temp_aux[ind])\n",
    "            del temp_aux\n",
    "            #print('min/max',np.nanmin(data),np.nanmax(data))\n",
    "\n",
    "    print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cedf0bf-6783-4a8b-bb1e-cd3aa83bba46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load year 0055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1966262/1822140920.py:50: RuntimeWarning: invalid value encountered in true_divide\n",
      "  data = np.nansum(data*dz_3d,axis=2)/np.nansum(dz_3d,axis=2)\n",
      "/tmp/ipykernel_1966262/1822140920.py:51: RuntimeWarning: invalid value encountered in true_divide\n",
      "  dataS = np.nansum(dataS*dz_3d,axis=2)/np.nansum(dz_3d,axis=2)\n",
      "/tmp/ipykernel_1966262/1822140920.py:52: RuntimeWarning: invalid value encountered in true_divide\n",
      "  dataO = np.nansum(dataO*dz_3d,axis=2)/np.nansum(dz_3d,axis=2)\n",
      " 17%|█▋        | 1/6 [00:14<01:10, 14.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load year 0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:26<00:52, 13.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load year 0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:38<00:37, 12.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load year 0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:50<00:25, 12.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load year 0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [01:02<00:12, 12.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load year 0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:14<00:00, 12.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min/Max temp: -0.8807149333742528 20.815802256266277\n",
      "Min/Max salinity: 34.091909408569336 40.03798294067383\n",
      "Min/Max oxygen: 5.04816198348999 301.51340738932294\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#-----\n",
    "# load full model output\n",
    "#-----\n",
    "\n",
    "path1 = '/global/cfs/cdirs/m4003/maltrud/6year/monthlyEulerianAverages/'\n",
    "year_list = ['0055','0056','0057','0058','0059','0060']\n",
    "\n",
    "#months = ['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "#subregions = ['global','ICE_south','SPSS_south','STSS_south','STPS_south',\\\n",
    "#              'Equator',\n",
    "#              'STPS_north','STSS_north','SPSS_north','ICE_north']\n",
    "#subregions = ['global','ICE_south','SPSS_south','STSS_south','STPS_south',\\\n",
    "#              'Equator',\n",
    "#              'STPS_north','STSS_north','SPSS_north','NA_SPSS']\n",
    "#subregions = ['SPSS_NA','STSS_NA','STPS_NA','AEQU','STPS_SA','MED',\\\n",
    "#              'STPS_IND','xx','SPSS_A','STSS_NA','STPS_NP','PEQU-W','PEQU-E','STPS_SP',\\\n",
    "#              'ICE_ARCTIC','ICE_NP','ICE_NA','Barents',\\\n",
    "#             'STSS_Atl','SPSS_Atl','ICE_Atl','STSS_Ind','SPSS_Ind',\\\n",
    "#             'ICE_Ind','STSS_Pac','SPSS_Pac','ICE_Pac']\n",
    "\n",
    "subregions = ['south_of_60S','3060N_Atl','south_of_60S_WS']\n",
    "\n",
    "for yy in tqdm(range(0,len(year_list))):\n",
    "    print('Load year',year_list[yy]) \n",
    "    \n",
    "    file1 = 'monthlyAverageEulerianFields.year'+year_list[yy]+'.nc'\n",
    "    ff = xr. open_dataset(path1+file1)\n",
    "    data=ff['timeMonthly_avg_activeTracers_temperature'] #.values.squeeze()\n",
    "    dataS=ff['timeMonthly_avg_activeTracers_salinity']\n",
    "    dataO=ff['timeMonthly_avg_ecosysTracers_O2']\n",
    "    ff.close()\n",
    "    \n",
    "    data = data[:,:,:,dd1:].values.squeeze()\n",
    "    data[data<-999] = np.nan\n",
    "    data[data==0]   = np.nan\n",
    "    \n",
    "    dataS = dataS[:,:,:,dd1:].values.squeeze()\n",
    "    dataS[dataS<-999] = np.nan\n",
    "    dataS[dataS==0]   = np.nan\n",
    "    \n",
    "    dataO = dataO[:,:,:,dd1:].values.squeeze()\n",
    "    dataO[dataO<-999] = np.nan\n",
    "    dataO[dataO==0]   = np.nan\n",
    "    \n",
    "    # 3D dz field\n",
    "    dz_3d = np.tile(dz,[12,236853,1])\n",
    "    dz_3d[np.isnan(data)] = np.nan\n",
    "    \n",
    "    # avg temp below 2000m\n",
    "    data = np.nansum(data*dz_3d,axis=2)/np.nansum(dz_3d,axis=2)\n",
    "    dataS = np.nansum(dataS*dz_3d,axis=2)/np.nansum(dz_3d,axis=2)\n",
    "    dataO = np.nansum(dataO*dz_3d,axis=2)/np.nansum(dz_3d,axis=2)\n",
    "    \n",
    "    # keep full model output (to plot maps)\n",
    "    if yy==0:\n",
    "        dataT_full = data\n",
    "        dataS_full = dataS\n",
    "        dataO_full = dataO\n",
    "    else:\n",
    "        dataT_full = dataT_full+data\n",
    "        dataS_full = dataS_full+dataS\n",
    "        dataO_full = dataO_full+dataO\n",
    "    \n",
    "    # get regional averages\n",
    "    data_std = np.zeros([data.shape[0],len(subregions)])\n",
    "    data_stdS = np.zeros([dataS.shape[0],len(subregions)])\n",
    "    data_stdO = np.zeros([dataO.shape[0],len(subregions)])\n",
    "    data_avg = np.zeros([data.shape[0],len(subregions)])\n",
    "    data_avgS = np.zeros([dataS.shape[0],len(subregions)])\n",
    "    data_avgO = np.zeros([dataO.shape[0],len(subregions)])\n",
    "    for mm in range(0,12):\n",
    "        \n",
    "        aux = data[mm,:]\n",
    "        auxS = dataS[mm,:]\n",
    "        auxO = dataO[mm,:]\n",
    "        for ss in range(0,len(subregions)):\n",
    "            which_region = subregions[ss]\n",
    "            #print('Process ',which_region)\n",
    "\n",
    "            area2 = np.copy(area)\n",
    "            area2[np.isnan(aux)] = np.nan # make sure area file has the same NaNs as data file\n",
    "            #------\n",
    "            # get indices for current region\n",
    "            if which_region in ['south_of_60S']:\n",
    "                ind_reg = np.where(lat<=-60)[0]\n",
    "                #ind_reg = np.where((lat<=-60)  & (lat>-70))[0] # test: subregion\n",
    "            elif which_region in ['3060N_Atl']:\n",
    "                #ind_reg = np.where((lat>30) & (lat<=60) & (lon>300))[0]\n",
    "                ind_reg = np.where((lat>30) & (lat<=60) & (lon>300) & (lon<=350))[0]\n",
    "            elif which_region in ['south_of_60S_WS']:\n",
    "                ind_reg = np.where((lat<=-60)  & (lon>300) & (lon<=350))[0]\n",
    "                #ind_reg = np.where((lat<=-60)  & (lat>-70))[0] # test: subregion\n",
    "            else:\n",
    "                ind_reg = np.where(mask_global.ravel()==ss+1)[0]\n",
    "    \n",
    "            weights = area2[ind_reg]/np.nansum(area2[ind_reg])\n",
    "            ind_not_NaN = np.where(~np.isnan(aux[ind_reg]))[0]\n",
    "            \n",
    "            data_std[mm,ss] = DescrStatsW(aux[ind_reg][ind_not_NaN],weights=weights[ind_not_NaN]).std \n",
    "            data_stdS[mm,ss] = DescrStatsW(auxS[ind_reg][ind_not_NaN],weights=weights[ind_not_NaN]).std \n",
    "            data_stdO[mm,ss] = DescrStatsW(auxO[ind_reg][ind_not_NaN],weights=weights[ind_not_NaN]).std \n",
    "                    \n",
    "            data_avg[mm,ss] = np.nansum(aux[ind_reg]*weights) #area2[ind_reg])/np.nansum(area2[ind_reg])\n",
    "            data_avgS[mm,ss] = np.nansum(auxS[ind_reg]*weights) #area2[ind_reg])/np.nansum(area2[ind_reg])\n",
    "            data_avgO[mm,ss] = np.nansum(auxO[ind_reg]*weights) #area2[ind_reg])/np.nansum(area2[ind_reg])\n",
    "        del aux,auxS,auxO\n",
    "        \n",
    "    if yy==0:\n",
    "        data_reg_all_std = data_std\n",
    "        data_reg_allS_std = data_stdS\n",
    "        data_reg_allO_std = data_stdO\n",
    "        \n",
    "        data_reg_all = data_avg\n",
    "        data_reg_allS = data_avgS\n",
    "        data_reg_allO = data_avgO\n",
    "    else:\n",
    "        data_reg_all_std = np.concatenate((data_reg_all_std,data_std))\n",
    "        data_reg_allS_std = np.concatenate((data_reg_allS_std,data_stdS))\n",
    "        data_reg_allO_std = np.concatenate((data_reg_allO_std,data_stdO))\n",
    "        \n",
    "        data_reg_all = np.concatenate((data_reg_all,data_avg))\n",
    "        data_reg_allS = np.concatenate((data_reg_allS,data_avgS))\n",
    "        data_reg_allO = np.concatenate((data_reg_allO,data_avgO))\n",
    "        \n",
    "    del data_avg,data,dz_3d,data_avgS,dataS,data_avgO,dataO\n",
    "    \n",
    "# normalize full output by number of years\n",
    "dataT_full = np.divide(dataT_full,len(year_list))\n",
    "dataS_full = np.divide(dataS_full,len(year_list))\n",
    "dataO_full = np.divide(dataO_full,len(year_list))\n",
    "print('Min/Max temp:',np.nanmin(dataT_full),np.nanmax(dataT_full))\n",
    "print('Min/Max salinity:',np.nanmin(dataS_full),np.nanmax(dataS_full))\n",
    "print('Min/Max oxygen:',np.nanmin(dataO_full),np.nanmax(dataO_full))\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232c1762-148d-445a-8a34-b1f7d87f6a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---\n",
    "# plot maps of Eulerian output\n",
    "#---\n",
    "from mpasview import * # Qing's library, modified by Yohei Takano, Dec, 2022\n",
    "import copy\n",
    "cmap1 = copy.copy(plt.cm.RdYlBu_r)\n",
    "cmap1.set_under('w')\n",
    "\n",
    "# Restart files\n",
    "meshroot = '/global/cfs/cdirs/m4003/maltrud/' # restart file\n",
    "meshfile = meshroot+'ocean.EC30to60E2r2.210210.nc' # EC30to60E2r2\n",
    "\n",
    "# MPAS-O input file (model output)\n",
    "inputroot = '/global/cfs/cdirs/m4003/maltrud/6year/monthlyEulerianAverages/'\n",
    "year_list = ['0055','0056','0057','0058','0059','0060']\n",
    "\n",
    "# MPAS-O mesh for EC30to60E2r2\n",
    "mpasmesh = MPASMesh(name = 'EC30to60E2r2', filepath = meshfile)\n",
    "print(mpasmesh)\n",
    "\n",
    "save_plots = True\n",
    "dpicnt = 200\n",
    "\n",
    "#---\n",
    "# TEMP\n",
    "#---\n",
    "res = 0.25\n",
    "levels = np.arange(-1, 4.5+res, res)\n",
    "cticks = [-1,0,1,2,3,4]\n",
    "\n",
    "data_plot = np.copy(dataT_full)\n",
    "data_plot = np.mean(data_plot,axis=0) # annual mean\n",
    "data_plot[data_plot==0]        = -999\n",
    "data_plot[np.isnan(data_plot)] = -999\n",
    "\n",
    "mpasomap_run1 = MPASOMap(data = data_plot, name = 'avg. T below 2000m', units = 'deg C', mesh = mpasmesh)\n",
    "\n",
    "plt.figure(figsize=(18,7))\n",
    "m = mpasomap_run1.plot(region = 'Global', levels = levels, cmap = cmap1, ptype = 'contourf',colorbar=False) # pcolor, contourf\n",
    "#plt.title('Annual mean, 2012-2017')\n",
    "if save_plots:\n",
    "    filename = 'Temperature_below_2000m_avg_2012_2017.png'\n",
    "    print(savepath+filename)\n",
    "    plt.savefig(savepath+filename,dpi = dpicnt, bbox_inches='tight')\n",
    "    del filename\n",
    "    \n",
    "#-----\n",
    "# COLORBAR: plot separately\n",
    "#-----\n",
    "print('Separate COLORBAR...')\n",
    "\n",
    "lon_reg2 = np.arange(-180,180,1)\n",
    "lat_reg2 = np.arange(-90,90,1)\n",
    "lon_reg, lat_reg = np.meshgrid(lon_reg2, lat_reg2)\n",
    "data_plot = np.zeros_like(lon_reg)\n",
    "\n",
    "height,width = 18,7\n",
    "fs = 12\n",
    "\n",
    "fig = plt.figure(figsize=(height,width))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree(central_longitude=-150))\n",
    "ax.set_extent([-180, 180, -90, 90])\n",
    "mm1=ax.contourf(lon_reg, lat_reg, data_plot,\\\n",
    "                   levels=levels,extend='both',cmap=cmap1,transform=ccrs.PlateCarree())\n",
    "cbar = plt.colorbar(mm1,ax=ax,orientation='vertical',fraction=0.075, pad=0.02,shrink=0.9,ticks=cticks)\n",
    "cbar.set_label('avg. T below 2000m',fontsize=fs-2)\n",
    "cbar.ax.tick_params(labelsize=fs-3)\n",
    "fig.gca().set_visible(False)\n",
    "if save_plots:\n",
    "    filename = 'COLORBAR_Temperature_below_2000m_avg_2012_2017.png'\n",
    "    print(savepath+filename)\n",
    "    plt.savefig(savepath+filename,dpi = dpicnt, bbox_inches='tight')\n",
    "    del filename\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(height,width))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree(central_longitude=-150))\n",
    "ax.set_extent([-180, 180, -90, 90])\n",
    "mm1=ax.contourf(lon_reg, lat_reg, data_plot,\\\n",
    "                   levels=levels,extend='both',cmap=cmap1,transform=ccrs.PlateCarree())\n",
    "cbar = plt.colorbar(mm1,ax=ax,orientation='vertical',fraction=0.075, pad=0.02,shrink=0.9,ticks=cticks)\n",
    "#cbar.set_label('avg. S below 2000m',fontsize=fs-2)\n",
    "cbar.ax.tick_params(labelsize=fs-3)\n",
    "cbar.ax.set_yticklabels(['', '', '','','',''])\n",
    "fig.gca().set_visible(False)\n",
    "if save_plots:\n",
    "    filename = 'COLORBAR_Temperature_below_2000m_avg_2012_2017.eps'\n",
    "    print(savepath+filename)\n",
    "    plt.savefig(savepath+filename,dpi = dpicnt, bbox_inches='tight',format='eps')\n",
    "    del filename\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7fdae3-a349-4695-adf6-c2471dd850ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---\n",
    "# OXYGEN\n",
    "#---\n",
    "res = 10\n",
    "levels = np.arange(0, 300+res, res)\n",
    "cticks = [0,50,100,150,200,250,300]\n",
    "\n",
    "data_plot = np.copy(dataO_full)\n",
    "data_plot = np.mean(data_plot,axis=0) # annual mean\n",
    "data_plot[data_plot==0]        = -999\n",
    "data_plot[np.isnan(data_plot)] = -999\n",
    "\n",
    "mpasomap_run1 = MPASOMap(data = data_plot, name = 'avg. O2 below 2000m', units = 'mmol m-3', mesh = mpasmesh)\n",
    "\n",
    "plt.figure(figsize=(18,7))\n",
    "m = mpasomap_run1.plot(region = 'Global', levels = levels, cmap = cmap1, ptype = 'contourf',colorbar=False) # pcolor, contourf\n",
    "#plt.title('Annual mean, 2012-2017')\n",
    "if save_plots:\n",
    "    filename = 'Oxygen_below_2000m_avg_2012_2017.png'\n",
    "    print(savepath+filename)\n",
    "    plt.savefig(savepath+filename,dpi = dpicnt, bbox_inches='tight')\n",
    "    del filename\n",
    "    \n",
    "#-----\n",
    "# COLORBAR: plot separately\n",
    "#-----\n",
    "print('Separate COLORBAR...')\n",
    "\n",
    "lon_reg2 = np.arange(-180,180,1)\n",
    "lat_reg2 = np.arange(-90,90,1)\n",
    "lon_reg, lat_reg = np.meshgrid(lon_reg2, lat_reg2)\n",
    "data_plot = np.zeros_like(lon_reg)\n",
    "\n",
    "height,width = 18,7\n",
    "fs = 12\n",
    "\n",
    "fig = plt.figure(figsize=(height,width))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree(central_longitude=-150))\n",
    "ax.set_extent([-180, 180, -90, 90])\n",
    "mm1=ax.contourf(lon_reg, lat_reg, data_plot,\\\n",
    "                   levels=levels,extend='both',cmap=cmap1,transform=ccrs.PlateCarree())\n",
    "cbar = plt.colorbar(mm1,ax=ax,orientation='vertical',fraction=0.075, pad=0.02,shrink=0.9,ticks=cticks)\n",
    "cbar.set_label('avg. O2 below 2000m',fontsize=fs-2)\n",
    "cbar.ax.tick_params(labelsize=fs-3)\n",
    "fig.gca().set_visible(False)\n",
    "if save_plots:\n",
    "    filename = 'COLORBAR_Oxygen_below_2000m_avg_2012_2017.png'\n",
    "    print(savepath+filename)\n",
    "    plt.savefig(savepath+filename,dpi = dpicnt, bbox_inches='tight')\n",
    "    del filename\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(height,width))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree(central_longitude=-150))\n",
    "ax.set_extent([-180, 180, -90, 90])\n",
    "mm1=ax.contourf(lon_reg, lat_reg, data_plot,\\\n",
    "                   levels=levels,extend='both',cmap=cmap1,transform=ccrs.PlateCarree())\n",
    "cbar = plt.colorbar(mm1,ax=ax,orientation='vertical',fraction=0.075, pad=0.02,shrink=0.9,ticks=cticks)\n",
    "#cbar.set_label('avg. S below 2000m',fontsize=fs-2)\n",
    "cbar.ax.tick_params(labelsize=fs-3)\n",
    "cbar.ax.set_yticklabels(['', '', '','','','',''])\n",
    "fig.gca().set_visible(False)\n",
    "if save_plots:\n",
    "    filename = 'COLORBAR_Oxygen_below_2000m_avg_2012_2017.eps'\n",
    "    print(savepath+filename)\n",
    "    plt.savefig(savepath+filename,dpi = dpicnt, bbox_inches='tight',format='eps')\n",
    "    del filename\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eee611-7d3f-477b-8d0f-349d8dcd2aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---\n",
    "# SALINITY\n",
    "#---\n",
    "res = 0.025\n",
    "levels = np.arange(34.5,35+res, res)\n",
    "cticks = [34.5,34.65,34.8,34.95]\n",
    "\n",
    "data_plot = np.copy(dataS_full)\n",
    "data_plot = np.mean(data_plot,axis=0) # annual mean\n",
    "data_plot[data_plot<levels[0]] = levels[0]+0.0001\n",
    "data_plot[data_plot==0]        = -999\n",
    "data_plot[np.isnan(data_plot)] = -999\n",
    "\n",
    "mpasomap_run1 = MPASOMap(data = data_plot, name = 'avg. S below 2000m', units = '', mesh = mpasmesh)\n",
    "\n",
    "plt.figure(figsize=(18,7))\n",
    "m = mpasomap_run1.plot(region = 'Global', levels = levels, cmap = cmap1, ptype = 'contourf',colorbar=False) # pcolor, contourf\n",
    "#plt.title('Annual mean, 2012-2017')\n",
    "if save_plots:\n",
    "    filename = 'Salinity_below_2000m_avg_2012_2017.png'\n",
    "    print(savepath+filename)\n",
    "    plt.savefig(savepath+filename,dpi = dpicnt, bbox_inches='tight')\n",
    "    del filename\n",
    "    \n",
    "    \n",
    "#-----\n",
    "# COLORBAR: plot separately\n",
    "#-----\n",
    "print('Separate COLORBAR...')\n",
    "cticks = [34.5,34.65,34.8,34.95]\n",
    "\n",
    "lon_reg2 = np.arange(-180,180,1)\n",
    "lat_reg2 = np.arange(-90,90,1)\n",
    "lon_reg, lat_reg = np.meshgrid(lon_reg2, lat_reg2)\n",
    "data_plot = np.zeros_like(lon_reg)\n",
    "\n",
    "height,width = 18,7\n",
    "fs = 12\n",
    "\n",
    "fig = plt.figure(figsize=(height,width))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree(central_longitude=-150))\n",
    "ax.set_extent([-180, 180, -90, 90])\n",
    "mm1=ax.contourf(lon_reg, lat_reg, data_plot,\\\n",
    "                   levels=levels,extend='both',cmap=cmap1,transform=ccrs.PlateCarree())\n",
    "cbar = plt.colorbar(mm1,ax=ax,orientation='vertical',fraction=0.075, pad=0.02,shrink=0.9,ticks=cticks)\n",
    "cbar.set_label('avg. S below 2000m',fontsize=fs-2)\n",
    "cbar.ax.tick_params(labelsize=fs-3)\n",
    "fig.gca().set_visible(False)\n",
    "if save_plots:\n",
    "    filename = 'COLORBAR_Salinity_below_2000m_avg_2012_2017.png'\n",
    "    print(savepath+filename)\n",
    "    plt.savefig(savepath+filename,dpi = dpicnt, bbox_inches='tight')\n",
    "    del filename\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(height,width))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree(central_longitude=-150))\n",
    "ax.set_extent([-180, 180, -90, 90])\n",
    "mm1=ax.contourf(lon_reg, lat_reg, data_plot,\\\n",
    "                   levels=levels,extend='both',cmap=cmap1,transform=ccrs.PlateCarree())\n",
    "cbar = plt.colorbar(mm1,ax=ax,orientation='vertical',fraction=0.075, pad=0.02,shrink=0.9,ticks=cticks)\n",
    "#cbar.set_label('avg. S below 2000m',fontsize=fs-2)\n",
    "cbar.ax.tick_params(labelsize=fs-3)\n",
    "cbar.ax.set_yticklabels(['', '', '',''])\n",
    "fig.gca().set_visible(False)\n",
    "if save_plots:\n",
    "    filename = 'COLORBAR_Salinity_below_2000m_avg_2012_2017.eps'\n",
    "    print(savepath+filename)\n",
    "    plt.savefig(savepath+filename,dpi = dpicnt, bbox_inches='tight',format='eps')\n",
    "    del filename\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1ca1007-b116-4ce8-b056-cd4a1e1fda79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "                \n",
    "plot_time_series = False\n",
    "if plot_time_series:\n",
    "    #----\n",
    "    # plot 6-year time series of below2000m-temperature\n",
    "    #----\n",
    "    #subregions = ['global','ICE_south','SPSS_south','STSS_south','STPS_south',\\\n",
    "    #              'Equator',\n",
    "    #              'STPS_north','STSS_north','SPSS_north','ICE_north']\n",
    "\n",
    "    #ind1 = subregions.index(\"STSS_north\")\n",
    "    color1 = 'darkblue'\n",
    "    color2 = 'firebrick'\n",
    "    lw = 2\n",
    "    fs = 12\n",
    "    \n",
    "    display_plots = True\n",
    "    save_plots    = False\n",
    "\n",
    "    #ind = np.where((lat10.ravel()<-60))[0]\n",
    "    #ind = np.where((lat10[0,:]>30) & (lat10[0,:]<=60) & (lon10[0,:]>300) & (lon10[0,:]<=350))[0]\n",
    "\n",
    "    data_plot = np.copy(oxy10_avg) # temp10_avg, oxy10_avg, salt10_avg\n",
    "    data_plot_euler = np.copy(data_reg_allO) # data_reg_all, data_reg_allO, data_reg_allS\n",
    "    vari = 'Oxy' # Temp, Oxy, Salt (for filename only)\n",
    "    \n",
    "    for ss in range(0,len(subregions)):\n",
    "        print(subregions[ss])\n",
    "        \n",
    "        data_sub = np.zeros([data_plot.shape[0]])\n",
    "        for tt in range(0,data_plot.shape[0]):\n",
    "            data_aux = data_plot[tt,:].ravel() \n",
    "            if subregions[ss] in ['south_of_60S']:\n",
    "                ind = np.where((lat10[tt,:]<-60))[0]\n",
    "            elif subregions[ss] in ['3060N_Atl']:\n",
    "                ind = np.where((lat10[tt,:]<60) & (lat10[tt,:]>30) & (lon10[tt,:]>300) & (lon10[tt,:]<=350) )[0]\n",
    "            elif subregions[ss] in ['south_of_60S_WS']:\n",
    "                ind = np.where((lat10[tt,:]<-60) & (lon10[tt,:]>300) & (lon10[tt,:]<=350))[0]\n",
    "            #if tt==0:\n",
    "            #    print(data_aux[ind])\n",
    "            data_sub[tt] = np.nanmean(data_aux[ind])\n",
    "            del data_aux\n",
    "\n",
    "        num_time1 = data_sub.shape[0] # how many time steps infile?\n",
    "        num_time2 = data_reg_all.shape[0]\n",
    "\n",
    "                   \n",
    "        fig = plt.figure(figsize=(10,4))\n",
    "        plt.plot(np.arange(0,num_time1,1),data_sub,color=color1,linewidth=lw,label='all floats, 10-daily')\n",
    "        plt.plot(np.arange(0,num_time1,3)[:-1],data_plot_euler[:,ss],color=color2,linewidth=lw,label='Eulerian, monthly')\n",
    "        \n",
    "        annual_ = [np.mean(data_plot_euler[0:12,ss]),np.mean(data_plot_euler[12:24,ss]),np.mean(data_plot_euler[24:36,ss]),\n",
    "                          np.mean(data_plot_euler[36:48,ss]),np.mean(data_plot_euler[48:60,ss]),np.mean(data_plot_euler[60:,ss])]\n",
    "\n",
    "        if subregions[ss] in ['south_of_60S']:\n",
    "            print('Eulerian mean, std, max-min:',np.mean(data_plot_euler[:,ss]),np.std(data_plot_euler[:,ss]),(np.max(annual_)-np.min(annual_)),\\\n",
    "                  (np.max(data_plot_euler[:,ss])-np.min(data_plot_euler[:,ss])),\\\n",
    "                  1.4/np.std(data_plot_euler[:,ss]),1.4/(np.max(annual_)-np.min(annual_)),1.4/(np.max(data_plot_euler[:,ss])-np.min(data_plot_euler[:,ss])))\n",
    "        elif subregions[ss] in ['3060N_Atl']:\n",
    "            print('Eulerian mean, std, max-min:',np.mean(data_plot_euler[:,ss]),np.std(data_plot_euler[:,ss]),(np.max(annual_)-np.min(annual_)),\\\n",
    "                  (np.max(data_plot_euler[:,ss])-np.min(data_plot_euler[:,ss])),\\\n",
    "                  3.62/np.std(data_plot_euler[:,ss]),3.62/(np.max(annual_)-np.min(annual_)),3.62/(np.max(data_plot_euler[:,ss])-np.min(data_plot_euler[:,ss])))\n",
    "        else:\n",
    "            print('Eulerian mean, std:',np.mean(data_plot_euler[:,ss]),np.std(data_plot_euler[:,ss]))\n",
    "\n",
    "        plt.xticks(np.arange(0,num_time1,365/10),[2012,2013,2014,2015,2016,2017],fontsize=fs)\n",
    "        #plt.yticks(fontsize=fs)\n",
    "        plt.ylabel('avg. below 2000 m')#,fontsize=fs) #in $^{\\circ}$C\n",
    "\n",
    "        plt.legend(frameon=False)\n",
    "        plt.annotate(subregions[ss],xy=(0.01,1.025),\\\n",
    "                    xycoords='axes fraction',fontsize=fs,fontweight='bold',ha='left',color='k')\n",
    "        dpicnt = 150\n",
    "        if save_plots:\n",
    "            filename = vari+'_below_2000m_2012_2017_Elerian_vs_all_floats_'+subregions[ss]+'.png'\n",
    "            #print(savepath+filename)\n",
    "            plt.savefig(savepath+filename,dpi = dpicnt, bbox_inches='tight')\n",
    "            del filename\n",
    "        if display_plots:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "081cdeef-1ed1-4e4d-9765-c3d6f1cbda2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3060N_Atl\n",
      "0.5043027083483196\n",
      "\n",
      "south_of_60S\n",
      "0.19029926317313084\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ss=1\n",
    "\n",
    "print(subregions[ss])\n",
    "\n",
    "annual_ = [np.mean(data_plot_euler[0:12,ss]),np.mean(data_plot_euler[12:24,ss]),np.mean(data_plot_euler[24:36,ss]),\\\n",
    "          np.mean(data_plot_euler[36:48,ss]),np.mean(data_plot_euler[48:60,ss]),np.mean(data_plot_euler[60:,ss])]\n",
    "\n",
    "print(np.max(annual_)-np.min(annual_))\n",
    "\n",
    "print('')\n",
    "\n",
    "ss=0\n",
    "\n",
    "print(subregions[ss])\n",
    "\n",
    "annual_ = [np.mean(data_plot_euler[0:12,ss]),np.mean(data_plot_euler[12:24,ss]),np.mean(data_plot_euler[24:36,ss]),\\\n",
    "          np.mean(data_plot_euler[36:48,ss]),np.mean(data_plot_euler[48:60,ss]),np.mean(data_plot_euler[60:,ss])]\n",
    "\n",
    "print(np.max(annual_)-np.min(annual_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc760bc5-fb01-4bea-a694-7ceb06407367",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898c000f-9bb5-4356-8005-3abc9d9e53a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----\n",
    "# functions to speed things up\n",
    "#----\n",
    "\n",
    "#@njit\n",
    "def get_profiles_in_region_njit(data_mask,which_region):\n",
    "    # data_mask can be 1D or 2D! (ravel() will be applied here)\n",
    "    \n",
    "    #subregions = ['SPSS_NA','STSS_NA','STPS_NA','AEQU','STPS_SA','MED',\\\n",
    "    #          'STPS_IND','xx','SPSS_NP','STSS_NP','STPS_NP','PEQU-W','PEQU-E','STPS_SP',\\\n",
    "    #          'ICE_ARCTIC','ICE_NP','ICE_NA','Barents',\\\n",
    "    #         'STSS_Atl','SPSS_Atl','ICE_Atl','STSS_Ind','SPSS_Ind',\\\n",
    "    #         'ICE_Ind','STSS_Pac','SPSS_Pac','ICE_Pac']\n",
    "    if which_region in ['SPSS_NA']:\n",
    "        ind_pos = np.where(data_mask.ravel()==1)[0]\n",
    "    elif which_region in ['STSS_NA']:\n",
    "        ind_pos = np.where(data_mask.ravel()==2)[0]\n",
    "    elif which_region in ['STPS_NA']:\n",
    "        ind_pos = np.where(data_mask.ravel()==3)[0]\n",
    "    elif which_region in ['AEQU']:\n",
    "        ind_pos = np.where(data_mask.ravel()==4)[0]\n",
    "    elif which_region in ['STPS_SA']:\n",
    "        ind_pos = np.where(data_mask.ravel()==5)[0]\n",
    "    elif which_region in ['MED']:\n",
    "        ind_pos = np.where(data_mask.ravel()==6)[0]\n",
    "    elif which_region in ['STPS_IND']:\n",
    "        ind_pos = np.where(data_mask.ravel()==7)[0]\n",
    "    elif which_region in ['xx']:\n",
    "        ind_pos = np.where(data_mask.ravel()==8)[0]\n",
    "    elif which_region in ['SPSS_NP']:\n",
    "        ind_pos = np.where(data_mask.ravel()==9)[0]\n",
    "    elif which_region in ['STSS_NP']:\n",
    "        ind_pos = np.where(data_mask.ravel()==10)[0]\n",
    "    elif which_region in ['STPS_NP']:\n",
    "        ind_pos = np.where(data_mask.ravel()==11)[0]\n",
    "    elif which_region in ['PEQU-W']:\n",
    "        ind_pos = np.where(data_mask.ravel()==12)[0]\n",
    "    elif which_region in ['PEQU-E']:\n",
    "        ind_pos = np.where(data_mask.ravel()==13)[0]\n",
    "    elif which_region in ['STPS_SP']:\n",
    "        ind_pos = np.where(data_mask.ravel()==14)[0]\n",
    "    elif which_region in ['ICE_ARCTIC']:\n",
    "        ind_pos = np.where(data_mask.ravel()==15)[0]\n",
    "    elif which_region in ['ICE_NP']:\n",
    "        ind_pos = np.where(data_mask.ravel()==16)[0]\n",
    "    elif which_region in ['ICE_NA']:\n",
    "        ind_pos = np.where(data_mask.ravel()==17)[0]\n",
    "    elif which_region in ['Barents']:\n",
    "        ind_pos = np.where(data_mask.ravel()==18)[0]\n",
    "    elif which_region in ['STSS_Atl']:\n",
    "        ind_pos = np.where(data_mask.ravel()==19)[0]\n",
    "    elif which_region in ['SPSS_Atl']:\n",
    "        ind_pos = np.where(data_mask.ravel()==20)[0]\n",
    "    elif which_region in ['ICE_Atl']:\n",
    "        ind_pos = np.where(data_mask.ravel()==21)[0]\n",
    "    elif which_region in ['STSS_Ind']:\n",
    "        ind_pos = np.where(data_mask.ravel()==22)[0]\n",
    "    elif which_region in ['SPSS_Ind']:\n",
    "        ind_pos = np.where(data_mask.ravel()==23)[0]\n",
    "    elif which_region in ['ICE_Ind']:\n",
    "        ind_pos = np.where(data_mask.ravel()==24)[0]\n",
    "    elif which_region in ['STSS_Pac']:\n",
    "        ind_pos = np.where(data_mask.ravel()==25)[0]\n",
    "    elif which_region in ['SPSS_Pac']:\n",
    "        ind_pos = np.where(data_mask.ravel()==26)[0]\n",
    "    elif which_region in ['ICE_Pac']:\n",
    "        ind_pos = np.where(data_mask.ravel()==27)[0]\n",
    "        \n",
    "    return ind_pos\n",
    "\n",
    "def get_profiles_in_region_njit_2(lat,lon,which_region):\n",
    "    # data_mask can be 1D or 2D! (ravel() will be applied here)\n",
    "    \n",
    "    # subregions = ['sout_of_60S','3060N_Atl']\n",
    "    if which_region in ['south_of_60S']:\n",
    "        ind_pos = np.where(lat<=-60)[0]\n",
    "    elif which_region in ['3060N_Atl']:\n",
    "        ind_pos = np.where((lat>30) & (lat<=60) & (lon>300))[0]\n",
    "                \n",
    "    return ind_pos\n",
    "\n",
    "def get_avg_at_each_time_with_weights(a1,a2,a3,a4,num_time,weights,vector_num_region,\\\n",
    "                                      a5,a6,which_region,\\\n",
    "                                      temp_sub_floats,salt_sub_floats,oxy_sub_floats):\n",
    "    # temp_sub_floats,salt_sub_floats,oxy_sub_floats are initialized outside of function\n",
    "    \n",
    "    for tt in range(0,num_time):\n",
    "        aux1a = a1[tt,:] # mask, random subset of floats\n",
    "        aux2a = a2[tt,:] # temp, random subset of floats\n",
    "        aux3a = a3[tt,:]\n",
    "        aux4a = a4[tt,:]\n",
    "        aux5a = a5[tt,:] # lat\n",
    "        aux6a = a6[tt,:] # lon\n",
    "        \n",
    "        for nn in range(0,weights.shape[0]): # loop over regions\n",
    "            ind = np.where(vector_num_region==nn+1)[0] # all floats in current region\n",
    "            aux1 = aux1a[ind] # mask, random subset of floats\n",
    "            aux2 = aux2a[ind] # temp, random subset of floats\n",
    "            aux3 = aux3a[ind]\n",
    "            aux4 = aux4a[ind]\n",
    "            aux5 = aux5a[ind]\n",
    "            aux6 = aux6a[ind]\n",
    "            # choose all profiles in region (some floats miht move out of the current biome at some point)\n",
    "            if which_region in ['south_of_60S','3060N_Atl']:\n",
    "                ind_pos = get_profiles_in_region_njit_2(aux5,aux6,which_region)\n",
    "            else:\n",
    "                ind_pos = get_profiles_in_region_njit(aux1,which_region)\n",
    "            #ind_pos = get_profiles_in_region_njit(aux1,which_region)\n",
    "            \n",
    "            # account for weights in averaging \n",
    "            if not np.isnan(np.nanmean(aux2[ind_pos][aux2[ind_pos]>-999])*weights[nn]):\n",
    "                temp_sub_floats[tt]=temp_sub_floats[tt]+np.nanmean(aux2[ind_pos][aux2[ind_pos]>-999])*weights[nn]\n",
    "                #print(tt,temp_sub_floats[tt])\n",
    "                # if the all values are -999, mean function returns NaN!\n",
    "                #print(aux2[ind_pos][aux2[ind_pos]>-999])\n",
    "                salt_sub_floats[tt]=salt_sub_floats[tt]+np.nanmean(aux3[ind_pos][aux3[ind_pos]>-999])*weights[nn]\n",
    "                oxy_sub_floats[tt] =oxy_sub_floats[tt]+np.nanmean(aux4[ind_pos][aux4[ind_pos]>-999])*weights[nn]\n",
    "            #del aux1,aux2,aux3,aux4,ind_pos\n",
    "    return temp_sub_floats,salt_sub_floats,oxy_sub_floats\n",
    "\n",
    "\n",
    "#@njit #(error_model=\"numpy\")\n",
    "def get_avg_at_each_time(a1,a2,a3,a4,num_time,a5,a6,which_region,temp_sub_floats,salt_sub_floats,oxy_sub_floats):\n",
    "    # temp_sub_floats,salt_sub_floats,oxy_sub_floats are initialized outside of function\n",
    "    \n",
    "    for tt in range(0,num_time):\n",
    "        aux1 = a1[tt,:] # mask, random subset of floats\n",
    "        aux2 = a2[tt,:] # temp, random subset of floats\n",
    "        aux3 = a3[tt,:]\n",
    "        aux4 = a4[tt,:]     \n",
    "        aux5 = a5[tt,:]     \n",
    "        aux6 = a6[tt,:]     \n",
    "        #ind_pos = np.where(aux1.ravel()==nn)[0]\n",
    "        if which_region in ['south_of_60S','3060N_Atl']:\n",
    "            ind_pos = get_profiles_in_region_njit_2(aux5,aux6,which_region)\n",
    "        else:\n",
    "            ind_pos = get_profiles_in_region_njit(aux1,which_region)\n",
    "        #print(np.nanmean(aux2[ind_pos]))\n",
    "        #print(aux2[ind_pos][aux2[ind_pos]>-999].shape)\n",
    "        temp_sub_floats[tt]=np.mean(aux2[ind_pos][aux2[ind_pos]>-999]) \n",
    "        # if the all values are -999, mean function returns NaN!\n",
    "        #print(aux2[ind_pos][aux2[ind_pos]>-999])\n",
    "        salt_sub_floats[tt]=np.mean(aux3[ind_pos][aux3[ind_pos]>-999])\n",
    "        oxy_sub_floats[tt] =np.mean(aux4[ind_pos][aux4[ind_pos]>-999])\n",
    "        #del aux1,aux2,aux3,aux4,ind_pos\n",
    "    return temp_sub_floats,salt_sub_floats,oxy_sub_floats\n",
    "\n",
    "\n",
    "\n",
    "def get_avg_at_each_time_with_weights_wFreq(a1,a2,a3,a4,num_time,freq,weights,vector_num_region,\\\n",
    "                                      a5,a6,which_region,\\\n",
    "                                      temp_sub_floats,salt_sub_floats,oxy_sub_floats):\n",
    "    # temp_sub_floats,salt_sub_floats,oxy_sub_floats are initialized outside of function\n",
    "    \n",
    "    for tt in range(0,num_time):\n",
    "        if freq==30:\n",
    "            aux1a = a1[tt,:] # mask, all floats in subregion\n",
    "            aux2a = a2[tt,:] # temp, all floats in subregion\n",
    "            aux3a = a3[tt,:]\n",
    "            aux4a = a4[tt,:]\n",
    "            aux5a = a5[tt,:]\n",
    "            aux6a = a6[tt,:]\n",
    "        elif freq==10:\n",
    "            # avg float 1-3, 4-6, 7-9 etc -> only for properties; for mask/lat/lon, take info from first time entry\n",
    "            list_floats = np.arange(0,219,3)\n",
    "            \n",
    "            # there was a problem with the values: \n",
    "            # sometimes, one of the three values averaged here will be -999, so that the avg is messed up\n",
    "            # (can happen if float moves over shallower areas)\n",
    "            # make sure to set these to NaN here\n",
    "            aux1a = a1[list_floats[tt],:] # mask, all floats in subregion\n",
    "            aux1 = a2[list_floats[tt]:list_floats[tt]+3,:]\n",
    "            aux1[aux1<-99] = np.nan\n",
    "            aux2a = np.mean(aux1,axis=0) # temp, all floats in subregion\n",
    "            aux1 = a3[list_floats[tt]:list_floats[tt]+3,:]\n",
    "            aux1[aux1<-99] = np.nan\n",
    "            aux3a = np.mean(aux1,axis=0)\n",
    "            aux1 = a4[list_floats[tt]:list_floats[tt]+3,:]\n",
    "            aux1[aux1<-99] = np.nan\n",
    "            aux4a = np.mean(aux1,axis=0) \n",
    "            aux5a = a5[list_floats[tt],:]\n",
    "            aux6a = a6[list_floats[tt],:]\n",
    "       # print('subsampling, aux4a:',aux4a)\n",
    "            \n",
    "        for nn in range(0,weights.shape[0]): # loop over regions\n",
    "            ind = np.where(vector_num_region==nn+1)[0] # all floats in current region\n",
    "            aux1 = aux1a[ind] # mask, random subset of floats\n",
    "            aux2 = aux2a[ind] # temp, random subset of floats\n",
    "            aux3 = aux3a[ind]\n",
    "            aux4 = aux4a[ind]\n",
    "            aux5 = aux5a[ind]\n",
    "            aux6 = aux6a[ind]\n",
    "            # choose all profiles in region (some floats miht move out of the current biome at some point)\n",
    "            if which_region in ['south_of_60S','3060N_Atl']:\n",
    "                ind_pos = get_profiles_in_region_njit_2(aux5,aux6,which_region)\n",
    "            else:\n",
    "                ind_pos = get_profiles_in_region_njit(aux1,which_region)\n",
    "            #ind_pos = get_profiles_in_region_njit(aux1,which_region)\n",
    "            \n",
    "            # account for weights in averaging \n",
    "            if not np.isnan(np.nanmean(aux2[ind_pos][aux2[ind_pos]>-999])*weights[nn]):\n",
    "                temp_sub_floats[tt]=temp_sub_floats[tt]+np.nanmean(aux2[ind_pos][aux2[ind_pos]>-999])*weights[nn]\n",
    "                #print(tt,temp_sub_floats[tt])\n",
    "                # if the all values are -999, mean function returns NaN!\n",
    "                #print(aux2[ind_pos][aux2[ind_pos]>-999])\n",
    "                salt_sub_floats[tt]=salt_sub_floats[tt]+np.nanmean(aux3[ind_pos][aux3[ind_pos]>-999])*weights[nn]\n",
    "                oxy_sub_floats[tt] =oxy_sub_floats[tt]+np.nanmean(aux4[ind_pos][aux4[ind_pos]>-999])*weights[nn]\n",
    "            #del aux1,aux2,aux3,aux4,ind_pos\n",
    "    return temp_sub_floats,salt_sub_floats,oxy_sub_floats\n",
    "\n",
    "#----\n",
    "# error statistics\n",
    "# functions from here: https://gist.github.com/bshishov/5dc237f59f019b26145648e2124ca1c9\n",
    "#----\n",
    "\n",
    "def _error(actual: np.ndarray, predicted: np.ndarray):\n",
    "            \"\"\" Simple error \"\"\"\n",
    "            return actual - predicted\n",
    "\n",
    "def mse(actual: np.ndarray, predicted: np.ndarray):\n",
    "    \"\"\" Mean Squared Error \"\"\"\n",
    "    return np.mean(np.square(_error(actual, predicted)))\n",
    "\n",
    "def rmse(actual: np.ndarray, predicted: np.ndarray):\n",
    "    \"\"\" Root Mean Squared Error \"\"\"\n",
    "    return np.sqrt(mse(actual, predicted))\n",
    "\n",
    "def nrmse(actual: np.ndarray, predicted: np.ndarray):\n",
    "    \"\"\" Normalized Root Mean Squared Error \"\"\"\n",
    "    #print(np.var(actual))\n",
    "    return rmse(actual, predicted) / np.std(actual) #(actual.max() - actual.min())\n",
    "\n",
    "#-----\n",
    "# I added these:\n",
    "def mae(actual: np.ndarray, predicted: np.ndarray):\n",
    "    \"\"\" Mean Absolute Error \"\"\"\n",
    "    return np.mean(np.abs((_error(actual, predicted))))\n",
    "                   \n",
    "def nmae(actual: np.ndarray, predicted: np.ndarray):\n",
    "    \"\"\" normalized Mean Absolute Error \"\"\"\n",
    "    return np.mean(np.abs((_error(actual, predicted))))/np.std(actual)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3209c5c3-bdc4-46ea-b515-936fd7626b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subregions = ['SPSS_NA','STSS_NA','STPS_NA','AEQU','STPS_SA','MED',\\\n",
    "#              'STPS_IND','xx','SPSS_NP','STSS_NP','STPS_NP','PEQU-W','PEQU-E','STPS_SP',\\\n",
    "#              'ICE_ARCTIC','ICE_NP','ICE_NA','Barents',\\\n",
    "#             'STSS_Atl','SPSS_Atl','ICE_Atl','STSS_Ind','SPSS_Ind',\\\n",
    "#             'ICE_Ind','STSS_Pac','SPSS_Pac','ICE_Pac']\n",
    "subregions = ['south_of_60S','3060N_Atl']\n",
    "\n",
    "print(len(subregions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dc8a02-5d11-4164-8204-cbf75f03ea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---\n",
    "# subsample floats to target float density\n",
    "#---\n",
    "# repeat random sampling XX times\n",
    "# do for each region \n",
    "# do for each variable\n",
    "\n",
    "# if I choose too few floats, a significant fraction of the iterations could enp up being NaN\n",
    "# -> is this because a lot of the profiles could then be in too shallow areas?\n",
    "\n",
    "which_error = 'nrmse' # nmae, nrmse, rmse\n",
    "print('Use the following error metric:',which_error)\n",
    "\n",
    "#\"1.NA SPSS, 2.NA STSS, 3.NA STPS, 4.AEQU, 5.SA STPS, 6.MED (not in FM14)\" ;\n",
    "#\"7.IND STPS, 8.(not in FM14)\" ;\n",
    "#\"9.NP SPSS, 10.NP STSS, 11.NP STPS, 12.PEQU-W, 13.PEQU-E, 14.SP STPS\" ;\n",
    "#\"15.ARCTIC ICE (not in FM14), 16.NP ICE, 17.NA ICE, 18.Barents (not in FM14)\" ;\n",
    "#\"19. STSS_Atl, 20. SPSS_Atl, 21. ICE_Atl, 22. STSS_Ind, 23. SPSS_Ind, \n",
    "# 24. ICE_Ind, 25. STSS_Pac, 26. SPSS_Pac, 27. ICE_Pac\"\n",
    "\n",
    "#subregions = ['SPSS_NA','STSS_NA','STPS_NA','AEQU','STPS_SA','MED',\\\n",
    "#              'STPS_IND','xx','SPSS_NP','STSS_NP','STPS_NP','PEQU-W','PEQU-E','STPS_SP',\\\n",
    "#              'ICE_ARCTIC','ICE_NP','ICE_NA','Barents',\\\n",
    "#             'STSS_Atl','SPSS_Atl','ICE_Atl','STSS_Ind','SPSS_Ind',\\\n",
    "#             'ICE_Ind','STSS_Pac','SPSS_Pac','ICE_Pac']\n",
    "subregions = ['south_of_60S','3060N_Atl']\n",
    "\n",
    "#subregions = ['NA_SPSS']\n",
    "\n",
    "color1 = 'darkblue'\n",
    "color2 = 'cornflowerblue'\n",
    "color3 = 'firebrick'\n",
    "lw = 2\n",
    "fs = 12\n",
    "    \n",
    "def get_random_floats_1(floatID,num_floats_reduced1):\n",
    "    ind_random1 = np.random.choice(np.unique(floatID), size=num_floats_reduced1, replace=False)\n",
    "    ind_random1 = np.sort(ind_random1)\n",
    "    ind_random  = ind_random1\n",
    "    return ind_random\n",
    "\n",
    "#freq = 30 # take profiles every nn days (e.g., 30)\n",
    "freq = 10 # take profiles every nn days (e.g., 30)\n",
    "print('Use the following sampling frequency: '+str(freq)+'-daily')\n",
    "\n",
    "# get data of synthetic floats every nn days\n",
    "# later: if I want floats to sample every 10th day, don't have all of them sample on day 1, 11, 21 etc but some on 3, 13, 23 etc\n",
    "# in reality, not all floats are deployed on the same day!\n",
    "temp_nn  = temp_all[::freq,:,:]\n",
    "salt_nn  = salt_all[::freq,:,:]\n",
    "oxy_nn   = oxy_all[::freq,:,:]\n",
    "lat_nn   = lat_all[::freq,:]\n",
    "lon_nn   = lon_all[::freq,:]\n",
    "print(temp_nn.shape)\n",
    "if freq==30:\n",
    "    num_time = temp_nn.shape[0]\n",
    "elif freq==10:\n",
    "    num_time = 73 # 73 time entries when freq=30 (corresponds with Eulerian output), 219 when freq==10 -> reduce here so that error calculation works\n",
    "    # 10-daily flot values are averaged to obtain quasi-monthly estimates\n",
    "    \n",
    "#----\n",
    "# get average temperature/salinity/oxygen below e.g. 2000m\n",
    "#----\n",
    "dz = np.diff(np.hstack((0,zlevs)))[dd1:] # add a zero to vector; assume zlevs to give depth at the bottom\n",
    "\n",
    "temp_nn[np.isnan(temp_nn)] = -999 # njit does not like NaNs\n",
    "temp_nn[temp_nn==0] = -999\n",
    "temp_nn_avg = np.ones([temp_nn.shape[0],temp_nn.shape[2]]) # initialize array to pass to function\n",
    "temp_nn_avg = get_vertical_avg(temp_nn,dz,temp_nn_avg) # get avg temp\n",
    "temp_nn_avg[temp_nn_avg==1]=np.nan # NaN -> areas shallower than 2000m\n",
    "print('shape, min, max of avg temp below 2000m:',temp_nn_avg.shape,np.nanmin(temp_nn_avg),np.nanmax(temp_nn_avg))\n",
    "\n",
    "salt_nn[np.isnan(salt_nn)] = -999 # njit does not like NaNs\n",
    "salt_nn[salt_nn==0] = -999\n",
    "salt_nn_avg = np.ones([salt_nn.shape[0],salt_nn.shape[2]]) # initialize array to pass to function\n",
    "salt_nn_avg = get_vertical_avg(salt_nn,dz,salt_nn_avg) # get avg temp\n",
    "salt_nn_avg[salt_nn_avg==1]=np.nan # NaN -> areas shallower than 2000m\n",
    "print('shape, min, max of avg salinity below 2000m:',salt_nn_avg.shape,np.nanmin(salt_nn_avg),np.nanmax(salt_nn_avg))\n",
    "\n",
    "oxy_nn[np.isnan(oxy_nn)] = -999 # njit does not like NaNs\n",
    "oxy_nn[oxy_nn==0] = -999\n",
    "oxy_nn_avg = np.ones([oxy_nn.shape[0],oxy_nn.shape[2]]) # initialize array to pass to function\n",
    "oxy_nn_avg = get_vertical_avg(oxy_nn,dz,oxy_nn_avg) # get avg temp\n",
    "oxy_nn_avg[oxy_nn_avg==1]=np.nan # NaN -> areas shallower than 2000m\n",
    "print('shape, min, max of avg oxygen below 2000m:',oxy_nn_avg.shape,np.nanmin(oxy_nn_avg),np.nanmax(oxy_nn_avg))\n",
    "print('')\n",
    "\n",
    "# global target of deep-Argo of 1200 floats (converted to Mio km2 per float)\n",
    "#global_target_list = [np.sum(area)/1e12/1200]\n",
    "\n",
    "global_target_list = [np.sum(area)/1e12/1200,np.sum(area)/1e12/800,\\\n",
    "                      np.sum(area)/1e12/400]\n",
    "num_it = 10000\n",
    "    \n",
    "# in case NRMSE is chosen, both NRSME and RMSE are stored\n",
    "# (NRMSE is plotted as violin plots, avg RMSE printed into panel)\n",
    "rmse_sub_temp = np.zeros([num_it,len(subregions),len(global_target_list)])\n",
    "rmse_sub_salt = np.zeros([num_it,len(subregions),len(global_target_list)])\n",
    "rmse_sub_oxy  = np.zeros([num_it,len(subregions),len(global_target_list)])\n",
    "nrmse_sub_temp = np.zeros([num_it,len(subregions),len(global_target_list)])\n",
    "nrmse_sub_salt = np.zeros([num_it,len(subregions),len(global_target_list)])\n",
    "nrmse_sub_oxy  = np.zeros([num_it,len(subregions),len(global_target_list)])\n",
    "rmse_full_temp = np.zeros([len(subregions)])\n",
    "rmse_full_salt = np.zeros([len(subregions)])\n",
    "rmse_full_oxy  = np.zeros([len(subregions)])\n",
    "nrmse_full_temp = np.zeros([len(subregions)])\n",
    "nrmse_full_salt = np.zeros([len(subregions)])\n",
    "nrmse_full_oxy  = np.zeros([len(subregions)])\n",
    "num_floats_in_region = np.zeros([len(subregions),len(global_target_list)])\n",
    "num_floats_all_in_region = np.zeros([len(subregions)])\n",
    "for ss in range(0,len(subregions)):\n",
    "    which_region = subregions[ss]\n",
    "    print('Process',which_region)\n",
    "    \n",
    "    #----\n",
    "    # get indices in region mask on native mesh (for area)\n",
    "    #----\n",
    "    if not which_region in ['south_of_60S','3060N_Atl']:\n",
    "        ind_reg = np.where(mask_global==ss+1)[0]\n",
    "        num_regions = 1\n",
    "        indices_regions = [ss+1]\n",
    "    else:\n",
    "        if which_region in ['south_of_60S']:\n",
    "            ind_reg = np.where(lat<=-60)[0]\n",
    "        elif which_region in ['3060N_Atl']:\n",
    "            ind_reg = np.where((lat>30) & (lat<=60) & (lon>300) & (lon<=350))[0]\n",
    "        num_regions = 1\n",
    "        indices_regions = [1] # not actually used in this case, so don't couple to loop index for now\n",
    "    \n",
    "    # use mask at first time step to determine what floats I am interested in\n",
    "    mask_biomes = mask_biomes_all[::freq,:][0,:]\n",
    "\n",
    "    #----\n",
    "    # get indices in region mask for floats\n",
    "    #----\n",
    "    if which_region in ['south_of_60S']:\n",
    "        ind = np.where(lat_nn[0,:]<=-60)[0] # only based on position at day 1\n",
    "    elif which_region in ['3060N_Atl']:\n",
    "        ind = np.where((lat_nn[0,:]>30) & (lat_nn[0,:]<=60) & (lon_nn[0,:]>300) & (lon_nn[0,:]<=350))[0]\n",
    "    else:\n",
    "        ind = np.where(mask_biomes.ravel()==ss+1)[0]\n",
    "           \n",
    "    # select all floats in current region\n",
    "    temp_aux = temp_nn_avg[:,ind] # all floats in the area\n",
    "    salt_aux = salt_nn_avg[:,ind]\n",
    "    oxy_aux  = oxy_nn_avg[:,ind]\n",
    "    lat_aux  = lat_nn[:,ind]\n",
    "    lon_aux  = lon_nn[:,ind]\n",
    "    mask_aux = mask_biomes_all[::freq,ind]\n",
    "    \n",
    "    floatID = np.arange(0,temp_aux[0].shape[0],1) \n",
    "    # make sure to start from zero (this array will be used for subsampling)\n",
    "    num_floats_all_in_region[ss] = np.max(floatID)\n",
    "    #---\n",
    "    # FULL\n",
    "    #---\n",
    "    # \n",
    "    # get mean temp for full float data set\n",
    "    #\n",
    "    # get weights for current regions\n",
    "    weights_regions = np.zeros([num_regions])\n",
    "    for nn in range(0,num_regions):\n",
    "        # get indices of current region (for area)\n",
    "        #ind_reg1 = np.where((mask_global==indices_regions[nn]))[0] \n",
    "        if which_region in ['south_of_60S']:\n",
    "            ind_reg1 = np.where(lat<=-60)[0]\n",
    "        elif which_region in ['3060N_Atl']:\n",
    "            ind_reg1 = np.where((lat>30) & (lat<=60) & (lon>300) & (lon<=350))[0]\n",
    "        else:\n",
    "            ind_reg1 = np.where((mask_global==indices_regions[nn]))[0] \n",
    "    \n",
    "        weights_regions[nn] = np.sum(area[ind_reg1])/np.sum(area[ind_reg])\n",
    "    print('sum weights:',np.sum(weights_regions))  \n",
    "    \n",
    "    temp_all_floats = np.zeros([num_time])\n",
    "    salt_all_floats = np.zeros([num_time])\n",
    "    oxy_all_floats  = np.zeros([num_time])\n",
    "    for tt in range(0,num_time):\n",
    "        # before adding a weighting with area:\n",
    "        #aux1 = mask_aux[tt,:] # mask, all floats in subregion\n",
    "        #aux2 = temp_aux[tt,:] # temp, all floats in subregion\n",
    "        #aux3 = salt_aux[tt,:]\n",
    "        #aux4 = oxy_aux[tt,:]\n",
    "        #-----\n",
    "        if freq==30:\n",
    "            aux1a = mask_aux[tt,:] # mask, all floats in subregion\n",
    "            aux2a = temp_aux[tt,:] # temp, all floats in subregion\n",
    "            aux3a = salt_aux[tt,:]\n",
    "            aux4a = oxy_aux[tt,:]\n",
    "            aux5a = lat_aux[tt,:] # lat\n",
    "            aux6a = lon_aux[tt,:] # lon\n",
    "        elif freq==10:\n",
    "            # avg float 1-3, 4-6, 7-9 etc -> only for properties; for mask/lat/lon, take info from first time entry\n",
    "            list_floats = np.arange(0,219,3)\n",
    "            aux1a = mask_aux[list_floats[tt],:] # mask, all floats in subregion\n",
    "            aux2a = np.mean(temp_aux[list_floats[tt]:list_floats[tt]+3,:],axis=0) # temp, all floats in subregion\n",
    "            aux3a = np.mean(salt_aux[list_floats[tt]:list_floats[tt]+3,:],axis=0)\n",
    "            aux4a = np.mean(oxy_aux[list_floats[tt]:list_floats[tt]+3,:],axis=0)\n",
    "            aux5a = lat_aux[list_floats[tt],:] # lat\n",
    "            aux6a = lon_aux[list_floats[tt],:] # lon\n",
    "        \n",
    "        count = 0\n",
    "        for nn in indices_regions: # loop over regions\n",
    "            if which_region in ['south_of_60S']:\n",
    "                ind = np.where(aux5a<=-60)[0] \n",
    "            elif which_region in ['3060N_Atl']:\n",
    "                ind = np.where((aux5a>30) & (aux5a<=60) & (aux6a>300) & (aux6a<=350))[0]\n",
    "            else:\n",
    "                ind = np.where(aux1a==nn)[0] # all floats in current region\n",
    "            aux1 = aux1a[ind] # mask, random subset of floats\n",
    "            aux2 = aux2a[ind] # temp, random subset of floats\n",
    "            aux3 = aux3a[ind]\n",
    "            aux4 = aux4a[ind]\n",
    "            aux5 = aux5a[ind] # lat\n",
    "            aux6 = aux6a[ind] # lon\n",
    "            # choose all profiles in region (some floats might move out of the current biome at some point)\n",
    "            if which_region in ['south_of_60S']:\n",
    "                ind_pos = np.where(aux5<=-60)[0]\n",
    "            elif which_region in ['3060N_Atl']:\n",
    "                ind_pos = np.where((aux5>30) & (aux5<=60) & (aux6>300) & (aux6<=350))[0]\n",
    "            else:\n",
    "                ind_pos = np.where(aux1.ravel()==nn)[0]\n",
    "            #ind_pos = get_profiles_in_region_njit(aux1,which_region)\n",
    "            \n",
    "            aux2[np.isnan(aux2)] = -999\n",
    "            aux3[np.isnan(aux3)] = -999\n",
    "            aux4[np.isnan(aux4)] = -999\n",
    "            aux5[np.isnan(aux5)] = -999 # lat\n",
    "            aux6[np.isnan(aux6)] = -999 # lon\n",
    "            \n",
    "            #print('salt',aux3)\n",
    "            #print('temp',aux2)\n",
    "            \n",
    "            # account for weights in averaging \n",
    "            if not np.isnan(np.nanmean(aux2[ind_pos][aux2[ind_pos]>-999])*weights_regions[count]):\n",
    "                temp_all_floats[tt]=temp_all_floats[tt]+np.nanmean(aux2[ind_pos][aux2[ind_pos]>-999])*weights_regions[count]\n",
    "                # if the all values are -999, mean function returns NaN!\n",
    "                salt_all_floats[tt]=salt_all_floats[tt]+np.nanmean(aux3[ind_pos][aux3[ind_pos]>-999])*weights_regions[count]\n",
    "                oxy_all_floats[tt] =oxy_all_floats[tt]+np.nanmean(aux4[ind_pos][aux4[ind_pos]>-999])*weights_regions[count]\n",
    "            count = count+1\n",
    "            del aux1,aux2,aux3,aux4,ind_pos,ind\n",
    "        del aux1a,aux2a,aux3a,aux4a\n",
    "    del weights_regions\n",
    "        \n",
    "    print('std temp full output:',np.std(data_reg_all[:,ss]))\n",
    "    print('std salt full output:',np.std(data_reg_allS[:,ss]))\n",
    "    print('std oxy full output:',np.std(data_reg_allO[:,ss]))\n",
    "    # get rmse for full float output\n",
    "    if which_error in ['nrmse']:\n",
    "        nrmse_full_temp[ss] = nrmse(data_reg_all[:,ss],temp_all_floats[:-1])\n",
    "        nrmse_full_salt[ss] = nrmse(data_reg_allS[:,ss],salt_all_floats[:-1])\n",
    "        nrmse_full_oxy[ss]  = nrmse(data_reg_allO[:,ss],oxy_all_floats[:-1])\n",
    "        # also store RMSE to get a sense of the actual mismatch\n",
    "        rmse_full_temp[ss] = math.sqrt(np.square(np.subtract(temp_all_floats[:-1],data_reg_all[:,ss])).mean())\n",
    "        rmse_full_salt[ss] = math.sqrt(np.square(np.subtract(salt_all_floats[:-1],data_reg_allS[:,ss])).mean())\n",
    "        rmse_full_oxy[ss]  = math.sqrt(np.square(np.subtract(oxy_all_floats[:-1],data_reg_allO[:,ss])).mean())\n",
    "    elif which_error in ['rmse']:\n",
    "        rmse_full_temp[ss] = math.sqrt(np.square(np.subtract(temp_all_floats[:-1],data_reg_all[:,ss])).mean())\n",
    "        rmse_full_salt[ss] = math.sqrt(np.square(np.subtract(salt_all_floats[:-1],data_reg_allS[:,ss])).mean())\n",
    "        rmse_full_oxy[ss]  = math.sqrt(np.square(np.subtract(oxy_all_floats[:-1],data_reg_allO[:,ss])).mean())\n",
    "    elif which_error in ['nmae']:\n",
    "        rmse_full_temp[ss] = nmae(data_reg_all[:,ss],temp_all_floats[:-1])\n",
    "        rmse_full_salt[ss] = nmae(data_reg_allS[:,ss],salt_all_floats[:-1])\n",
    "        rmse_full_oxy[ss]  = nmae(data_reg_allO[:,ss],oxy_all_floats[:-1])\n",
    "    #--------\n",
    "    \n",
    "    #----\n",
    "    # SUBSAMPLE FLOATS\n",
    "    #----\n",
    "    for gg in range(0,len(global_target_list)):\n",
    "        print('Process global target density: '+str(global_target_list[gg])+' ('+str(1/(global_target_list[gg]/(np.sum(area)/1e12)))+' floats)')\n",
    "        for ii in tqdm(range(0,num_it)):\n",
    "            # use unique float IDs to determine which floats to keep/kick out\n",
    "            \n",
    "            # find out how many time steps are NaN for each float in subregion\n",
    "            # --> only consider those whoch spend more than half of the time in deep enough waters\n",
    "            # 0.5*temp_aux.shape[0] --> 16 in the case of 30-daily flaot output (16 profiles have to be filled)\n",
    "            b1 = np.sum(np.isnan(temp_aux),axis=0)\n",
    "            ind_deep_enough = np.where(b1<=(0.5*temp_aux.shape[0]))[0]\n",
    "            \n",
    "            mask_aux_new = np.copy(mask_aux)[:,ind_deep_enough]\n",
    "            temp_aux_new = np.copy(temp_aux)[:,ind_deep_enough]\n",
    "            salt_aux_new = np.copy(salt_aux)[:,ind_deep_enough]\n",
    "            oxy_aux_new  = np.copy(oxy_aux)[:,ind_deep_enough]\n",
    "            lat_aux_new  = np.copy(lat_aux)[:,ind_deep_enough]\n",
    "            lon_aux_new  = np.copy(lon_aux)[:,ind_deep_enough]\n",
    "            floatID = np.arange(0,temp_aux_new[0].shape[0],1) \n",
    "            \n",
    "            # re-define num_floats_all after reduction to profiles with sufficient data\n",
    "            num_floats_all = floatID.shape[0]\n",
    "            \n",
    "            #num_floats_reduced_list = np.zeros([num_regions])\n",
    "            try:\n",
    "                del ind_random\n",
    "            except: \n",
    "                pass\n",
    "            \n",
    "            weights_regions = np.zeros([num_regions])\n",
    "            for nn in range(0,num_regions):\n",
    "                \n",
    "                # get indices of current region (for area)\n",
    "                if which_region in ['south_of_60S']:\n",
    "                    ind_reg1 = np.where(lat<=-60)[0]\n",
    "                elif which_region in ['3060N_Atl']:\n",
    "                    ind_reg1 = np.where((lat>30) & (lat<=60) & (lon>300) & (lon<=350))[0]\n",
    "                else:\n",
    "                    ind_reg1 = np.where((mask_global==indices_regions[nn]))[0] \n",
    "                # get indices of current region in float data set\n",
    "                # take first time step of mask; later: kick out profiles not in subregion\n",
    "                if which_region in ['south_of_60S']:\n",
    "                    ind1 = np.where(lat_aux_new[0,:]<=-60)[0]\n",
    "                elif which_region in ['3060N_Atl']:\n",
    "                    ind1 = np.where((lat_aux_new[0,:]>30) & (lat_aux_new[0,:]<=60) & (lon_aux_new[0,:]>300) & (lon_aux_new[0,:]<=350))[0]\n",
    "                else:\n",
    "                    ind1     = np.where((mask_aux_new[0,:]==indices_regions[nn]))[0] \n",
    "                #print(ind1.shape)\n",
    "                \n",
    "                # get number of reduced float density in current sub-subregion\n",
    "                num_floats_red = int(np.round(np.sum(area[ind_reg1])/1e12/global_target_list[gg]))\n",
    "                #print('Region index, number of floats',indices_regions[nn],num_floats_red)\n",
    "                \n",
    "                # reduce to floats in current sub-subregion\n",
    "                temp_aux_new2 = temp_aux_new[:,ind1]\n",
    "                salt_aux_new2 = salt_aux_new[:,ind1]\n",
    "                oxy_aux_new2  = oxy_aux_new[:,ind1]\n",
    "                lat_aux_new2  = lat_aux_new[:,ind1]\n",
    "                lon_aux_new2  = lon_aux_new[:,ind1]\n",
    "                #floatID_2     = np.arange(0,temp_aux_new2[0,:].shape[0],1)\n",
    "                \n",
    "            #    print('region index / number of floats:',indices_regions[nn],num_floats_red)\n",
    "                ind_random_2 = get_random_floats_1(ind1,num_floats_red)\n",
    "                if nn==0:\n",
    "                    ind_random = ind_random_2\n",
    "                    vector_region = np.ones([ind_random_2.shape[0]])\n",
    "                else:\n",
    "                    ind_random = np.concatenate((ind_random,ind_random_2))\n",
    "                    vector_region = np.concatenate((vector_region,(nn+1)*np.ones([ind_random_2.shape[0]])))\n",
    "                weights_regions[nn] = np.sum(area[ind_reg1])/np.sum(area[ind_reg])\n",
    "                del ind1,ind_reg1,temp_aux_new2,salt_aux_new2,oxy_aux_new2,ind_random_2,num_floats_red\n",
    "            \n",
    "            # check if sum of wieghts equal 1\n",
    "            # print(np.sum(weights_regions))\n",
    "            \n",
    "            if ii==0:\n",
    "                num_floats_in_region[ss,gg] = ind_random.shape[0]\n",
    "            ind_random = np.sort(ind_random)\n",
    "            # subsampled dataset in current subregion\n",
    "            a1 = mask_aux_new[:,ind_random]\n",
    "            a2 = temp_aux_new[:,ind_random]\n",
    "            a3 = salt_aux_new[:,ind_random]\n",
    "            a4 = oxy_aux_new[:,ind_random]\n",
    "            a5 = lat_aux_new[:,ind_random]\n",
    "            a6 = lon_aux_new[:,ind_random]\n",
    "            a2[np.isnan(a2)] = -999\n",
    "            a3[np.isnan(a3)] = -999\n",
    "            a4[np.isnan(a4)] = -999\n",
    "            a5[np.isnan(a5)] = -999\n",
    "            a6[np.isnan(a6)] = -999\n",
    "            #print('a2',a2)\n",
    "            \n",
    "            #---\n",
    "            # SUBSAMPLED\n",
    "            #---\n",
    "            # loop over all time steps and store average value of subsampled\n",
    "            temp_sub_floats = np.zeros([num_time])\n",
    "            salt_sub_floats = np.zeros([num_time])\n",
    "            oxy_sub_floats  = np.zeros([num_time])\n",
    "\n",
    "            #-----\n",
    "            # in the averaging, accounting for different areas of the sub-subregions!\n",
    "            #-----\n",
    "            # DONE create an array with randomly selected floats for each sub-subregion\n",
    "            # DONE crete weights for each sub-subregion\n",
    "            # DONE pass these to function \n",
    "            # carfully double-check that this is correct!\n",
    "            \n",
    "            temp_sub_floats,salt_sub_floats,oxy_sub_floats = get_avg_at_each_time_with_weights_wFreq(a1,a2,a3,a4,\\\n",
    "                                            num_time,freq,weights_regions,vector_region,\\\n",
    "                                                a5,a6,which_region,\\\n",
    "                                                temp_sub_floats,salt_sub_floats,oxy_sub_floats)\n",
    "            #print('subsampling temp_sub_floats:',temp_sub_floats)\n",
    "            #print('subsampling salt_sub_floats:',salt_sub_floats)\n",
    "            #print('subsampling oxy_sub_floats:',oxy_sub_floats)\n",
    "            \n",
    "            #temp_sub_floats,salt_sub_floats,oxy_sub_floats = get_avg_at_each_time(a1,a2,a3,a4,\\\n",
    "            #                                num_time,temp_sub_floats,salt_sub_floats,oxy_sub_floats)\n",
    "             \n",
    "            #----\n",
    "            # get rmse or nrmse\n",
    "            #----      \n",
    "            \n",
    "            # SOME entries are zero \n",
    "            # --> randomly selected floats end up in shallow regions and are skipped in function above\n",
    "            # think carefully about how to treat them!\n",
    "            # 1st idea here: kick all misisng time entries to NaN and disregard them from nrmse calculation\n",
    "            # --> test this. Does this reduce the large errors I see for some reigons?\n",
    "            # Note that this way, time series are not always exactly 6 years long! (but I assume that the majority of \n",
    "            # time series is not affected)\n",
    "            \n",
    "            b1 = np.copy(data_reg_all[:,ss])\n",
    "            b1[temp_sub_floats[:-1]==0] = np.nan\n",
    "            temp_sub_floats[temp_sub_floats==0] = np.nan\n",
    "            \n",
    "            b2 = np.copy(data_reg_allS[:,ss])\n",
    "            b2[salt_sub_floats[:-1]==0] = np.nan\n",
    "            salt_sub_floats[salt_sub_floats==0] = np.nan\n",
    "            \n",
    "            b3 = np.copy(data_reg_allO[:,ss])\n",
    "            b3[oxy_sub_floats[:-1]==0] = np.nan\n",
    "            oxy_sub_floats[oxy_sub_floats==0]   = np.nan\n",
    "            ind_no_NaN = np.where(~np.isnan(b1))[0]\n",
    "            \n",
    "            #print(oxy_sub_floats[:-1])\n",
    "            # TEMP\n",
    "            if which_error in ['nrmse']:\n",
    "                nrmse_sub_temp[ii,ss,gg] = nrmse(b1[ind_no_NaN],temp_sub_floats[:-1][ind_no_NaN])\n",
    "                rmse_sub_temp[ii,ss,gg]  = math.sqrt(np.square(np.subtract(temp_sub_floats[:-1][ind_no_NaN],b1[ind_no_NaN])).mean())\n",
    "            elif which_error in ['rmse']:\n",
    "                rmse_sub_temp[ii,ss,gg] = math.sqrt(np.square(np.subtract(temp_sub_floats[:-1][ind_no_NaN],b1[ind_no_NaN])).mean())\n",
    "            elif which_error in ['nmae']:\n",
    "                rmse_sub_temp[ii,ss,gg] = nmae(b1[ind_no_NaN],temp_sub_floats[:-1][ind_no_NaN])\n",
    "            #if np.isnan(rmse_sub_temp[ii,ss,gg]):\n",
    "            #    print('stop due to NaN')\n",
    "            #    break\n",
    "\n",
    "            # SALT\n",
    "            if which_error in ['nrmse']:\n",
    "                nrmse_sub_salt[ii,ss,gg] = nrmse(b2[ind_no_NaN],salt_sub_floats[:-1][ind_no_NaN])\n",
    "                rmse_sub_salt[ii,ss,gg]  = math.sqrt(np.square(np.subtract(salt_sub_floats[:-1][ind_no_NaN],b2[ind_no_NaN])).mean())\n",
    "            elif which_error in ['rmse']:\n",
    "                rmse_sub_salt[ii,ss,gg] = math.sqrt(np.square(np.subtract(salt_sub_floats[:-1][ind_no_NaN],b2[ind_no_NaN])).mean())\n",
    "            elif which_error in ['nmae']:\n",
    "                rmse_sub_salt[ii,ss,gg] = nmae(b2[ind_no_NaN],salt_sub_floats[:-1][ind_no_NaN])\n",
    "                \n",
    "            # OXYGEN\n",
    "            if which_error in ['nrmse']:\n",
    "                nrmse_sub_oxy[ii,ss,gg] = nrmse(b3[ind_no_NaN],oxy_sub_floats[:-1][ind_no_NaN])\n",
    "                rmse_sub_oxy[ii,ss,gg]  = math.sqrt(np.square(np.subtract(oxy_sub_floats[:-1][ind_no_NaN],b3[ind_no_NaN])).mean())\n",
    "            elif which_error in ['rmse']:\n",
    "                rmse_sub_oxy[ii,ss,gg] = math.sqrt(np.square(np.subtract(oxy_sub_floats[:-1][ind_no_NaN],b3[ind_no_NaN])).mean())\n",
    "            elif which_error in ['nmae']:\n",
    "                rmse_sub_oxy[ii,ss,gg] = nmae(b3[ind_no_NaN],oxy_sub_floats[:-1][ind_no_NaN])\n",
    "                \n",
    "        if gg==2:\n",
    "            print('rmse sub oxy: ',np.mean(rmse_sub_oxy[:,ss,gg]))\n",
    "                \n",
    "            del b1,b2,b3,ind_no_NaN\n",
    "print('done')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a00c4f1-29eb-4b9d-9daf-4d77c9e54ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(which_error)\n",
    "\n",
    "print('oxy:',rmse_full_oxy,np.mean(rmse_sub_oxy,axis=0))\n",
    "\n",
    "print('salt:',rmse_full_salt,np.mean(rmse_sub_salt,axis=0))\n",
    "\n",
    "print('temp:',rmse_full_temp,np.mean(rmse_sub_temp,axis=0))\n",
    "\n",
    "#ind1 = np.where((lat_aux_new[0,:]>30) & (lat_aux_new[0,:]<=60) & (lon_aux_new[0,:]>300))[0]\n",
    "#print(lat_aux_new[0,:])\n",
    "#print(ind1)\n",
    "\n",
    "print(np.mean(rmse_sub_temp[:,ss,0]))\n",
    "print(np.mean(rmse_sub_salt[:,ss,0]))\n",
    "print(np.mean(rmse_sub_oxy[:,ss,0]))\n",
    "print(global_target_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dae4b5-0f74-4ab9-b65d-c4cf9e1b458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#subregions = ['SPSS_NA','STSS_NA','STPS_NA','AEQU','STPS_SA','MED',\\\n",
    "#              'STPS_IND','xx','SPSS_NP','STSS_NP','STPS_NP','PEQU-W','PEQU-E','STPS_SP',\\\n",
    "#              'ICE_ARCTIC','ICE_NP','ICE_NA','Barents',\\\n",
    "#             'STSS_Atl','SPSS_Atl','ICE_Atl','STSS_Ind','SPSS_Ind',\\\n",
    "#             'ICE_Ind','STSS_Pac','SPSS_Pac','ICE_Pac']\n",
    "\n",
    "savepath2     = savepath+str(num_it)+'iterations_'+which_error+'/'\n",
    "# check existence of paths\n",
    "if not os.path.exists(savepath2):\n",
    "    print ('Created '+savepath2)\n",
    "    os.makedirs(savepath2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5576410a-8aa6-4ea8-a258-6f9d1ae41c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---\n",
    "# plot\n",
    "#---\n",
    "from matplotlib import cm \n",
    "\n",
    "fs = 12\n",
    "\n",
    "# subsampled float data set\n",
    "ms2 = 10\n",
    "caps = 4\n",
    "\n",
    "# full float data set\n",
    "symbol_full = 's'\n",
    "ms = 6\n",
    "\n",
    "color2 = 'darkorange'\n",
    "\n",
    "nn=250\n",
    "color1a = [cm.Blues(nn)[0],cm.Blues(nn)[1],cm.Blues(nn)[2]]\n",
    "nn=190\n",
    "color1b = [cm.Blues(nn)[0],cm.Blues(nn)[1],cm.Blues(nn)[2]]\n",
    "nn=130\n",
    "color1c = [cm.Blues(nn)[0],cm.Blues(nn)[1],cm.Blues(nn)[2]]\n",
    "nn=70\n",
    "color1d = [cm.Blues(nn)[0],cm.Blues(nn)[1],cm.Blues(nn)[2]]\n",
    "\n",
    "#subregions = ['global','ICE_south','SPSS_south','STSS_south','STPS_south',\\\n",
    "#              'Equator',\n",
    "#              'STPS_north','STSS_north','SPSS_north']\n",
    "\n",
    "#subregions = ['SPSS_NA','STSS_NA','STPS_NA','AEQU','STPS_SA','MED',\\\n",
    "#              'STPS_IND','xx','SPSS_NP','STSS_NP','STPS_NP','PEQU-W','PEQU-E','STPS_SP',\\\n",
    "#              'ICE_ARCTIC','ICE_NP','ICE_NA','Barents',\\\n",
    "#             'STSS_Atl','SPSS_Atl','ICE_Atl','STSS_Ind','SPSS_Ind',\\\n",
    "#             'ICE_Ind','STSS_Pac','SPSS_Pac','ICE_Pac']\n",
    "\n",
    "save_plots = False\n",
    "display_plots = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36468f49-a7f1-49df-89d2-af5c25476568",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---\n",
    "# VIOLIN PLOTS plot each region\n",
    "#---\n",
    "\n",
    "#subregions2 = ['SPSS_NA','STSS_NA','STPS_NA','AEQU','STPS_SA',\\\n",
    "#              'STPS_IND','SPSS_NP','STSS_NP','STPS_NP','PEQU-W','PEQU-E','STPS_SP',\\\n",
    "#              'STSS_Atl','SPSS_Atl','ICE_Atl','STSS_Ind','SPSS_Ind',\\\n",
    "#             'ICE_Ind','STSS_Pac','SPSS_Pac','ICE_Pac']\n",
    "#subregions2 = ['south of 60°S','N. Atl. 30-60°N']\n",
    "subregions2 = ['south_of_60S','3060N_Atl']\n",
    "\n",
    "display_plots_png = True\n",
    "display_plots_eps = False\n",
    "save_plots = True\n",
    "plot_eps = True\n",
    "\n",
    "if len(global_target_list)>3:\n",
    "    xpos = [0.3,0.2,0.1,0]\n",
    "    xlim1,xlim2 = -0.05,0.35\n",
    "    width,height = 3,3\n",
    "else:\n",
    "    xpos = [0.2,0.1,0]\n",
    "    xlim1,xlim2 = -0.05,0.25\n",
    "    width,height = 2,3\n",
    "    width2,height2 = 3.2,3\n",
    "    \n",
    "for rr in range(0,len(subregions2)):\n",
    "    print(subregions2[rr])\n",
    "    which_region = subregions2[rr]\n",
    "    ss = subregions.index(subregions2[rr])\n",
    "    #---\n",
    "    # TEMP\n",
    "    #---\n",
    "    fig = plt.figure(figsize=(width2,height2))\n",
    "    if which_error in ['nrmse']:\n",
    "        plt.vlines(0.8,-2,220,color='darkgrey',linestyle='-',linewidth=1)\n",
    "    #plt.plot(0.3,rmse_full_temp[ss],symbol_full,color=color2,markersize=ms,zorder=0,label='all floats')\n",
    "    plt.hlines(nrmse_full_temp[ss],xlim1,xlim2,'black',linewidth=1.5,zorder=0,label='all floats')\n",
    "    \n",
    "    width1 = 0.06\n",
    "    color_vio = 'darkblue'\n",
    "    pp1=plt.violinplot(nrmse_sub_temp[:,ss,0],[xpos[0]],points=20,widths=width1,showmeans=False,\n",
    "                     showextrema=False,showmedians=True,quantiles=[0.1, 0.9]) \n",
    "    pp2=plt.violinplot(nrmse_sub_temp[:,ss,1],[xpos[1]],points=20,widths=width1,showmeans=False,\n",
    "                     showextrema=False,showmedians=True,quantiles=[0.1, 0.9])\n",
    "    pp3=plt.violinplot(nrmse_sub_temp[:,ss,2],[xpos[2]],points=20,widths=width1,showmeans=False,\n",
    "                     showextrema=False,showmedians=True,quantiles=[0.1, 0.9])\n",
    "    for pc in pp1['bodies']:\n",
    "        pc.set_facecolor(color_vio)\n",
    "        pc.set_edgecolor(color_vio)\n",
    "    for pc in pp2['bodies']:\n",
    "        pc.set_facecolor(color_vio)\n",
    "        pc.set_edgecolor(color_vio)\n",
    "    for pc in pp3['bodies']:\n",
    "        pc.set_facecolor(color_vio)\n",
    "        pc.set_edgecolor(color_vio)\n",
    "    \n",
    "    if which_error in ['rmse']:\n",
    "        plt.ylabel(which_error.upper()+' T below 2000m\\nin deg C\\n(Eulerian vs. float-based)',fontsize=fs)\n",
    "    else:\n",
    "        plt.ylabel(which_error.upper()+' T below 2000m\\n(Eulerian vs. float-based)',fontsize=fs)\n",
    "    plt.xlabel('Global # of floats\\n(# in subregion)',fontsize=fs)\n",
    "    plt.annotate('n='+str(num_it),xy=(0.01,1.015),\\\n",
    "                xycoords='axes fraction',fontsize=fs,ha='left',color='k')\n",
    "    plt.annotate(subregions[ss],xy=(0.99,1.015),\\\n",
    "                xycoords='axes fraction',fontsize=fs-2,ha='right',color='k',style='italic')\n",
    "    plt.annotate('# all synthetic floats\\nin subregion: '+str(int(num_floats_all_in_region[ss])),xy=(0.97,0.84),\\\n",
    "                xycoords='axes fraction',fontsize=fs-2,ha='right',color=color2)\n",
    "    plt.annotate(str(int(np.round((np.sum(area)/1e12)/global_target_list[2])))+' floats: '+\\\n",
    "                 str(np.round(1000*np.mean(rmse_sub_temp[:,ss,2]))/1000)+' mmol m-3',xy=(0.97,0.77),\\\n",
    "                xycoords='axes fraction',fontsize=fs-6,ha='right',color='k')\n",
    "    plt.annotate(str(int(np.round((np.sum(area)/1e12)/global_target_list[1])))+' floats: '+\\\n",
    "                 str(np.round(1000*np.mean(rmse_sub_temp[:,ss,1]))/1000)+' mmol m-3',xy=(0.97,0.73),\\\n",
    "                xycoords='axes fraction',fontsize=fs-6,ha='right',color='k')\n",
    "    plt.annotate(str(int(np.round((np.sum(area)/1e12)/global_target_list[0])))+' floats: '+\\\n",
    "                 str(np.round(1000*np.mean(rmse_sub_temp[:,ss,0]))/1000)+' mmol m-3',xy=(0.97,0.69),\\\n",
    "                xycoords='axes fraction',fontsize=fs-6,ha='right',color='k')\n",
    "    if len(global_target_list)>3:\n",
    "        plt.xticks([0,0.1,0.2,0.3],[str(int(np.round((np.sum(area)/1e12)/global_target_list[3])))+\\\n",
    "                                            '\\n('+str(int(num_floats_in_region[ss,3]))+')',\\\n",
    "                               str(int(np.round((np.sum(area)/1e12)/global_target_list[2])))+\\\n",
    "                                            '\\n('+str(int(num_floats_in_region[ss,2]))+')',\\\n",
    "                               str(int(np.round((np.sum(area)/1e12)/global_target_list[1])))+\\\n",
    "                                            '\\n('+str(int(num_floats_in_region[ss,1]))+')',\\\n",
    "                               str(int(np.round((np.sum(area)/1e12)/global_target_list[0])))+\\\n",
    "                                            '\\n('+str(int(num_floats_in_region[ss,0]))+')'],fontsize=fs)\n",
    "    else: # only 3 values\n",
    "        plt.xticks([0,0.1,0.2],[str(int(np.round((np.sum(area)/1e12)/global_target_list[2])))+\\\n",
    "                                            '\\n('+str(int(num_floats_in_region[ss,2]))+')',\\\n",
    "                               str(int(np.round((np.sum(area)/1e12)/global_target_list[1])))+\\\n",
    "                                            '\\n('+str(int(num_floats_in_region[ss,1]))+')',\\\n",
    "                               str(int(np.round((np.sum(area)/1e12)/global_target_list[0])))+\\\n",
    "                                            '\\n('+str(int(num_floats_in_region[ss,0]))+')'],fontsize=fs)\n",
    "    if which_error in ['nrmse']:\n",
    "        if which_region in ['south_of_60S']:\n",
    "            plt.ylim((0,100))\n",
    "        elif which_region in ['3060N_Atl']:\n",
    "            plt.ylim((0,400))\n",
    "    elif which_error in ['rmse']:\n",
    "        ylim1,ylim2 = plt.gca().get_ylim()\n",
    "        plt.ylim((0,ylim2))\n",
    "    plt.yticks(fontsize=fs)\n",
    "    plt.xlim((xlim1,xlim2))\n",
    "    if which_error in ['rmse']:\n",
    "        if which_region in ['south_of_60S']:\n",
    "            plt.yticks([0,0.05,0.1,0.15],[0,0.05,0.1,0.15])\n",
    "        elif which_region in ['3060N_Atl']:\n",
    "            plt.yticks([0,0.1,0.2,0.3,0.4],[0,0.1,0.2,0.3,0.4])\n",
    "    elif which_error in ['nrmse']:\n",
    "        if which_region in ['south_of_60S']:\n",
    "            plt.yticks([0,25,50,75,100],[0,25,50,75,100])\n",
    "        elif which_region in ['3060N_Atl']:\n",
    "            plt.yticks([0,100,200,300,400],[0,100,200,300,400])\n",
    "    if save_plots:\n",
    "        filename = 'Violin_Temperature_below_2000m_2012_2017_'+which_error+'_norm_by_std_full_vs_subsampled_vs_eulerian_'+\\\n",
    "                str(num_it)+'iterations_'+subregions2[rr]+'.png'\n",
    "        plt.savefig(savepath2+filename,dpi = dpicnt, bbox_inches='tight')\n",
    "        del filename\n",
    "    if display_plots_png:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close(fig)\n",
    "        \n",
    "    #---\n",
    "    # OXYGEN\n",
    "    #---\n",
    "    fig = plt.figure(figsize=(width2,height2))\n",
    "    if which_error in ['nrmse']:\n",
    "        plt.vlines(0.8,-2,220,color='darkgrey',linestyle='-',linewidth=1)\n",
    "    #plt.plot(0.3,rmse_full_temp[ss],symbol_full,color=color2,markersize=ms,zorder=0,label='all floats')\n",
    "    plt.hlines(nrmse_full_oxy[ss],xlim1,xlim2,color='black',linewidth=1.5,zorder=0,label='all floats')\n",
    "    \n",
    "    width1 = 0.06\n",
    "    color_vio = 'darkblue'\n",
    "    pp1=plt.violinplot(nrmse_sub_oxy[:,ss,0],[xpos[0]],points=20,widths=width1,showmeans=False,\n",
    "                     showextrema=False,showmedians=True,quantiles=[0.1, 0.9]) \n",
    "    pp2=plt.violinplot(nrmse_sub_oxy[:,ss,1],[xpos[1]],points=20,widths=width1,showmeans=False,\n",
    "                     showextrema=False,showmedians=True,quantiles=[0.1, 0.9])\n",
    "    pp3=plt.violinplot(nrmse_sub_oxy[:,ss,2],[xpos[2]],points=20,widths=width1,showmeans=False,\n",
    "                     showextrema=False,showmedians=True,quantiles=[0.1, 0.9])\n",
    "    for pc in pp1['bodies']:\n",
    "        pc.set_facecolor(color_vio)\n",
    "        pc.set_edgecolor(color_vio)\n",
    "    for pc in pp2['bodies']:\n",
    "        pc.set_facecolor(color_vio)\n",
    "        pc.set_edgecolor(color_vio)\n",
    "    for pc in pp3['bodies']:\n",
    "        pc.set_facecolor(color_vio)\n",
    "        pc.set_edgecolor(color_vio)\n",
    "    \n",
    "    if which_error in ['rmse']:\n",
    "        plt.ylabel(which_error.upper()+' O$_{2}$ below 2000m\\nin mmol m$^{-3}$\\n(Eulerian vs. float-based)',fontsize=fs)\n",
    "    else:\n",
    "        plt.ylabel(which_error.upper()+' O$_{2}$ below 2000m\\n(Eulerian vs. float-based)',fontsize=fs)\n",
    "    plt.xlabel('Global # of floats\\n(# in subregion)',fontsize=fs)\n",
    "    plt.annotate('n='+str(num_it),xy=(0.01,1.015),\\\n",
    "                xycoords='axes fraction',fontsize=fs,ha='left',color='k')\n",
    "    plt.annotate(subregions[ss],xy=(0.99,1.015),\\\n",
    "                xycoords='axes fraction',fontsize=fs-2,ha='right',color='k',style='italic')\n",
    "    plt.annotate('# all synthetic floats\\nin subregion: '+str(int(num_floats_all_in_region[ss])),xy=(0.97,0.84),\\\n",
    "                xycoords='axes fraction',fontsize=fs-2,ha='right',color=color2)\n",
    "    plt.annotate(str(int(np.round((np.sum(area)/1e12)/global_target_list[2])))+' floats: '+\\\n",
    "                 str(np.round(100*np.mean(rmse_sub_oxy[:,ss,2]))/100)+' mmol m-3',xy=(0.97,0.77),\\\n",
    "                xycoords='axes fraction',fontsize=fs-6,ha='right',color='k')\n",
    "    plt.annotate(str(int(np.round((np.sum(area)/1e12)/global_target_list[1])))+' floats: '+\\\n",
    "                 str(np.round(100*np.mean(rmse_sub_oxy[:,ss,1]))/100)+' mmol m-3',xy=(0.97,0.73),\\\n",
    "                xycoords='axes fraction',fontsize=fs-6,ha='right',color='k')\n",
    "    plt.annotate(str(int(np.round((np.sum(area)/1e12)/global_target_list[0])))+' floats: '+\\\n",
    "                 str(np.round(100*np.mean(rmse_sub_oxy[:,ss,0]))/100)+' mmol m-3',xy=(0.97,0.69),\\\n",
    "                xycoords='axes fraction',fontsize=fs-6,ha='right',color='k')\n",
    "    plt.yticks(fontsize=fs)\n",
    "    plt.xlim((xlim1,xlim2))\n",
    "    if len(global_target_list)>3:\n",
    "        plt.xticks([0,0.1,0.2,0.3],[str(int(np.round((np.sum(area)/1e12)/global_target_list[3])))+\\\n",
    "                                            '\\n('+str(int(num_floats_in_region[ss,3]))+')',\\\n",
    "                               str(int(np.round((np.sum(area)/1e12)/global_target_list[2])))+\\\n",
    "                                            '\\n('+str(int(num_floats_in_region[ss,2]))+')',\\\n",
    "                               str(int(np.round((np.sum(area)/1e12)/global_target_list[1])))+\\\n",
    "                                            '\\n('+str(int(num_floats_in_region[ss,1]))+')',\\\n",
    "                               str(int(np.round((np.sum(area)/1e12)/global_target_list[0])))+\\\n",
    "                                            '\\n('+str(int(num_floats_in_region[ss,0]))+')'],fontsize=fs)\n",
    "    else: # only 3 values\n",
    "        plt.xticks([0,0.1,0.2],[str(int(np.round((np.sum(area)/1e12)/global_target_list[2])))+\\\n",
    "                                            '\\n('+str(int(num_floats_in_region[ss,2]))+')',\\\n",
    "                               str(int(np.round((np.sum(area)/1e12)/global_target_list[1])))+\\\n",
    "                                            '\\n('+str(int(num_floats_in_region[ss,1]))+')',\\\n",
    "                               str(int(np.round((np.sum(area)/1e12)/global_target_list[0])))+\\\n",
    "                                            '\\n('+str(int(num_floats_in_region[ss,0]))+')'],fontsize=fs)\n",
    "    if which_error in ['nrmse']:\n",
    "        if which_region in ['south_of_60S']:\n",
    "            plt.ylim((0,100))\n",
    "        elif which_region in ['3060N_Atl']:\n",
    "            plt.ylim((0,400))\n",
    "    elif which_error in ['rmse']:\n",
    "        ylim1,ylim2 = plt.gca().get_ylim()\n",
    "        plt.ylim((0,ylim2))\n",
    "    if which_error in ['rmse']:\n",
    "        if which_region in ['south_of_60S']:\n",
    "            plt.yticks([0,1,2,3,4],[0,1,2,3,4])\n",
    "        elif which_region in ['3060N_Atl']:\n",
    "            plt.yticks([0,2,4,6,8,10,12],[0,2,4,6,8,10,12])\n",
    "    elif which_error in ['nrmse']:\n",
    "        if which_region in ['south_of_60S']:\n",
    "            plt.yticks([0,25,50,75,100],[0,25,50,75,100])\n",
    "        elif which_region in ['3060N_Atl']:\n",
    "            plt.yticks([0,100,200,300,400],[0,100,200,300,400])\n",
    "    if save_plots:\n",
    "        filename = 'Violin_Oxygen_below_2000m_2012_2017_'+which_error+'_norm_by_std_full_vs_subsampled_vs_eulerian_'+\\\n",
    "                str(num_it)+'iterations_'+subregions2[rr]+'.png'\n",
    "        plt.savefig(savepath2+filename,dpi = dpicnt, bbox_inches='tight')\n",
    "        del filename\n",
    "    if display_plots_png:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close(fig)\n",
    "    \n",
    "    #---\n",
    "    # Salinity\n",
    "    #---\n",
    "    fig = plt.figure(figsize=(width2,height2))\n",
    "    if which_error in ['nrmse']:\n",
    "        plt.vlines(0.8,-2,220,color='darkgrey',linestyle='-',linewidth=1)\n",
    "    #plt.plot(0.3,rmse_full_temp[ss],symbol_full,color=color2,markersize=ms,zorder=0,label='all floats')\n",
    "    plt.hlines(nrmse_full_salt[ss],xlim1,xlim2,color='black',linewidth=1.5,zorder=0,label='all floats')\n",
    "    \n",
    "    width1 = 0.06\n",
    "    color_vio = 'darkblue'\n",
    "    pp1=plt.violinplot(nrmse_sub_salt[:,ss,0],[xpos[0]],points=20,widths=width1,showmeans=False,\n",
    "                     showextrema=False,showmedians=True,quantiles=[0.1, 0.9]) \n",
    "    pp2=plt.violinplot(nrmse_sub_salt[:,ss,1],[xpos[1]],points=20,widths=width1,showmeans=False,\n",
    "                     showextrema=False,showmedians=True,quantiles=[0.1, 0.9])\n",
    "    pp3=plt.violinplot(nrmse_sub_salt[:,ss,2],[xpos[2]],points=20,widths=width1,showmeans=False,\n",
    "                     showextrema=False,showmedians=True,quantiles=[0.1, 0.9])\n",
    "    for pc in pp1['bodies']:\n",
    "        pc.set_facecolor(color_vio)\n",
    "        pc.set_edgecolor(color_vio)\n",
    "    for pc in pp2['bodies']:\n",
    "        pc.set_facecolor(color_vio)\n",
    "        pc.set_edgecolor(color_vio)\n",
    "    for pc in pp3['bodies']:\n",
    "        pc.set_facecolor(color_vio)\n",
    "        pc.set_edgecolor(color_vio)\n",
    "    \n",
    "    if which_error in ['rmse']:\n",
    "        plt.ylabel(which_error.upper()+' S below 2000m\\n(Eulerian vs. float-based)',fontsize=fs)\n",
    "    else:\n",
    "        plt.ylabel(which_error.upper()+' S below 2000m\\n(Eulerian vs. float-based)',fontsize=fs)\n",
    "    plt.xlabel('Global # of floats\\n(# in subregion)',fontsize=fs)\n",
    "    plt.annotate('n='+str(num_it),xy=(0.01,1.015),\\\n",
    "                xycoords='axes fraction',fontsize=fs,ha='left',color='k')\n",
    "    plt.annotate(subregions[ss],xy=(0.99,1.015),\\\n",
    "                xycoords='axes fraction',fontsize=fs-2,ha='right',color='k',style='italic')\n",
    "    plt.annotate('# all synthetic floats\\nin subregion: '+str(int(num_floats_all_in_region[ss])),xy=(0.97,0.84),\\\n",
    "                xycoords='axes fraction',fontsize=fs-2,ha='right',color=color2)\n",
    "    plt.annotate(str(int(np.round((np.sum(area)/1e12)/global_target_list[2])))+' floats: '+\\\n",
    "                 str(np.round(10000*np.mean(rmse_sub_salt[:,ss,2]))/10000)+' mmol m-3',xy=(0.97,0.77),\\\n",
    "                xycoords='axes fraction',fontsize=fs-6,ha='right',color='k')\n",
    "    plt.annotate(str(int(np.round((np.sum(area)/1e12)/global_target_list[1])))+' floats: '+\\\n",
    "                 str(np.round(10000*np.mean(rmse_sub_salt[:,ss,1]))/10000)+' mmol m-3',xy=(0.97,0.73),\\\n",
    "                xycoords='axes fraction',fontsize=fs-6,ha='right',color='k')\n",
    "    plt.annotate(str(int(np.round((np.sum(area)/1e12)/global_target_list[0])))+' floats: '+\\\n",
    "                 str(np.round(10000*np.mean(rmse_sub_salt[:,ss,0]))/10000)+' mmol m-3',xy=(0.97,0.69),\\\n",
    "                xycoords='axes fraction',fontsize=fs-6,ha='right',color='k')\n",
    "    plt.yticks(fontsize=fs)\n",
    "    plt.xlim((xlim1,xlim2))\n",
    "    if len(global_target_list)>3:\n",
    "        plt.xticks([0,0.1,0.2,0.3],[str(int(np.round((np.sum(area)/1e12)/global_target_list[3])))+\\\n",
    "                                            '\\n('+str(int(num_floats_in_region[ss,3]))+')',\\\n",
    "                               str(int(np.round((np.sum(area)/1e12)/global_target_list[2])))+\\\n",
    "                                            '\\n('+str(int(num_floats_in_region[ss,2]))+')',\\\n",
    "                               str(int(np.round((np.sum(area)/1e12)/global_target_list[1])))+\\\n",
    "                                            '\\n('+str(int(num_floats_in_region[ss,1]))+')',\\\n",
    "                               str(int(np.round((np.sum(area)/1e12)/global_target_list[0])))+\\\n",
    "                                            '\\n('+str(int(num_floats_in_region[ss,0]))+')'],fontsize=fs)\n",
    "    else: # only 3 values\n",
    "        plt.xticks([0,0.1,0.2],[str(int(np.round((np.sum(area)/1e12)/global_target_list[2])))+\\\n",
    "                                            '\\n('+str(int(num_floats_in_region[ss,2]))+')',\\\n",
    "                               str(int(np.round((np.sum(area)/1e12)/global_target_list[1])))+\\\n",
    "                                            '\\n('+str(int(num_floats_in_region[ss,1]))+')',\\\n",
    "                               str(int(np.round((np.sum(area)/1e12)/global_target_list[0])))+\\\n",
    "                                            '\\n('+str(int(num_floats_in_region[ss,0]))+')'],fontsize=fs)\n",
    "    if which_error in ['nrmse']:\n",
    "        if which_region in ['south_of_60S']:\n",
    "            plt.ylim((0,100))\n",
    "        elif which_region in ['3060N_Atl']:\n",
    "            plt.ylim((0,400))\n",
    "    elif which_error in ['rmse']:\n",
    "        ylim1,ylim2 = plt.gca().get_ylim()\n",
    "        plt.ylim((0,ylim2))\n",
    "    if which_error in ['rmse']:\n",
    "        if which_region in ['south_of_60S']:\n",
    "            plt.yticks([0,0.002,0.004,0.006,0.008],[0,0.002,0.004,0.006,0.008])\n",
    "        elif which_region in ['3060N_Atl']:\n",
    "            plt.yticks([0,0.01,0.02,0.03,0.04],[0,0.01,0.02,0.03,0.04])\n",
    "    elif which_error in ['nrmse']:\n",
    "        if which_region in ['south_of_60S']:\n",
    "            plt.yticks([0,25,50,75,100],[0,25,50,75,100])\n",
    "        elif which_region in ['3060N_Atl']:\n",
    "            plt.yticks([0,100,200,300,400],[0,100,200,300,400])\n",
    "    if save_plots:\n",
    "        filename = 'Violin_Salinity_below_2000m_2012_2017_'+which_error+'_norm_by_std_full_vs_subsampled_vs_eulerian_'+\\\n",
    "                str(num_it)+'iterations_'+subregions2[rr]+'.png'\n",
    "        plt.savefig(savepath2+filename,dpi = dpicnt, bbox_inches='tight')\n",
    "        del filename\n",
    "    if display_plots_png:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close(fig)\n",
    "        \n",
    "        \n",
    "    #----\n",
    "    # PLOT EPS\n",
    "    #----\n",
    "    \n",
    "    if plot_eps:\n",
    "        #---\n",
    "        # TEMP\n",
    "        #---\n",
    "        fig = plt.figure(figsize=(width2,height2))\n",
    "        if which_error in ['nrmse']:\n",
    "            plt.vlines(0.8,-2,220,color='darkgrey',linestyle='-',linewidth=1)\n",
    "        #plt.plot(0.3,rmse_full_temp[ss],symbol_full,color=color2,markersize=ms,zorder=0,label='all floats')\n",
    "        plt.hlines(nrmse_full_temp[ss],xlim1,xlim2,'black',linewidth=1.5,zorder=0,label='all floats')\n",
    "\n",
    "        width1 = 0.06\n",
    "        color_vio = 'darkblue'\n",
    "        pp1=plt.violinplot(nrmse_sub_temp[:,ss,0],[xpos[0]],points=20,widths=width1,showmeans=False,\n",
    "                         showextrema=False,showmedians=True,quantiles=[0.1, 0.9]) \n",
    "        pp2=plt.violinplot(nrmse_sub_temp[:,ss,1],[xpos[1]],points=20,widths=width1,showmeans=False,\n",
    "                         showextrema=False,showmedians=True,quantiles=[0.1, 0.9])\n",
    "        pp3=plt.violinplot(nrmse_sub_temp[:,ss,2],[xpos[2]],points=20,widths=width1,showmeans=False,\n",
    "                         showextrema=False,showmedians=True,quantiles=[0.1, 0.9])\n",
    "        for pc in pp1['bodies']:\n",
    "            pc.set_facecolor(color_vio)\n",
    "            pc.set_edgecolor(color_vio)\n",
    "        for pc in pp2['bodies']:\n",
    "            pc.set_facecolor(color_vio)\n",
    "            pc.set_edgecolor(color_vio)\n",
    "        for pc in pp3['bodies']:\n",
    "            pc.set_facecolor(color_vio)\n",
    "            pc.set_edgecolor(color_vio)\n",
    "\n",
    "        if len(global_target_list)>3:\n",
    "            plt.xticks([0,0.1,0.2,0.3],[],fontsize=fs)\n",
    "        else: # only 3 values\n",
    "            plt.xticks([0,0.1,0.2],[],fontsize=fs)\n",
    "        if which_error in ['nrmse']:\n",
    "            if which_region in ['south_of_60S']:\n",
    "                plt.ylim((0,100))\n",
    "            elif which_region in ['3060N_Atl']:\n",
    "                plt.ylim((0,400))\n",
    "        elif which_error in ['rmse']:\n",
    "            ylim1,ylim2 = plt.gca().get_ylim()\n",
    "            plt.ylim((0,ylim2))\n",
    "        plt.yticks(fontsize=fs)\n",
    "        plt.xlim((xlim1,xlim2))\n",
    "        # TEMP\n",
    "        if which_error in ['rmse']:\n",
    "            if which_region in ['south_of_60S']:\n",
    "                plt.yticks([0,0.05,0.1,0.15],[])\n",
    "            elif which_region in ['3060N_Atl']:\n",
    "                plt.yticks([0,0.1,0.2,0.3,0.4],[])\n",
    "        elif which_error in ['nrmse']:\n",
    "            if which_region in ['south_of_60S']:\n",
    "                plt.yticks([0,25,50,75,100],[])\n",
    "            elif which_region in ['3060N_Atl']:\n",
    "                plt.yticks([0,100,200,300,400],[])\n",
    "        if save_plots:\n",
    "            filename = 'Violin_Temperature_below_2000m_2012_2017_'+which_error+'_norm_by_std_full_vs_subsampled_vs_eulerian_'+\\\n",
    "                    str(num_it)+'iterations_'+subregions2[rr]+'.eps'\n",
    "            plt.savefig(savepath2+filename,dpi = dpicnt, bbox_inches='tight',format='eps')\n",
    "            del filename\n",
    "        if display_plots_eps:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close(fig)\n",
    "\n",
    "        #---\n",
    "        # OXYGEN\n",
    "        #---\n",
    "        fig = plt.figure(figsize=(width2,height2))\n",
    "        if which_error in ['nrmse']:\n",
    "            plt.vlines(0.8,-2,220,color='darkgrey',linestyle='-',linewidth=1)\n",
    "        #plt.plot(0.3,rmse_full_temp[ss],symbol_full,color=color2,markersize=ms,zorder=0,label='all floats')\n",
    "        plt.hlines(nrmse_full_oxy[ss],xlim1,xlim2,color='black',linewidth=1.5,zorder=0,label='all floats')\n",
    "\n",
    "        width1 = 0.06\n",
    "        color_vio = 'darkblue'\n",
    "        pp1=plt.violinplot(nrmse_sub_oxy[:,ss,0],[xpos[0]],points=20,widths=width1,showmeans=False,\n",
    "                         showextrema=False,showmedians=True,quantiles=[0.1, 0.9]) \n",
    "        pp2=plt.violinplot(nrmse_sub_oxy[:,ss,1],[xpos[1]],points=20,widths=width1,showmeans=False,\n",
    "                         showextrema=False,showmedians=True,quantiles=[0.1, 0.9])\n",
    "        pp3=plt.violinplot(nrmse_sub_oxy[:,ss,2],[xpos[2]],points=20,widths=width1,showmeans=False,\n",
    "                         showextrema=False,showmedians=True,quantiles=[0.1, 0.9])\n",
    "        for pc in pp1['bodies']:\n",
    "            pc.set_facecolor(color_vio)\n",
    "            pc.set_edgecolor(color_vio)\n",
    "        for pc in pp2['bodies']:\n",
    "            pc.set_facecolor(color_vio)\n",
    "            pc.set_edgecolor(color_vio)\n",
    "        for pc in pp3['bodies']:\n",
    "            pc.set_facecolor(color_vio)\n",
    "            pc.set_edgecolor(color_vio)\n",
    "\n",
    "        plt.yticks(fontsize=fs)\n",
    "        plt.xlim((xlim1,xlim2))\n",
    "        if len(global_target_list)>3:\n",
    "            plt.xticks([0,0.1,0.2,0.3],[],fontsize=fs)\n",
    "        else: # only 3 values\n",
    "            plt.xticks([0,0.1,0.2],[],fontsize=fs)\n",
    "        if which_error in ['nrmse']:\n",
    "            if which_region in ['south_of_60S']:\n",
    "                plt.ylim((0,100))\n",
    "            elif which_region in ['3060N_Atl']:\n",
    "                plt.ylim((0,400))\n",
    "        elif which_error in ['rmse']:\n",
    "            ylim1,ylim2 = plt.gca().get_ylim()\n",
    "            plt.ylim((0,ylim2))\n",
    "        # OXYGEN\n",
    "        if which_error in ['rmse']:\n",
    "            if which_region in ['south_of_60S']:\n",
    "                plt.yticks([0,1,2,3,4],[])\n",
    "            elif which_region in ['3060N_Atl']:\n",
    "                plt.yticks([0,2,4,6,8,10,12],[])\n",
    "        elif which_error in ['nrmse']:\n",
    "            if which_region in ['south_of_60S']:\n",
    "                plt.yticks([0,25,50,75,100],[])\n",
    "            elif which_region in ['3060N_Atl']:\n",
    "                plt.yticks([0,100,200,300,400],[])\n",
    "        if save_plots:\n",
    "            filename = 'Violin_Oxygen_below_2000m_2012_2017_'+which_error+'_norm_by_std_full_vs_subsampled_vs_eulerian_'+\\\n",
    "                    str(num_it)+'iterations_'+subregions2[rr]+'.eps'\n",
    "            plt.savefig(savepath2+filename,dpi = dpicnt, bbox_inches='tight',format='eps')\n",
    "            del filename\n",
    "        if display_plots_eps:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close(fig)\n",
    "\n",
    "        #---\n",
    "        # Salinity\n",
    "        #---\n",
    "        fig = plt.figure(figsize=(width2,height2))\n",
    "        if which_error in ['nrmse']:\n",
    "            plt.vlines(0.8,-2,220,color='darkgrey',linestyle='-',linewidth=1)\n",
    "        #plt.plot(0.3,rmse_full_temp[ss],symbol_full,color=color2,markersize=ms,zorder=0,label='all floats')\n",
    "        plt.hlines(nrmse_full_salt[ss],xlim1,xlim2,color='black',linewidth=1.5,zorder=0,label='all floats')\n",
    "\n",
    "        width1 = 0.06\n",
    "        color_vio = 'darkblue'\n",
    "        pp1=plt.violinplot(nrmse_sub_salt[:,ss,0],[xpos[0]],points=20,widths=width1,showmeans=False,\n",
    "                         showextrema=False,showmedians=True,quantiles=[0.1, 0.9]) \n",
    "        pp2=plt.violinplot(nrmse_sub_salt[:,ss,1],[xpos[1]],points=20,widths=width1,showmeans=False,\n",
    "                         showextrema=False,showmedians=True,quantiles=[0.1, 0.9])\n",
    "        pp3=plt.violinplot(nrmse_sub_salt[:,ss,2],[xpos[2]],points=20,widths=width1,showmeans=False,\n",
    "                         showextrema=False,showmedians=True,quantiles=[0.1, 0.9])\n",
    "        for pc in pp1['bodies']:\n",
    "            pc.set_facecolor(color_vio)\n",
    "            pc.set_edgecolor(color_vio)\n",
    "        for pc in pp2['bodies']:\n",
    "            pc.set_facecolor(color_vio)\n",
    "            pc.set_edgecolor(color_vio)\n",
    "        for pc in pp3['bodies']:\n",
    "            pc.set_facecolor(color_vio)\n",
    "            pc.set_edgecolor(color_vio)\n",
    "\n",
    "        plt.yticks(fontsize=fs)\n",
    "        plt.xlim((xlim1,xlim2))\n",
    "        if len(global_target_list)>3:\n",
    "            plt.xticks([0,0.1,0.2,0.3],[],fontsize=fs)\n",
    "        else: # only 3 values\n",
    "            plt.xticks([0,0.1,0.2],[],fontsize=fs)\n",
    "        if which_error in ['nrmse']:\n",
    "            if which_region in ['south_of_60S']:\n",
    "                plt.ylim((0,100))\n",
    "            elif which_region in ['3060N_Atl']:\n",
    "                plt.ylim((0,400))\n",
    "        elif which_error in ['rmse']:\n",
    "            ylim1,ylim2 = plt.gca().get_ylim()\n",
    "            plt.ylim((0,ylim2))\n",
    "        # SALT\n",
    "        if which_error in ['rmse']:\n",
    "            if which_region in ['south_of_60S']:\n",
    "                plt.yticks([0,0.002,0.004,0.006,0.008],[])\n",
    "            elif which_region in ['3060N_Atl']:\n",
    "                plt.yticks([0,0.01,0.02,0.03,0.04],[])\n",
    "        elif which_error in ['nrmse']:\n",
    "            if which_region in ['south_of_60S']:\n",
    "                plt.yticks([0,25,50,75,100],[])\n",
    "            elif which_region in ['3060N_Atl']:\n",
    "                plt.yticks([0,100,200,300,400],[])\n",
    "        if save_plots:\n",
    "            filename = 'Violin_Salinity_below_2000m_2012_2017_'+which_error+'_norm_by_std_full_vs_subsampled_vs_eulerian_'+\\\n",
    "                    str(num_it)+'iterations_'+subregions2[rr]+'.eps'\n",
    "            plt.savefig(savepath2+filename,dpi = dpicnt, bbox_inches='tight',format='eps')\n",
    "            del filename\n",
    "        if display_plots_eps:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close(fig)\n",
    "        \n",
    "print('done')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c074072-bfa4-4537-abab-0ad269b0d94a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv-jupyter",
   "language": "python",
   "name": "myenv-jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
