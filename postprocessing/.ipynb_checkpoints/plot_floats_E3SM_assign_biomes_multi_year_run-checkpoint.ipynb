{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "816a8784-8c24-4bb5-b790-052766d66fa8",
   "metadata": {},
   "source": [
    "\n",
    "# assign a biome to each float profile\n",
    "# save as netcdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "860ad28a-7d61-4bd1-ab78-71fc1ca51b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('/global/homes/c/cnissen/scripts/seawater-3.3.4/seawater/')\n",
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seawater\n",
    "#from seawater import dist\n",
    "#import seawater as sw\n",
    "import matplotlib.path as mpath\n",
    "from cartopy.util import add_cyclic_point\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.ticker as mticker\n",
    "from cartopy.mpl.ticker import (LongitudeFormatter, LatitudeFormatter,\n",
    "                                LatitudeLocator)\n",
    "import random\n",
    "from numba import njit\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "from netCDF4 import Dataset\n",
    "import time \n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbc915e7-ae0f-47f0-afc8-a8406aa85d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----\n",
    "# saving plots\n",
    "#-----\n",
    "\n",
    "#savepath     = '/project/projectdirs/m4003/cnissen/Plots/E3SM_floats/map_initial_positions/'\n",
    "## check existence of paths\n",
    "#if not os.path.exists(savepath):\n",
    "#    print ('Created '+savepath)\n",
    "#    os.makedirs(savepath)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "921ce04e-4e4b-456b-8ad9-7d32f07d8184",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----\n",
    "# FUNCTIONS\n",
    "#----\n",
    "\n",
    "@njit\n",
    "def get_closest_grid_point_vector(lon_point, lat_point, lon2, lat2):  \n",
    "    # PROVIDE LIST OF LOCATIONS TO FUNCTION!\n",
    "    # in all nodes in mesh, return the index of the closest node to lon_point/lat_point\n",
    "    # lon2 & lat2 are the locations in the new mesh (to be redistributed to)\n",
    "    # lon2 & lat2 should be in radians\n",
    "    # numpy needs to be imported outside the function\n",
    "    \n",
    "    #from math import sin, cos, sqrt, atan2, radians\n",
    "    #import numpy as np\n",
    "    # approximate radius of earth in km\n",
    "    R = 6373.0\n",
    "    \n",
    "    #lat2 = radians(mesh.y2) # all positions in mesh\n",
    "    #lon2 = radians(mesh.x2)\n",
    "    #lat2 = [radians(x) for x in mesh.y2]\n",
    "    #lon2 = [radians(x) for x in mesh.x2]\n",
    "    \n",
    "    index_closest_node    = np.zeros(len(lon_point))\n",
    "    distance_closest_node = np.zeros(len(lon_point))\n",
    "    for jj in range(0,len(lon_point)):\n",
    "        lat1 = radians(lat_point[jj])\n",
    "        lon1 = radians(lon_point[jj])\n",
    "        bb1 = cos(lat1)\n",
    "        \n",
    "        all_distances = np.zeros(len(lon2))\n",
    "        for i in range(0,len(lon2)):\n",
    "            dlon = lon2[i] - lon1\n",
    "            dlat = lat2[i] - lat1\n",
    "            a = sin(dlat / 2)**2 + bb1 * cos(lat2[i]) * sin(dlon / 2)**2\n",
    "            all_distances[i] = 2*R*atan2(sqrt(a), sqrt(1 - a)) # to speed things up, omit constant factors here!\n",
    "            #all_distances[i] = 2*R*atan2(sqrt(a), sqrt(1 - a)) # correct distance\n",
    "            #del dlon, dlat, a\n",
    "        index_closest_node[jj] = np.argmin(all_distances)\n",
    "        distance_closest_node[jj] = np.min(all_distances)\n",
    "\n",
    "    return index_closest_node, distance_closest_node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c7bab27-fab0-4496-b9df-e997f936bd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236853 nodes in mesh\n",
      "(236853,)\n",
      "(236853,)\n",
      "Min/Max lon: 0.0007300572350528742 359.997672445938\n",
      "Min/Max lat: -78.53259417674468 89.94461290099375\n",
      "layerThickness.shape: (1, 236853, 60)\n",
      "restingThickness.shape: (236853, 60)\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "# specifics for trajectory output\n",
    "####\n",
    "\n",
    "rad_to_deg = 180.0/np.pi\n",
    "latlim = -45.0\n",
    "\n",
    "path_mesh = '/global/cfs/cdirs/m4003/maltrud/'\n",
    "meshID = 'EC30to60E2r2'\n",
    "meshfile = xr. open_dataset(path_mesh+'ocean.'+meshID+'.210210.nc')\n",
    "#print(meshfile)\n",
    "\n",
    "lon  = meshfile['lonCell'].values*rad_to_deg\n",
    "lat  = meshfile['latCell'].values*rad_to_deg\n",
    "topo = meshfile['bottomDepth'].values\n",
    "area = meshfile['areaCell'].values\n",
    "zlevs            = meshfile['refBottomDepth'].values\n",
    "layerThickness   = meshfile['layerThickness'].values\n",
    "restingThickness = meshfile['restingThickness'].values\n",
    "\n",
    "print(len(lon),'nodes in mesh')\n",
    "print(topo.shape)\n",
    "print(area.shape)\n",
    "print('Min/Max lon:',np.min(lon),np.max(lon))\n",
    "print('Min/Max lat:',np.min(lat),np.max(lat))\n",
    "print('layerThickness.shape:',layerThickness.shape)\n",
    "print('restingThickness.shape:',restingThickness.shape)\n",
    "\n",
    "meshfile.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3956674e-5403-4928-a386-77e0e36c5fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min/Max mask_e3sm_all_regions: 0.0 27.0\n",
      "(236853,) (236853,) (236853,)\n"
     ]
    }
   ],
   "source": [
    "#----\n",
    "# load mask of biomes\n",
    "#----\n",
    "\n",
    "path_mask = '/global/cfs/cdirs/m4003/cnissen/masks/'\n",
    "file_mask = 'reccap_mask_regions_e3sm_mesh_EC30to60E2r2_wSubregions.nc'\n",
    "\n",
    "ff = xr. open_dataset(path_mask+file_mask)\n",
    "mask_global=ff['mask_e3sm_all_regions'].values.squeeze()\n",
    "ff.close()\n",
    "\n",
    "#subareas = ['Atlantic','Pacific','Indian','Arctic','SouthernOcean']\n",
    "#subareas = ['Atlantic','Pacific','Indian','Arctic','STSS','SPSS','ICE']\n",
    "\n",
    "print('Min/Max mask_e3sm_all_regions:',np.min(mask_global),np.max(mask_global)) \n",
    "\n",
    "print(mask_global.shape,lat.shape,lon.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fab0043d-92c4-4375-8e80-a2355c3e572b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load year 0060\n",
      "(364, 10560)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3560 [00:00<?, ?it/s]/global/homes/c/cnissen/.conda/envs/myenv/lib/python3.9/site-packages/numba/core/ir_utils.py:2152: NumbaPendingDeprecationWarning: \n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'lat2' of function 'get_closest_grid_point_vector'.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\n",
      "File \"../../../../../tmp/ipykernel_1053735/704263543.py\", line 5:\n",
      "<source missing, REPL/exec in use?>\n",
      "\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n",
      "/global/homes/c/cnissen/.conda/envs/myenv/lib/python3.9/site-packages/numba/core/ir_utils.py:2152: NumbaPendingDeprecationWarning: \n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'lon2' of function 'get_closest_grid_point_vector'.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\n",
      "File \"../../../../../tmp/ipykernel_1053735/704263543.py\", line 5:\n",
      "<source missing, REPL/exec in use?>\n",
      "\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n",
      "  0%|          | 3/3560 [00:02<38:43,  1.53it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all days for float 7001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 203/3560 [01:28<10:15,  5.46it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all days for float 7201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 401/3560 [02:44<10:39,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all days for float 7401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 600/3560 [03:59<11:20,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all days for float 7601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 803/3560 [05:08<10:18,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all days for float 7801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1002/3560 [06:14<04:43,  9.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all days for float 8001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 1204/3560 [07:32<06:44,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all days for float 8201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 1401/3560 [08:43<10:31,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all days for float 8401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 1602/3560 [09:59<05:21,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all days for float 8601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 1802/3560 [11:04<08:56,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all days for float 8801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 2002/3560 [11:56<02:38,  9.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all days for float 9001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 2201/3560 [12:49<06:08,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all days for float 9201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2402/3560 [14:10<12:10,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all days for float 9401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 2603/3560 [15:06<02:19,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all days for float 9601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 2802/3560 [16:11<04:13,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all days for float 9801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 3004/3560 [17:09<01:19,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all days for float 10001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 3202/3560 [18:12<02:08,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all days for float 10201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 3403/3560 [19:14<00:47,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all days for float 10401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3560/3560 [20:02<00:00,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#----\n",
    "# process daily float output\n",
    "#----\n",
    "save_netcdf = True\n",
    "\n",
    "path = '/global/cfs/cdirs/m4003/maltrud/6year/floats/'\n",
    "year_list = ['0055','0056','0057','0058','0059','0060']\n",
    "\n",
    "# kick out floats in shallow regions (these are not advected I think)\n",
    "ind = np.where(zlevs<=2200)[0]\n",
    "\n",
    "start_at_float = 7000\n",
    "\n",
    "for yy in range(5,len(year_list)):\n",
    "    print('Load year '+year_list[yy])\n",
    "    file1 = 'floats.year'+year_list[yy]+'.nc'   \n",
    "    data = xr. open_dataset(path+file1)\n",
    "\n",
    "    lon_1   = data['particleColumnLon'].values*rad_to_deg \n",
    "    lat_1   = data['particleColumnLat'].values*rad_to_deg \n",
    "    dic_1   = data['particleColumnDIC'].values #[:,0,:]\n",
    "    #print('lat_all',lat_all.shape)\n",
    "\n",
    "    # set missing values to NaN (deep ocean layers) \n",
    "    if year_list[yy] in ['0059']: # last year has only 363 days, but DIC has 364  \n",
    "        #lat_1[dic_1[:-1,:,:]==-1]=np.nan\n",
    "        #lon_1[dic_1[:-1,:,:]==-1]=np.nan\n",
    "        lat_1[dic_1[:,:,:]==-1]=np.nan\n",
    "        lon_1[dic_1[:,:,:]==-1]=np.nan\n",
    "    else: # until year 5\n",
    "        lat_1[dic_1==-1]=np.nan\n",
    "        lon_1[dic_1==-1]=np.nan\n",
    "    dic_1[dic_1==-1]=np.nan \n",
    "    \n",
    "    #print('Reduce to floats in the deep ocean')\n",
    "    #if yy==0: # only load the first time, re-use ind_deep\n",
    "    #    aux = np.sum(np.isnan(dic_1[0,ind,:]),axis=0) # check if any of the depth levels shallower than 1100m is NaN\n",
    "    #    ind_deep = np.where(aux==0)[0] # if it is, aux is >0; only keep those that are 0\n",
    "    ##print('Floats in the deep ocean:',ind_deep.shape)\n",
    "    #lon_1   = lon_1[:,:,ind_deep]\n",
    "    #lat_1   = lat_1[:,:,ind_deep]\n",
    "    \n",
    "    \n",
    "    #----\n",
    "    # loop over all floats and find 1) closest node in mesh, 2) biome index\n",
    "    #----\n",
    "\n",
    "    lat_float = lat_1[:,0,:]\n",
    "    lon_float = lon_1[:,0,:]\n",
    "    print(lat_float.shape) \n",
    "\n",
    "    ## convert lat/lon on model grid to radians\n",
    "    #lon_radians = [np.radians(x) for x in lon]\n",
    "    #lat_radians = [np.radians(x) for x in lat]\n",
    "\n",
    "    #closest_node = np.nan*np.ones_like(lat_float)\n",
    "    #biome_index  = np.nan*np.ones_like(lat_float)\n",
    "    for nn in tqdm(range(start_at_float,lat_float.shape[1])): # loop over floats\n",
    "        #start_time = time.time()\n",
    "\n",
    "        # narrow down the region of the float\n",
    "        #print(np.min(lon_float[:,nn]),np.max(lon_float[:,nn]))\n",
    "        #print(np.min(lat_float[:,nn]),np.max(lat_float[:,nn]))\n",
    "\n",
    "        # narrow down the region of the float\n",
    "        # to speed things up -> in colocation, there is no need to loop over all 200.000 nodes to find the closest one!!\n",
    "\n",
    "        # d1,d2: define spread of lon/lat for a given float\n",
    "        #d1 = np.abs((np.max(lon_float[:,nn])-np.min(lon_float[:,nn])))\n",
    "        #d2 = np.abs((np.max(lat_float[:,nn])-np.min(lat_float[:,nn])))\n",
    "        # select all locations that \n",
    "        #.   are between lat_min-3 and lat_max+3\n",
    "        #.   are between lon_min-3 and lon_max+3\n",
    "        dd = 1\n",
    "\n",
    "        d1 = np.min(lon_float[:,nn])-3 # lon is larger than this\n",
    "        d2 = np.max(lon_float[:,nn])+3 # lon is smaller than this\n",
    "        d3 = np.min(lat_float[:,nn])-3\n",
    "        d4 = np.max(lat_float[:,nn])+3\n",
    "        #print(d1,d2)\n",
    "        #print(d3,d4)\n",
    "        ind_near = np.where((lon>d1) & (lon<d2) & (lat>d3) & (lat<d4))[0]\n",
    "        #print(ind_near.shape)\n",
    "\n",
    "\n",
    "        #ind_near = np.where((np.abs(lon-np.min(lon_float[:,nn]))<5) & (np.abs(lat-np.min(lat_float[:,nn]))<5))[0]\n",
    "        #if (np.max(lat_float[:,nn])-np.min(lat_float[:,nn]))<5:\n",
    "        #    ind_near = np.where((np.abs(lon-np.min(lon_float[:,nn]))<5) & (np.abs(lat-np.min(lat_float[:,nn]))<5))[0]\n",
    "        #else:\n",
    "        #    ind_near = np.where((np.abs(lon-np.min(lon_float[:,nn]))<35) & (np.abs(lat-np.min(lat_float[:,nn]))<35))[0]\n",
    "        #print(np.min(lon[ind_near]),np.max(lon[ind_near]))\n",
    "        #print(np.min(lat[ind_near]),np.max(lat[ind_near]))\n",
    "\n",
    "        # convert lat/lon on model grid to radians\n",
    "        lon_radians = [np.radians(x) for x in lon[ind_near]]\n",
    "        lat_radians = [np.radians(x) for x in lat[ind_near]]\n",
    "\n",
    "        ##-----\n",
    "        # CORRECTION July, 20: \n",
    "        #   the index identified here is relative to lon[ind_near] and lat[ind_near], not relative to the full mesh!!!\n",
    "        #   i.e., all indices were stored incorrectly in previous version!!\n",
    "        #-------\n",
    "        index, distance = get_closest_grid_point_vector(lon_float[:,nn], lat_float[:,nn], lon_radians, lat_radians)\n",
    "        index = [int(x) for x in index]\n",
    "        \n",
    "        # convert to index relative to full mesh\n",
    "        index_all = np.zeros_like(index)\n",
    "        for ii in range(0,len(index)):\n",
    "            index_all[ii] = np.where((lon==lon[ind_near][index[ii]]) & (lat==lat[ind_near][index[ii]]))[0]\n",
    "        del distance\n",
    "\n",
    "        if save_netcdf: \n",
    "            # save to netcdf file\n",
    "            saving_directory  = '/global/cfs/cdirs/m4003/cnissen/6year_run/' \n",
    "            netcdf_name       = 'Float_positions_colocated_with_biomes_year'+year_list[yy]+'_v2.nc' \n",
    "\n",
    "            fv=-999\n",
    "\n",
    "            if save_netcdf: \n",
    "                # check if file exists already\n",
    "                if not os.path.exists(saving_directory+netcdf_name):\n",
    "                    print ('Create file '+saving_directory+netcdf_name)\n",
    "                    w_nc_fid = Dataset(saving_directory+netcdf_name, 'w', format='NETCDF4_CLASSIC')\n",
    "\n",
    "                    w_nc_fid.source_file = path+file1\n",
    "                    w_nc_fid.mesh_file = path_mesh+meshID\n",
    "                    w_nc_fid.script = '/global/homes/c/cnissen/scripts/plot_floats_E3SM_assign_biomes_multi_year_run.ipynb'\n",
    "                    w_nc_fid.mask_file = path_mask+file_mask\n",
    "\n",
    "                    w_nc_fid.mask_e3sm_all_regions = \"1.NA SPSS, 2.NA STSS, 3.NA STPS, 4.AEQU, 5.SA STPS, 6.MED (not in FM14)\" ;\n",
    "                    w_nc_fid.mask_e3sm_all_regions = \"7.IND STPS, 8.(not in FM14)\" ;\n",
    "                    w_nc_fid.mask_e3sm_all_regions = \"9.NP SPSS, 10.NP STSS, 11.NP STPS, 12.PEQU-W, 13.PEQU-E, 14.SP STPS\" ;\n",
    "                    w_nc_fid.mask_e3sm_all_regions = \"15.ARCTIC ICE (not in FM14), 16.NP ICE, 17.NA ICE, 18.Barents (not in FM14)\" ;\n",
    "                    w_nc_fid.mask_e3sm_all_regions = \"19. STSS_Atl, 20. SPSS_Atl, 21. ICE_Atl, 22. STSS_Ind, 23. SPSS_Ind, 24. ICE_Ind, 25. STSS_Pac, 26. SPSS_Pac, 27. ICE_Pac\"\n",
    "\n",
    "                    # create dimension & variable\n",
    "                    w_nc_fid.createDimension('Time', lat_float.shape[0]) \n",
    "                    w_nc_fid.createDimension('nParticles', lat_float.shape[1]) \n",
    "                    w_nc_var1 = w_nc_fid.createVariable('closest_node', 'f4',('Time','nParticles'),fill_value=fv)\n",
    "                    w_nc_var1.description = 'closest node on MPAS-O mesh'\n",
    "                    w_nc_var2 = w_nc_fid.createVariable('biome_index', 'f4',('Time','nParticles'),fill_value=fv)\n",
    "                    w_nc_var2.description = 'biome index on MPAS-O mesh'\n",
    "                    w_nc_fid.close()\n",
    "\n",
    "                # store data in file\n",
    "                data1 = np.arange(0,len(mask_global))[ind_near][index]\n",
    "                data2 = mask_global[ind_near][index] # make sure to hear first reduce to \"ind_near\" so that indices are correct\n",
    "                #print(data1)\n",
    "                #print(lon[data1])\n",
    "                #print(lon_float[:,nn])\n",
    "                data1[np.isnan(data1)] = fv\n",
    "                data2[np.isnan(data2)] = fv\n",
    "                w_nc_fid = Dataset(saving_directory+netcdf_name, 'r+', format='NETCDF4_CLASSIC')      # Create and open new netcdf file to write to\n",
    "                w_nc_fid.variables['closest_node'][:,nn] = index_all # CORRECTION JULY 2023, was \"index\" before!\n",
    "                w_nc_fid.variables['biome_index'][:,nn]  = data2\n",
    "                w_nc_fid.close()  \n",
    "                del data2\n",
    "                if np.mod(nn,200)==0:\n",
    "                    print('Saved all days for float',nn+1)\n",
    "\n",
    "        del index,ind_near\n",
    "        #end_time = time.time()\n",
    "        #print('Total time elapsed:',end_time-start_time)   \n",
    "\n",
    "    \n",
    "print('done')  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82063780-6973-4f43-83f7-ad82acaea123",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mindex\u001b[49m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'index' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76fc32c-2e63-410c-8e78-a2b22506759c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd04d63b-f034-4f41-80bd-ab3b8da1d693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b3a0ba-1665-44ed-8eaa-d2158ebbee24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ad4864-62b6-4bc7-9452-210b37e7ca4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e81b2fa-14cd-4e35-9885-fc0632e9438f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv-jupyter",
   "language": "python",
   "name": "myenv-jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
